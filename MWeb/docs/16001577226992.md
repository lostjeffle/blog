## Block - bio - 4 bio list


### bio list

bio list 最初应用于 dm 框架，虚拟的 dm 设备可以在另一个虚拟的 dm 设备之上，因而 dm 设备可以组成一个多层的 stack 结构，在这种结构下，顶层的 dm 设备下发一个 bio 的时候，在调用栈中会重复多次调用 submit_bio() 函数，如果 dm 设备栈的深度很深，那么就很容易将内核栈打爆

bio list 的引入正是为了解决这一问题，假设设备栈如下

```
            dm-0
dm-1        dm-2        dm3
nvme1       nvme2       nvme3
```

1. submit bio of dm-0

首先调用 submit_bio() 提交 dm-0 设备的 bio（记为 bio 0）的时候，开始初始化 current->bio_list 字段

```sh
(dm-0)submit_bio
    submit_bio_noacct
        __submit_bio_noacct
            # current->bio_list = bio_list_on_stack
            __submit_bio
```


之后调用 dm-0 的 submit_bio() 回调函数处理 bio 0，此时 bio 0 映射为 bio 1/2/3，这个时候在下发 bio 1/2/3 的时候就会重复调用 submit_bio()

```sh
(dm-1/2/3)submit_bio
    submit_bio_noacct
        if (current->bio_list):
		      bio_list_add(&current->bio_list[0], bio);
		      return BLK_QC_T_NONE;
```

此时只是将 bio 1/2/3 添加到 @bio_list_on_stack[0] 链表中，注意这个链表是位于 (dm-0)submit_bio 进程上下文中的

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 1 -> bio 2 -> bio 3
    @bio_list_on_stack[1] =
```


2. submit bio of dm-1

之后返回到 (dm-0)submit_bio 的进程上下文中

- 从 @bio_list_on_stack[0] 链表中取出一个 bio 也就是 bio 1
- 将 @bio_list_on_stack[0] 链表中剩余的 bio 转移到 @bio_list_on_stack[1] 链表中
- 之后就开始处理 bio 1

```sh
(dm-0)submit_bio
    submit_bio_noacct
        __submit_bio_noacct
            bio = bio_list_pop(&bio_list_on_stack[0])      
```

注意此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] =
    @bio_list_on_stack[1] = bio 2 -> bio 3
```


之后在处理 bio 1 的过程中，bio 1 被映射为 nvme1 设备下的 bio 4，此时 bio 4 会被添加到 @bio_list_on_stack[0] 链表中，此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 4
    @bio_list_on_stack[1] = bio 2 -> bio 3
```


3. submit bio of nvme1

之后再次返回到 (dm-0)submit_bio 的进程上下文中

接下来会将 @bio_list_on_stack[1] 链表合并到 @bio_list_on_stack[0] 链表中，此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 4 -> bio 2 -> bio 3
    @bio_list_on_stack[1] =
```


之后重复以上的步骤

- 从 @bio_list_on_stack[0] 链表中取出一个 bio 也就是 bio 4
- 将 @bio_list_on_stack[0] 链表中剩余的 bio 转移到 @bio_list_on_stack[1] 链表中
- 之后就开始处理 bio 4

注意此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] =
    @bio_list_on_stack[1] = bio 2 -> bio 3
```

之后调用 blk_mq_submit_bio() 处理 bio 4，由于 nvme 设备中不会再重复调用 submit_bio()，因而 bio 4 最终不会再添加到 bio list 中


4. submit bio of dm-2

之后再次返回到 (dm-0)submit_bio 的进程上下文中

接下来都是重复以上的步骤，将 @bio_list_on_stack[1] 链表合并到 @bio_list_on_stack[0] 链表中，此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 2 -> bio 3
    @bio_list_on_stack[1] =
```


之后重复以上的步骤

- 从 @bio_list_on_stack[0] 链表中取出一个 bio 也就是 bio 2
- 将 @bio_list_on_stack[0] 链表中剩余的 bio 转移到 @bio_list_on_stack[1] 链表中
- 之后就开始处理 bio 2

注意此时 bio list 更新为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] =
    @bio_list_on_stack[1] = bio 3
```

bio 2 的处理和之前介绍的 bio 1 的处理步骤是完全一样的


所以 bio list 中 bio 的处理相当于是“深度优先”的原则

> bio_list_on_stack[0] contains bios submitted by the current ->submit_bio.
> bio_list_on_stack[1] contains bios that were submitted before the current->submit_bio, but that haven't been processed yet.


### bioset

在 dm 路径中，dm 设备的 bio 需要映射为底层对应的物理设备的 bio，这一过程中就需要分配新的 bio 结构，通常都是依赖于 bioset 分配 bio 结构的，bioset 底层实际依赖于 mempool 机制分配内存

bio list 和 mempool 结合在一起会带来潜在的 deadlock 风险

首先 mempool 中为了确保内存分配的成功，当 zoned page allocator 直接分配内存失败、同时事先预留的内存也用尽时，当前进程上下文会进入等待队列睡眠等待，直到其他进程上下文释放内存，但是前提是传入的 gfpmask 设置有 __GFP_DIRECT_RECLAIM 标志

block layer 中通过 bioset 分配 bio 结构的时候，为了确保 bio 结构分配成功，通常都会传入 __GFP_DIRECT_RECLAIM 标志，这样在 low memory 的情况下，进程会进入等待队列睡眠等待，直到其他进程释放之前从该 bioset 分配的 bio 的时候，才会唤醒等待队列中的睡眠进程

但是在引入 bio list 之后，其中就存在潜在的 deadlock，以之前介绍的例子为例

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 1 -> bio 2 -> bio 3
    @bio_list_on_stack[1] =
```

(从链表中取出一个 bio 即 bio 1 进行处理)

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] =
    @bio_list_on_stack[1] = bio 2 -> bio 3
```

我们在处理 bio 1 的时候，需要创建 bio 4，假设这个时候发生了 low memory，因而当前进程就进入睡眠等待，直到之前分配的 bio (即 bio2/3) 释放的时候，才会被唤醒

但是由于 bio list 的存在，bio2/3 缓存在 bio list 中，实际上等到 bio 1 处理完成后才会处理（之后并释放）bio2/3，从而形成死锁


为了解决这一问题，bioset 引入 rescue worker 机制

```c
struct bio_set {
	/*
	 * Deadlock avoidance for stacking block drivers: see comments in
	 * bio_alloc_bioset() for details
	 */
	struct bio_list		rescue_list;
	struct work_struct	rescue_work;
	struct workqueue_struct	*rescue_workqueue;
};
```

bio_alloc_bioset() 中

- 首先尝试去除 gfpmask 中的 __GFP_DIRECT_RECLAIM 标志，向 mempool 申请分配内存
- 如果分配失败，那么会唤醒 rescue worker 处理 current->bio_list[] 中缓存的 bio
- 之后再尝试设置有 __GFP_DIRECT_RECLAIM 标志版本的 mempool 内存分配

这样当前进程在执行设置有 __GFP_DIRECT_RECLAIM 标志的 mempool 内存分配，rescue worker 在处理之前分配的 bio，两个操作在两个进程上下文中分开执行，就避免了前文介绍的 deadlock 问题


### bio-split

bio list 不止应用于 dm 路径，实际上在 bio-split 路径中也有所应用

bio-split 路径中会依赖 bioset 分配 bio 结构

```
submit_bio
    submit_bio_noacct
        __submit_bio_noacct
            __submit_bio
                blk_mq_submit_bio
                    __blk_queue_split
                        blk_bio_segment_split
                            bio_split
                                bio_clone_fast
                                    bio_alloc_bioset()
                                        mempool_alloc(q->bio_split, GFP_NOIO)
```

像之前介绍的，bioset 引入 rescue worker 机制是为了解决 bio 分配过程中潜在的 deadlock 风险，实际上在 bio 下发过程中，任何一个进程上下文在一次 submit_bio() 调用过程中，都不能从同一个 bioset 分配多个 bio，否则就有潜在的 deadlock 风险

因而在实现 bio-split 路径的时候，也不能在一次 submit_bio() 调用过程中就将一个 bio 一次性划分为多个 bio，因为这个过程中涉及到多个 split bio 结构的内存分配，而所有 split bio 都是从 @q->bio_split 这个 bioset 中分配的，因而存在潜在的 deadlock 风险

因而 bio-split 路径实际上是以递归的方式实现，即递归调用 submit_bio()，每次 submit_bio() 调用过程中就只划分出一个 split bio


bio-split 路径中也会用到 bio list，如下图所示为 split 过程的示意图，此时对 remain bio 递归调用 submit_bio() 时，只是将该 bio 添加到 @current->bio_list 链表中

```
        original struct bio
+-------------------------------+
|                               |
+-------------------------------+

cloned struct bio      original struct bio
+-------+           +-----------------------+
| split |           |       remain          |
+-------+           +-----------------------+

```

此时 bio list 更新为

```
    @bio_list[0] = remain bio
    @bio_list[1] =
```


将 remain bio 添加到 bio list 之后，会立即对 split bio 进行处理；split bio 处理完成后，再从 @current->bio_list 链表中取出 remain bio，其处理过程同以上


### improved dm split

需要注意的是，以上 "bio list" 小节介绍的 dm 设备的 IO 路径是 v4.16 之前的行为，此时在处理 bio 0 的过程中，会一次性将 bio 0 映射为所有底层设备对应的 bio 即 bio 1/2/3，此时这些 bio 存储在 bio list 中

此时 bio list 的状态为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 1 -> bio 2 -> bio 3
    @bio_list_on_stack[1] =
```

这样的设计实际上就是一次性从 bioset 分配多个 bio，在 "bioset" 小节介绍过，这样的行为有可能带来潜在的 deadlock 风险

因而内核在 v4.16 引入 commit 18a25da84354 ("dm: ensure bio submission follows a depth-first tree walk")，该特性就是仿照 "bio-split" 小节中的行为，在处理 bio 0 的过程中，在映射并下发 bio 1 之后，将原来的 bio 0 拆分为 bio 1 与 remain bio 两部分，之后将 remain bio 通过 generic block layer 下发

```
        original struct bio (bio 0)
+-------------------------------+
|                               |
+-------------------------------+

cloned struct bio (bio 1)      original struct bio
+-------+                       +-----------------------+
| split |                       |       remain          |
+-------+                       +-----------------------+
```

此时 bio list 的状态为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 1 -> remain bio(1)
    @bio_list_on_stack[1] =
```

之后在 bio 1 处理完成后，处理 remain bio 的过程中，从 remain bio 中拆分出一个 bio 2 之后，又将剩余的 remain bio(2) 下发，此时 bio list 的状态为

```sh
(dm-0)submit_bio
    @bio_list_on_stack[0] = bio 2 -> remain bio(2)
    @bio_list_on_stack[1] =
```

我们可以看到 block layer 的 bio list 的运作机制就是 depth first 的，在该特性之前 dm 层拆分 bio 时的行为实际上是 width first 的，这一行为实际上会增大 deadlock 的风险（虽然 bioset 机制确保 deadlock 真的发生的时候，有 rescue 机制来进行兜底）；因而 v4.16 引入的这一特性就是将 dm 层拆分 bio 的行为转变为 depth first 的，与 block layer 的行为保持一致


### allocate multiple bios from one bioset at once

为了减少 deadlock 的风险，应该避免一次性从同一个 bioset 分配多个 bio 的行为

需要注意的是，之前介绍的 rescue worker 机制生效的前提是，之前分配的 bio 已经（通过调用 submit_bio()）添加到 bio list 中，因为 rescue worker 就是从 bio list 取出 bio 进行处理并腾出一些 bio 资源的；此时的模式实际上是分配一个 bio，调用 submit_bio() 将这个 bio 下发下去，之后再分配一个 bio，再下发

如果一次性从同一个 bioset 分配多个 bio，同时将这些 bio 囤积在那里，也就是说一次性分配多个 bio，等所有 bio 都分配出来之后，再依次调用 submit_bio() 下发这些 bio，此时就存在潜在的 deadlock 风险

例如当多个进程并发地从同一个 bioset 分配多个 bio 时，例如一个包含 256 个 bio 的 bioset，两个进程都需要一次性分配 256 个 bio，当这两个进程都从这个 bioset 分配出 128 个 bio 时，就会发生 deadlock，此时 rescue worker 机制并不能解决这个问题

dm 中就会出现以上这个问题，在处理 abnormal IO 的时候，例如 dm 设备的一个 DISCARD bio 有可能需要映射为多个底层设备的 DISCARD bio，每个底层设备一个 DISCARD bio，此时就需要从 bioset 分配多个 bio，如果多个进程同时并发执行以上逻辑，就有可能造成 deadlock

解决办法是使用锁机制防止并发访问，但是为了性能考虑会首先尝试不加锁的时候分配，如果分配成功自然皆大欢喜；如果分配失败那么先释放之前分配的 bio，之后再老老实实地加锁再分配

```sh
__process_abnormal_io
    __send_discard
        __send_duplicate_bios
            alloc_multiple_bios
                # round 1: try to allocate without locking
                success: return
                failed: free allocated bios back to bioset
                
                # round 2: allocate with locked
                success: return
```
