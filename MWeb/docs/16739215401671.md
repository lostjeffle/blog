title:'FUSE - IO - Buffer IO'
## FUSE - IO - Buffer IO

"cache=auto|always + Buffer IO" 模式下就会走 buffer IO 路径


### Buffer READ

```sh
f_op->read_iter(), i.e. fuse_file_read_iter()
    fuse_cache_read_iter
        generic_file_read_iter
            filemap_read
                filemap_get_pages
                    filemap_get_read_batch // find page cache
                    filemap_create_folio // create new page cache if not exist
                    if !PageUptodate(page):
                        filemap_update_page
                            filemap_read_page
                                a_ops->readpage(), i.e. fuse_readpage()
                                    fuse_do_readpage
                                        # send FUSE_READ request
                
                # copy data to page cache
```


### Buffer WRITE

fuse 的 buffer write 有两种模式，writethrough 和 writeback

fuse_conn 的 @update_mtime 标志位描述当前 fuse 文件系统是采用 writethrough 还是 writeback 模式

fuse server/client 可以在 FUSE_INIT 阶段进行协商，如果采用 writeback 模式，那么 fuse server 需要将 @fuse_init_out.flags 字段设置上 FUSE_WRITEBACK_CACHE 标志，否则就采用 writethrough 模式，这也是默认的模式

```c
struct fuse_conn {
	/** write-back cache policy (default is write-through) */
	unsigned writeback_cache:1;
	...
}
```


#### writethrough

writethrough 模式下执行 buffer write 的时候，1)在将数据写入 page cache 之后，2)会立即发起 FUSE_WRITE 请求，将这些写入的 page cache 回写到后端

```sh
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        fuse_perform_write
            # write page cache
            fuse_fill_write_pages
                page = grab_cache_page_write_begin() // find page cache
                # copy data to page cache
            
            # send FUSE_WRITE request (writeback page cache)
            fuse_send_write_pages
```


#### writeback

FUSE 一开始只支持 writethrough 模式，后来在 v3.15 开始引入 writeback 模式
> d5cd66c58edf fuse: Connection bit for enabling writeback
> 8373200b124d fuse: Trust kernel i_size only
> b0aa76065217 fuse: Trust kernel i_mtime only
> 4d99ff8f12eb fuse: Turn writeback cache on

writeback 模式下执行 buffer write 的时候，只是将数据写入 page cache

```sh
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        generic_file_write_iter      
            generic_perform_write
                a_ops->write_begin() // find page cache
                # copy data to page cache
                a_ops->write_end() // mark page cache and inode as dirty
```


之后在 writeback 的时候再发起 FUSE_WRITE 请求，将这些 dirty page cache 回写到后端

```sh
__writeback_single_inode
    do_writepages
        a_ops->writepages(), i.e., fuse_writepages
            # send FUSE_WRITE request
```


writeback 模式下，文件被 close 之后就会对文件的数据 (dirty page cache) 和元数据 (inode) 发起回写操作，也就是实现所谓的 flush-on-close 语义，即确保文件被 close 之后，fuse client 对文件的所有修改 (包括数据和元数据) 都已经下刷到 fuse server

```
# close(2)
filp_close
    f_op->flush(), i.e. fuse_flush()
        # if writeback mode and !(ff->open_flags & FOPEN_NOFLUSH):
            fuse_do_flush
                write_inode_now
                    writeback_single_inode
                        do_writepages
                            # data writeback
                            a_ops->writepages(), i.e., fuse_writepages()
                                # send FUSE_WRITE request
                            
                            # metadata writeback
                            a_ops->write_inode(), i.e. fuse_write_inode()
                                fuse_flush_times
                                    # send FUSE_SETATTR request, updating mtime/ctime
```

这里需要注意的是，在下刷元数据的时候，在下发的 FUSE_SETATTR 请求中只会申请下刷 fuse client 中维护的 mtime/ctime 版本，而不会申请下刷 size；这是因为之前通过 FUSE_WRITE 请求下刷 dirty data 的时候，fuse server 对文件执行写入操作的时候，文件的 size 自然就会保持更新；但是在 fuse server 对文件的写入操作结束后，文件的 mtime/ctime 是 fuse server 侧执行写入操作时自动更新的时间戳，因而必须通过 fuse client 下发的 FUSE_SETATTR 请求，更新为 fuse client 中维护的 mtime/ctime 版本


##### temp page design

上述介绍到，writeback 流程中实际上是调用 a_ops->writepages() 即 fuse_writepages() 完成回写操作

FUSE 的 writeback 逻辑 (commit [3be5a52b30aa ("fuse: support writable mmap")](https://github.com/torvalds/linux/commit/3be5a52b30aa)) 引入了 temp page 的设计，即 fuse 的 writeback 过程中，实际会分配一个额外的临时 page，将需要回写的 dirty page 的内容拷贝到新分配的临时 page 中，后续实际上是针对这个临时 page 发送 FUSE_WRITE 请求，以执行回写操作。

这是考虑到以下两点因素

首先 fuse daemon 在处理内核 writeback 下发的 FUSE_WRITE 请求的过程中，例如 fuse daemon 在处理 FUSE_WRITE 请求过程中需要申请内存分配，申请内存分配过程中可能触发了 direct memory reclaim 从而触发了 fuse 文件系统的 writeback 操作，从而形成 deadlock

另外一方面，一个实现不佳的甚至恶意的 fuse daemon 完全有可能导致回写下发的 FUSE_WRITE 请求迟迟无法完成并返回，从而使得系统中另一个不相关的进程发起的操作发生 halt。例如系统中一个进程发起的操作 sync 操作就会触发 fuse 文件系统的 writeback 操作，并在发起 sync 操作的进程上下文中阻塞等待回写的完成。此时如果 fuse daemon 在处理 FUSE_WRITE 请求的过程中迟迟无法完成，就会导致 sync 进程发生 halt

```
ksys_sync
    for each superblock
        sync_inodes_sb
            # initiate a writeback work
            		.reason               = WB_REASON_SYNC,
            		.sync_mode            = WB_SYNC_ALL,
            		.for_sync             = 1

wb_writeback
    writeback_sb_inodes
        __writeback_single_inode
            do_writepages // start writeback
            if wbc->sync_mode == WB_SYNC_ALL:
                filemap_fdatawait
                    # wait for all pages getting PG_writeback cleared
```

上述 sync 进程在等待 fuse writeback 下发的 IO 完成的过程中，实际上是等待 dirty page 的 PG_writeback 标志被清除（dirty page 的 writeback IO 完成的时候，就会移除 PG_writeback 标志）

因而 fuse writeback 的 temp page 的设计就是在下发 writeback 的时候，实际分配一个额外的临时 page，将需要回写的 dirty page 的内容拷贝到新分配的临时 page 中，后续实际上是针对这个临时 page 发送 FUSE_WRITE 请求，以执行回写操作；后面对这个临时 page 发起 FUSE_WRITE 请求之后，立即清除 address space (xarray) 的  PAGECACHE_TAG_WRITEBACK tag 与这个真正的 dirty page 的 PageWriteback 标记，这样 sync 进程就认为 fuse 的 writeback 已经完成了，而不会阻塞在这里

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            fuse_writepages_fill
                # allocate temp page to hold the dirty data
                tmp_page = alloc_page(GFP_NOFS | __GFP_HIGHMEM)
                
                # allocate struct fuse_writepage_args (wpa)
                # init FUSE_WRITE request with allocated temp page
                
                # copy data in original dirty page to temp page
                
                # inc wb WB_WRITEBACK counter
                inc_wb_stat(&inode_to_bdi(inode)->wb, WB_WRITEBACK);
                
                # inc global NR_WRITEBACK_TEMP counter
                inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP)
                
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # insert this fuse_writepage_args (wpa) into fuse_inode's writepages rbtree
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            # for each wpa in fuse_inode's queued_writes list
                fuse_send_writepage(..., wpa, ...)
                    fuse_simple_background // send FUSE_WRITE request
        
        # for each original page in this wpa
            end_page_writeback()
                # clear PG_writeback of this page
                # clear PAGECACHE_TAG_WRITEBACK tag of this page in its address space
```

当 FUSE_WRITE request 完成的时候，就会调用相应的 .end() 回调函数，即 fuse_writepage_end()

```
fuse_writepage_end
    # delete this wpa (fuse_writepage_args) from fuse_inode's writepages rbtree
    
    fuse_writepage_finish
        # for each temp page in this wpa
            # dec wb WB_WRITEBACK counter
            dec_wb_stat(&bdi->wb, WB_WRITEBACK)
            
            # dec global NR_WRITEBACK_TEMP counter
            dec_node_page_state(ap->pages[i], NR_WRITEBACK_TEMP);
            
            # inc wb's and global writeout completion counter
            wb_writeout_inc(&bdi->wb)
```

但是在回写下发的 FUSE_WRITE 请求真正完成之前，后续对同一 page cache 的写操作都会阻塞，从而防止同一个 page cache 产生多个的 temp page 从而在内存资源层面进行 DoS 攻击


##### write protect on same buffer page

尽管上述流程中，在将需要回写的 original dirty page 的内容拷贝到新分配的临时 page 中，并对这个临时 page 发送 FUSE_WRITE 请求之后，真正的 original page 就会立即清除 PageWriteback tag，但是这个设计只是为了让类似 sync(2) 这样的操作（等待 fuse page 回写完成）返回；而在数据真正回写完成之前、即这个 FUSE_WRITE 请求完成之前，对同一个 page 的写操作也不能并发进行，这一写操作必须等待之前的 FUSE_WRITE 请求完成，即回写完成之后才能继续进行，从而防止 data corruption。

###### writepages rbtree

为了判断当前需要写入的 page cache 是否存在之前未完成的回写请求，就必须对尚未完成的 inflight writepage request 进行缓存，以方便查询

因而使用 struct fuse_writepage_args 来抽象一个 writepages request

```c
struct fuse_writepage_args {
	struct fuse_io_args ia;
	struct fuse_writepage_args *next;
	struct inode *inode;
	...
};
```

并通过 fuse_inode 的 writepages rbtree 组织该文件的所有 writepages request (包括 pending 状态等待发送、以及已发送但尚未完成的 writepages request)，该 writepages request 需要回写的 file offset 作为该 rbtree 的 index

```c
struct fuse_inode {
		/* List of writepage requestst (pending or sent) */
		struct rb_root writepages;
		...
}
```


###### write protect of buffered write(2)

回到 writeback 模式下的 buffer write 路径中，就会检查 fuse_inode 的 writepages rbtree 中是否有当前需要写入的 page 对应的 wpa，若存在则说明该 page 对应的文件偏移位置处当前正存在回写任务，因而当前的写操作需要等待该回写任务完成才能继续进行

```
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        generic_file_write_iter      
            generic_perform_write
                a_ops->write_begin(), i.e. fuse_write_begin()
                    # find corresponding page
                    page = grab_cache_page_write_begin()
                        pagecache_get_page(..., FGP_WRITEBEGIN, ...)
                            __filemap_get_folio
                                # find folio at specified index
                                if fgp_flags & FGP_LOCK:
                                    folio_lock(folio)
                
                    fuse_wait_on_page_writeback
                        fuse_page_is_writeback
                            fuse_range_is_writeback
                                # find if existing wpa in fuse_inode's writepages rbtree
```

```c
#define FGP_WRITEBEGIN		(FGP_LOCK | FGP_WRITE | FGP_CREAT | FGP_STABLE)
```

上文介绍到，fuse writeback 路径中会向 fi->writepages rbtree 中插入 wpa，而 buffer write 路径中会在 fi->writepages rbtree 中查找对应的 wpa，而为了防止两者对 fi->writepages rbtree 的共同访问发生 race，使用 page lock 对这两个操作进行保护

buffer write 路径中，会在持有 page lock 的情况下，在 fi->writepages rbtree 中查找对应的 wpa

而 writeback 过程中，将 wpa 添加到 fi->writepages rbtree 全程都是持有对应 original page 的 page lock 的；在将 wpa 添加到 fi->writepages rbtree 之后，就可以释放 page lock 了

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            folio_lock(folio);
            fuse_writepages_fill
                ...
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # insert this fuse_writepage_args into fuse_inode's writepages rbtree
                ...
            folio_unlock(folio)
```


###### write protect of mmap

此外在 shared mmap 模式下，用户进程可以直接对 mmap(2) 返回的内存地址作写操作，因而也要防止 fuse writeback 过程中（wpa 尚未添加到 fi->writepages rbtree 中时），用户进程通过返回的内存地址直接对正在回写的 original page 进行写入操作

[title:'MM - 6 Write Protect Page Fault'](mweblib://16212343733707) 中介绍到 mm 层使用一种特殊的机制对所有 shared dirty page 进行追踪，即对 page 进行 writeback 的过程中，将回写的 page 对应的 pte 设置为 read-only

```sh
# wbc->sync_mode == WB_SYNC_NONE
__writeback_single_inode
    do_writepages
        a_ops->writepages(), i.e., ext4_writepages
            generic_writepages
                write_cache_pages
                    pagevec_lookup_range_tag(..., PAGECACHE_TAG_DIRTY) // find PAGECACHE_TAG_DIRTY pages
                    
                    (for each PAGECACHE_TAG_DIRTY page)
                        lock_page(page)
                        clear_page_dirty_for_io(page)
                            (if mapping_cap_account_dirty(mapping)) page_mkclean(page)
                                (for all vma (may belong to multiple processes)) page_mkclean_one(page, vma, ...)
                                    # get corresponding pte
                                    entry = ptep_clear_flush(vma, address, pte);
                                    entry = pte_wrprotect(entry); // clean pte's writable
                                    entry = pte_mkclean(entry);
```

之后进程再一次对该 page 执行写操作时，就会触发 Write Protect Page Fault，其中请求将对应的 pte 重新设置为 writable，这一过程中会调用 page_mkwrite() 回调函数以通知文件系统，用户进程尝试重新对这个 page 进行置脏。此时 fuse 的 page_mkwrite() 实现中就会在持有 page lock 的情况下，检查 fi->writepages rbtree 中是否有正在处理的回写任务

```sh
handle_mm_fault
    __handle_mm_fault
        handle_pte_fault
            # Write Protect: pte exist, pte.P = 1
            do_wp_page
                wp_page_shared
                    do_page_mkwrite
                        vmf->flags = FAULT_FLAG_WRITE|FAULT_FLAG_MKWRITE
                        
                        # notification that a previously read-only page is about to become writable
                        vma->vm_ops->page_mkwrite(). i.e. fuse_page_mkwrite() 
                            lock_page(page)
                            fuse_wait_on_page_writeback
                                # find if existing wpa in fuse_inode's writepages rbtree
```


###### write protect of DIRECT IO


auxiliary write request list

上述 writepages rbtree 的机制，无论是 buffered write(2) 还是 mmap write，都是在 buffer IO 场景下确保一个 page 回写的过程中，对同一个 page 的 buffer write(2) 操作无法并发进行，但是在 DIRECT IO 场景下，VFS 层没有提供合适的回调函数接口提供给文件系统实现，以通知文件系统当前有针对这个 page 的写入请求（例如 buffered write(2) 场景是通过 .write_begin() 回调函数，mmap write 场景中是通过 .page_mkwrite() 回调函数），因而在 DIRECT IO 的场景下，对某一个 page 的回写任务还没有完成的情况下（即 fi->writepages rbtree 中存在对应的 wpa），原 page 又被置 dirty 并再次发起一个回写操作，对同一个 page 两个并发的 FUSE_WRITE（两个并发的 wpa）就有可能导致 data corruption

为了解决这一问题，commit 8b284dc47291 ("fuse: writepages: handle same page rewrites") 中引入 auxiliary write request list 的概念

此时在下发回写操作的过程中，在将当前回写请求 (wpa) 添加到 writepages rbtree 的时候，会检查 writepages rbtree 中有没有旧的 wpa 与当前下发的 wpa 是写的同一个文件区间，如果确实有，就会将当前下发的 wpa (new_wpa) 添加到已有的 old_wpa 的 @next 字段，此时当前下发的 new_wpa 就会作为一个 secondary wpa 暂时缓存在那里，之后等到 old wpa 回写请求完成的时候才会下发 secondary wpa 描述的回写操作

此时需要注意的是 secondary wpa 都是只包含一个 single page 的，而 writepages rbtree 中的 old_wpa 则是可以包含多个 page 的

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            fuse_writepages_fill
                ...
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # try to insert this fuse_writepage_args (wpa) into fuse_inode's writepages rbtree
                        # if there's already one (old) wpa in writepages rbtree
                            # insert current (new) wpa into old_wpa->next as a secondary wpa
                ...
```


之后等到 old_wpa 描述的 FUSE_WRITE 请求完成的时候，才会下发 secondary wpa 描述的回写操作，下发对应的 FUSE_WRITE 请求

```
fuse_writepage_end
    # erase current wpa (old_wpa) from writepages rbtree
    
    # insert secondary wpa (old_wpa->next) into writepages rbtree
    fuse_insert_writeback
    
    # send this secondary wpa
    fuse_send_writepage
```


同时在下发回写操作，在将当前回写请求 (wpa) 添加到 writepages rbtree 的过程中，如果当前 writepages rbtree 中已经存在回写同一个文件区间的 old_wpa，同时这个 old_wpa->next 链表中也已经存在写同一个 page 的 secondary wpa，那么直接将已有的 secondary wpa 中的 page 描述符替换为当前下发的 wpa 需要回写的 page 描述符

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            fuse_writepages_fill
                ...
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # try to insert this fuse_writepage_args (wpa) into fuse_inode's writepages rbtree
                        # if there's already one (old) wpa in writepages rbtree
                            # if there's already one secondary wap (tmp_wpa) in old_wpa->next list
                                # directly swap page to existed secondary wpa
                                swap(tmp.pages[0], new_wpa.pages[0]);
                ...
```

所以同一个 page 最多只能有一个 secondary wpa，但是由于 writepages rbtree 中的 old_wpa 是可以包含多个 page 的，因而 old_wpa->next 链表中可以包含多个 secondary wpa（其中的每个 secondary wpa 回写的 page index 都是唯一的）


##### writepage request bouncing

一些操作过程中需要 freeze writeback 以防止下发新的 FUSE_WRITE 请求，例如 direct IO 过程中要求等待之前的 writepages request 都完成之后，才能下发 direct IO 对应的 FUSE_WRITE 请求，其实现就是将 fuse writeback freeze 以后，等待所有之前的 writepages request 完成

```
fuse_direct_io
    # Prevent concurrent writepages on inode
    fuse_sync_writes
        # Wait for all pending writepages on the inode to finish
        # This is currently done by blocking further writes with FUSE_NOWRITE
        # and waiting for all sent writes to complete.
        fuse_set_nowrite
```

因而引入 writectr 字段来描述该 fuse 文件是否处于 writeback freeze 状态 (commit 3be5a52b30aa ("fuse: support writable mmap"))

- writectr >= 0 时描述 unfreeze 状态
- writectr 为负 (在原有 writectr 上加一个负的 FUSE_NOWRITE bias) 时描述 freeze 状态

```c
struct fuse_inode {
		/* Number of sent writes, a negative bias
		 * (FUSE_NOWRITE) means more writes are blocked */
		int writectr;
		...
}
```

因而上述 direct IO 过程中就是将 writectr 加上一个负的 FUSE_NOWRITE 偏移，从而令 writectr 变为负数

```
fuse_direct_io
    fuse_sync_writes
        fuse_set_nowrite
            fi->writectr += FUSE_NOWRITE
```

而 writeback 那边也只有 writectr 非负，即该 fuse 文件处于 unfreeze 状态时，才会下发该 fuse 文件的 writepages request，即下发回写对应的 FUSE_WRITE 请求

```
fuse_writepages
    write_cache_pages
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            if fi->writectr >= 0:
                # for each writepages request (wpa):
                    fuse_send_writepage(..., wpa, ...)
                        fuse_simple_background // send FUSE_WRITE request
        
```

因而也必须提供一种对 writepages request 的缓存机制，使得对应的 fuse 文件处于 freeze 状态 (writectr 为负) 时，能够缓存 writeback 下发下来的 writepages request

此时 fuse inode 的 queued_writes 链表即用于缓存这些 writepages request

```c
struct fuse_inode {
		/* Writepages pending on truncate or fsync */
		struct list_head queued_writes;
		...
}
```

实际上 writeback 下发 writepages request 的过程中，无论 fuse 文件是否处于 freeze 状态，默认都是先将 writepages request 添加到 queued_writes 链表中；后面 writectr 检查通过开始下发这个 writepages request 的时候，就会将 writepages request 从 queued_writes 链表中移除

```
fuse_writepages
    write_cache_pages
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            if fi->writectr >= 0:
                # for each writepages request (wpa):
                    # remove this FUSE_WRITE request from queued_writes list
                    fuse_send_writepage(..., wpa, ...)
                        fuse_simple_background // send FUSE_WRITE request
        
```

而除了控制 writepages freeze 的机制 (writectr)、以及 writepages freeze 状态下缓存 writepages request 的链表 (queued_writes) 以外，考虑到上面介绍的 direct IO 过程中需要同步等待之前的 writepages request 都完成，因而还需要一个 page_waitq waitqueue 来实现两者之间的同步

```c
struct fuse_inode {
		/* Waitq for writepage completion */
		wait_queue_head_t page_waitq;
		...
}
```

direct IO 过程中在操作 writectr 从而将该文件标记为 freeze 之后，就会睡眠等待在 page_waitq waitqueue 上，以等待所有的 writepages request 完成

```
fuse_direct_io
    fuse_sync_writes
        fuse_set_nowrite
            wait_event(fi->page_waitq, fi->writectr == FUSE_NOWRITE)
```