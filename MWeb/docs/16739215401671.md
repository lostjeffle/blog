title:'FUSE - IO - Buffer IO'
## FUSE - IO - Buffer IO

"cache=auto|always + Buffer IO" 模式下就会走 buffer IO 路径


### Buffer READ

```sh
f_op->read_iter(), i.e. fuse_file_read_iter()
    fuse_cache_read_iter
        generic_file_read_iter
            filemap_read
                filemap_get_pages
                    filemap_get_read_batch // find page cache
                    filemap_create_folio // create new page cache if not exist
                    if !PageUptodate(page):
                        filemap_update_page
                            filemap_read_page
                                a_ops->readpage(), i.e. fuse_readpage()
                                    fuse_do_readpage
                                        # send FUSE_READ request
                
                # copy data to page cache
```


### Buffer WRITE

fuse 的 buffer write 有两种模式，writethrough 和 writeback

fuse_conn 的 @writeback_cache 标志位描述当前 fuse 文件系统是采用 writethrough 还是 writeback 模式

fuse server/client 可以在 FUSE_INIT 阶段进行协商，如果采用 writeback 模式，那么 fuse server 需要将 @fuse_init_out.flags 字段设置上 FUSE_WRITEBACK_CACHE 标志，否则就采用 writethrough 模式，这也是默认的模式

```c
struct fuse_conn {
	/** write-back cache policy (default is write-through) */
	unsigned writeback_cache:1;
	...
}
```


#### writethrough

writethrough 模式下执行 buffer write 的时候，1)在将数据写入 page cache 之后，2)会立即发起 FUSE_WRITE 请求，将这些写入的 page cache 回写到后端

```sh
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        fuse_perform_write
            # write page cache
            fuse_fill_write_pages
                page = grab_cache_page_write_begin() // find page cache
                # copy data to page cache
            
            # send FUSE_WRITE request (writeback page cache)
            fuse_send_write_pages
```


#### writeback

writeback 模式下执行 buffer write 的时候，只是将数据写入 page cache

```sh
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        generic_file_write_iter      
            generic_perform_write
                a_ops->write_begin() // find page cache
                # copy data to page cache
                a_ops->write_end() // mark page cache and inode as dirty
```


之后在 writeback 的时候再发起 FUSE_WRITE 请求，将这些 dirty page cache 回写到后端

```sh
__writeback_single_inode
    do_writepages
        a_ops->writepages(), i.e., fuse_writepages
            # send FUSE_WRITE request
```


writeback 模式下，文件被 close 之后就会对文件的数据 (dirty page cache) 和元数据 (inode) 发起回写操作，也就是实现所谓的 flush-on-close 语义，即确保文件被 close 之后，fuse client 对文件的所有修改 (包括数据和元数据) 都已经下刷到 fuse server

```
# close(2)
filp_close
    f_op->flush(), i.e. fuse_flush()
        # if writeback mode and !(ff->open_flags & FOPEN_NOFLUSH):
            fuse_do_flush
                write_inode_now
                    writeback_single_inode
                        do_writepages
                            # data writeback
                            a_ops->writepages(), i.e., fuse_writepages()
                                # send FUSE_WRITE request
                            
                            # metadata writeback
                            a_ops->write_inode(), i.e. fuse_write_inode()
                                fuse_flush_times
                                    # send FUSE_SETATTR request, updating mtime/ctime
```

这里需要注意的是，在下刷元数据的时候，在下发的 FUSE_SETATTR 请求中只会申请下刷 fuse client 中维护的 mtime/ctime 版本，而不会申请下刷 size；这是因为之前通过 FUSE_WRITE 请求下刷 dirty data 的时候，fuse server 对文件执行写入操作的时候，文件的 size 自然就会保持更新；但是在 fuse server 对文件的写入操作结束后，文件的 mtime/ctime 是 fuse server 侧执行写入操作时自动更新的时间戳，因而必须通过 fuse client 下发的 FUSE_SETATTR 请求，更新为 fuse client 中维护的 mtime/ctime 版本


##### temp page design

上述介绍到，writeback 流程中实际上是调用 a_ops->writepages() 即 fuse_writepages() 完成回写操作

FUSE 的 writeback 逻辑 (commit [3be5a52b30aa ("fuse: support writable mmap")](https://github.com/torvalds/linux/commit/3be5a52b30aa)) 引入了 temp page 的设计，即 fuse 的 writeback 过程中，实际会分配一个额外的临时 page，将需要回写的 dirty page 的内容拷贝到新分配的临时 page 中，后续实际上是针对这个临时 page 发送 FUSE_WRITE 请求，以执行回写操作。

这是考虑到以下两点因素

首先 fuse daemon 在处理内核 writeback 下发的 FUSE_WRITE 请求的过程中，如果依赖一些资源（例如内存），而这些资源又依赖 fuse 文件系统的 writeback 操作完成，例如 fuse daemon 在处理 FUSE_WRITE 请求过程中需要申请内存分配，申请内存分配过程中可能触发了 direct memory reclaim 从而触发了 fuse 文件系统的 writeback 操作，从而形成 deadlock

另外一方面，一个实现不佳的甚至恶意的 fuse daemon 完全有可能导致回写下发的 FUSE_WRITE 请求迟迟无法完成并返回，从而使得系统中另一个不相关的进程发起的操作发生 halt。例如系统中一个进程发起的操作 sync 操作就会触发 fuse 文件系统的 writeback 操作，并在发起 sync 操作的进程上下文中阻塞等待回写的完成。此时如果 fuse daemon 在处理 FUSE_WRITE 请求的过程中迟迟无法完成，就会导致 sync 进程发生 halt

```
ksys_sync
    for each superblock
        sync_inodes_sb
            # initiate a writeback work
            		.reason               = WB_REASON_SYNC,
            		.sync_mode            = WB_SYNC_ALL,
            		.for_sync             = 1

wb_writeback
    writeback_sb_inodes
        __writeback_single_inode
            do_writepages // start writeback
            if wbc->sync_mode == WB_SYNC_ALL:
                filemap_fdatawait
                    # wait for all pages getting PG_writeback cleared
```

上述 sync 进程在等待 fuse writeback 下发的 IO 完成的过程中，实际上是等待 dirty page 的 PG_writeback 标志被清除（dirty page 的 writeback IO 完成的时候，就会移除 PG_writeback 标志）

因而 fuse writeback 的 temp page 的设计就是在下发 writeback 的时候，实际分配一个额外的临时 page，将需要回写的 dirty page 的内容拷贝到新分配的临时 page 中，后续实际上是针对这个临时 page 发送 FUSE_WRITE 请求，以执行回写操作；而真正的 dirty page 则在发起 FUSE_WRITE 请求之后，立即清除 address space (xarray) 的  PAGECACHE_TAG_WRITEBACK tag 与这个真正的 dirty page 的 PageWriteback 标记，这样 sync 进程就认为 fuse 的 writeback 已经完成了，而不会阻塞在这里

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            fuse_writepages_fill
                # allocate temp page to hold the dirty data
                tmp_page = alloc_page(GFP_NOFS | __GFP_HIGHMEM)
                
                # allocate struct fuse_writepage_args (wpa)
                # init FUSE_WRITE request with allocated temp page
                
                # copy data in original dirty page to temp page
                
                # inc wb WB_WRITEBACK counter
                inc_wb_stat(&inode_to_bdi(inode)->wb, WB_WRITEBACK);
                
                # inc global NR_WRITEBACK_TEMP counter
                inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP)
                
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # insert this fuse_writepage_args (wpa) into fuse_inode's writepages rbtree
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            # for each wpa in fuse_inode's queued_writes list
                fuse_send_writepage(..., wpa, ...)
                    fuse_simple_background // send FUSE_WRITE request
        
        # for each original page in this wpa
            end_page_writeback()
                # clear PG_writeback of this page
                # clear PAGECACHE_TAG_WRITEBACK tag of this page in its address space
```

当 FUSE_WRITE request 完成的时候，就会调用相应的 .end() 回调函数，即 fuse_writepage_end()

```
fuse_writepage_end
    # delete this wpa (fuse_writepage_args) from fuse_inode's writepages rbtree
    
    fuse_writepage_finish
        # for each temp page in this wpa
            # dec wb WB_WRITEBACK counter
            dec_wb_stat(&bdi->wb, WB_WRITEBACK)
            
            # dec global NR_WRITEBACK_TEMP counter
            dec_node_page_state(ap->pages[i], NR_WRITEBACK_TEMP);
            
            # inc wb's and global writeout completion counter
            wb_writeout_inc(&bdi->wb)
```

但是在回写下发的 FUSE_WRITE 请求真正完成之前，后续对同一 page cache 的写操作都会阻塞，从而防止同一个 page cache 产生多个的 temp page 从而在内存资源层面进行 DoS 攻击


##### writepages rbtree

尽管上述流程中，在将需要回写的 original dirty page 的内容拷贝到新分配的临时 page 中，并对这个临时 page 发送 FUSE_WRITE 请求之后，真正的 original page 就会立即清除 PageWriteback tag，但是在这个 FUSE_WRITE 请求完成之前，对同一个 page 的写操作也不能并发进行，这一写操作必须等待之前的 FUSE_WRITE 请求完成，即回写完成之后才能继续进行。

为了判断当前需要写入的 page cache 是否存在之前未完成的回写请求，就必须对尚未完成的 inflight writepage request 进行缓存，以方便查询

因而使用 struct fuse_writepage_args 来抽象一个 writepages request

```c
struct fuse_writepage_args {
	struct fuse_io_args ia;
	struct fuse_writepage_args *next;
	struct inode *inode;
	...
};
```

并通过 fuse_inode 的 writepages rbtree 组织该文件的所有 writepages request (包括 pending 状态等待发送、以及已发送但尚未完成的 writepages request)，该 writepages request 需要回写的 file offset 作为该 rbtree 的 index

```c
struct fuse_inode {
		/* List of writepage requestst (pending or sent) */
		struct rb_root writepages;
		...
}
```


回到 writeback 模式下的 buffer write 路径中，会在持有 page lock 的情况下，检查 fuse_inode 的 writepages rbtree 中是否有当前需要写入的 page 对应的 wpa，若存在则说明该 page 对应的文件偏移位置处当前正存在回写任务，因而当前的写操作需要等待该回写任务完成才能继续进行

```
f_op->write_iter(), i.e. fuse_file_write_iter()
    fuse_cache_write_iter
        generic_file_write_iter      
            generic_perform_write
                a_ops->write_begin(), i.e. fuse_write_begin()
                    # find corresponding page
                    page = grab_cache_page_write_begin()
                        pagecache_get_page(..., FGP_WRITEBEGIN, ...)
                            __filemap_get_folio
                                # find folio at specified index
                                if fgp_flags & FGP_LOCK:
                                    folio_lock(folio)
                
                    fuse_wait_on_page_writeback
                        fuse_page_is_writeback
                            fuse_range_is_writeback
                                # find if existing wpa in fuse_inode's writepages rbtree
```

```c
#define FGP_WRITEBEGIN		(FGP_LOCK | FGP_WRITE | FGP_CREAT | FGP_STABLE)
```

而 writeback 过程中，将 wpa 添加到 fuse_inode 的 writepages rbtree 全程都是持有对应 original page 的 page lock 的

```
fuse_writepages
    write_cache_pages
        # find all dirty pages to be written back in specified range,
        # for each found page
            folio_lock(folio);
            fuse_writepages_fill
                ...
                fuse_writepage_add(wpa, page)
                    fuse_insert_writeback
                        # insert this fuse_writepage_args into fuse_inode's writepages rbtree
                ...
            folio_unlock(folio)
```


##### writepage request bouncing

一些操作过程中需要 freeze writeback 以防止下发新的 FUSE_WRITE 请求，例如 direct IO 过程中要求等待之前的 writepages request 都完成之后，才能下发 direct IO 对应的 FUSE_WRITE 请求，其实现就是将 fuse writeback freeze 以后，等待所有之前的 writepages request 完成

```
fuse_direct_io
    # Prevent concurrent writepages on inode
    fuse_sync_writes
        # Wait for all pending writepages on the inode to finish
        # This is currently done by blocking further writes with FUSE_NOWRITE
        # and waiting for all sent writes to complete.
        fuse_set_nowrite
```

因而引入 writectr 字段来描述该 fuse 文件是否处于 writeback freeze 状态

- writectr >= 0 时描述 unfreeze 状态
- writectr 为负 (在原有 writectr 上加一个负的 FUSE_NOWRITE bias) 时描述 freeze 状态

```c
struct fuse_inode {
		/* Number of sent writes, a negative bias
		 * (FUSE_NOWRITE) means more writes are blocked */
		int writectr;
		...
}
```

因而上述 direct IO 过程中就是将 writectr 加上一个负的 FUSE_NOWRITE 偏移，从而令 writectr 变为负数

```
fuse_direct_io
    fuse_sync_writes
        fuse_set_nowrite
            fi->writectr += FUSE_NOWRITE
```

而 writeback 那边也只有 writectr 非负，即该 fuse 文件处于 unfreeze 状态时，才会下发该 fuse 文件的 writepages request，即下发回写对应的 FUSE_WRITE 请求

```
fuse_writepages
    write_cache_pages
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            if fi->writectr >= 0:
                # for each writepages request (wpa):
                    fuse_send_writepage(..., wpa, ...)
                        fuse_simple_background // send FUSE_WRITE request
        
```

因而也必须提供一种对 writepages request 的缓存机制，使得对应的 fuse 文件处于 freeze 状态 (writectr 为负) 时，能够缓存 writeback 下发下来的 writepages request

此时 fuse inode 的 queued_writes 链表即用于缓存这些 writepages request

```c
struct fuse_inode {
		/* Writepages pending on truncate or fsync */
		struct list_head queued_writes;
		...
}
```

实际上 writeback 下发 writepages request 的过程中，无论 fuse 文件是否处于 freeze 状态，默认都是先将 writepages request 添加到 queued_writes 链表中；等待 writepages request 完成，即 FUSE_WRITE reply 的时候，才会将 writepages request 从 queued_writes 链表中移除

```
fuse_writepages
    write_cache_pages
    
    fuse_writepages_send
        # add this wpa (fuse_writepage_args) into fuse_inode's queued_writes list
        
        fuse_flush_writepages
            if fi->writectr >= 0:
                # for each writepages request (wpa):
                    fuse_send_writepage(..., wpa, ...)
                        fuse_simple_background // send FUSE_WRITE request
        
```

而除了控制 writepages freeze 的机制 (writectr)、以及 writepages freeze 状态下缓存 writepages request 的链表 (queued_writes) 以外，考虑到上面介绍的 direct IO 过程中需要同步等待之前的 writepages request 都完成，因而还需要一个 page_waitq waitqueue 来实现两者之间的同步

```c
struct fuse_inode {
		/* Waitq for writepage completion */
		wait_queue_head_t page_waitq;
		...
}
```

direct IO 过程中在操作 writectr 从而将该文件标记为 freeze 之后，就会睡眠等待在 page_waitq waitqueue 上，以等待所有的 writepages request 完成

```
fuse_direct_io
    fuse_sync_writes
        fuse_set_nowrite
            wait_event(fi->page_waitq, fi->writectr == FUSE_NOWRITE)
```