title:'Lock - 03 qspinlock'
## Lock - 03 qspinlock


每个 MCS lock 节点需要占用两个 u32，以及一个额外的指针指向链表的尾部节点，而一个 ticket spinlock 则只需要占用一个 u32，将原本的 ticket spinlock 升级为 MCS lock，一个是会增大内存占用，另一个是很多内嵌 spinlock 的结构体的内存布局无法改变，因而就需要对 MCS lock 进行一定的改造，将其塞到一个 u32 中，这也就是 qspinlock (queue spinlock)


### Concept

#### per-CPU mcs nodes

```c
/*
 * Per-CPU queue node structures; we can never have more than 4 nested
 * contexts: task, softirq, hardirq, nmi.
 *
 * Exactly fits one 64-byte cacheline on a 64-bit architecture.
 *
 * PV doubles the storage and uses the second cacheline for PV state.
 */
static DEFINE_PER_CPU_ALIGNED(struct mcs_spinlock, mcs_nodes[MAX_NODES]);
```


qspinlock 中每个 CPU 都会维护一个预分配的 mcs_spinlock 数组，每个数组包含 4 个 mcs_spinlock，这是因为 CPU context 会嵌套，因而一个 CPU 可以同时获取多个 spinlock，例如 normal->softirq->hardirq->nmi(non-maskable interrupt) 的过程中，一个 CPU 最多可以同时获取 4 个 spinlock

```c
#define MAX_NODES	4
```


#### qspinlock

qspinlock 的定义为

```c
typedef struct qspinlock {
	union {
		atomic_t val;

		/*
		 * By using the whole 2nd least significant byte for the
		 * pending bit, we can allow better optimization of the lock
		 * acquisition for the pending bit holder.
		 */
#ifdef __LITTLE_ENDIAN
		struct {
			u8	locked;
			u8	pending;
		};
		struct {
			u16	locked_pending;
			u16	tail;
		};
#else
		...
#endif
	};
} arch_spinlock_t;
```

在 LITTLE_ENDIAN 下其内存布局为

![](media/16082953878204/15845112157787.jpg)


```c
/*
 * Bitfields in the atomic value:
 *
 * When NR_CPUS < 16K
 *  0- 7: locked byte
 *     8: pending
 *  9-15: not used
 * 16-17: tail index
 * 18-31: tail cpu (+1)
 *
 * When NR_CPUS >= 16K
 *  0- 7: locked byte
 *     8: pending
 *  9-10: tail index
 * 11-31: tail cpu (+1)
 */
```

@locked byte 字段相当于 MCS lock 中的 locked 字段，虽然占用 8 bit，但实际上只需要标识 0 和 1


MCS lock 中使用一个指针来描述链表中的尾部节点，但是由于 qspinlock 中所有节点实际上是在 per-CPU array 中的，因而实际上可以用 index 来标识链表尾部节点的位置

此时链表尾部节点的位置实际上就是 tail cpu 上的 mcs_nodes[tail index]，这里的 tail cpu 从 1 开始计数，tail index 从 0 开始计数


#### qspinlock status

通常使用以下三元组描述 qspinlock 的当前状态

(queue tail, pending bit, locked byte)

其中 queue tail 由 (tail cpu, tail index) 二元组描述


### routine

#### init

刚初始化时，qspinlock 的所有字段的值均为 0，此时三元组的值为 (0, 0, 0)


#### CPU 1 lock (uncontended)

当第一个 CPU 即 CPU 1 试图获取锁时，检查到三元组的值为 (0, 0, 0)，则说明此时 qspinlock 处于空闲状态，因而当前 CPU 可以立即获得锁，此时会走 fastpath，即 queued_spin_lock()

其中会将 qspinlock 的 locked byte 字段设置为 1，此时三元组更新为 (0, 0, 1)


#### CPU 2 lock (pending)

之后当另一个 CPU 试图获取锁时，由于此时三元组的值为 (0, 0, 1)，说明此时该 qspinlock 已经被其他 CPU 占用，此时都会走 slowpath 即 queued_spin_lock_slowpath()

例如当 CPU 2 试图获取锁时，会将 qspinlock 的 pending bit 置为 1，此时三元组更新为 (0, 1, 1)

之后 CPU 2 即自旋等待 qspinlock 的 locked byte 字段清为 0

```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	
	/*
	 * trylock || pending
	 *
	 * 0,0,0 -> 0,0,1 ; trylock
	 * 0,0,1 -> 0,1,1 ; pending
	 */
	val = queued_fetch_set_pending_acquire(lock);

	/*
	 * We're pending, wait for the owner to go away.
	 *
	 * 0,1,1 -> 0,1,0
	 *
	 * this wait loop must be a load-acquire such that we match the
	 * store-release that clears the locked bit and create lock
	 * sequentiality; this is because not all
	 * clear_pending_set_locked() implementations imply full
	 * barriers.
	 */
	if (val & _Q_LOCKED_MASK)
		atomic_cond_read_acquire(&lock->val, !(VAL & _Q_LOCKED_MASK));

	...
}
```


#### CPU 3 lock (uncontended queue)

之后当另一个 CPU 即 CPU 3 试图获取锁时，此时由于 locked byte 与 pending bit 都已经被占用，只好分配一个 mcs node，其对应的 mcs node 位于对应的 tail CPU 上的 mcs_nodes[tail index] 处

同时将当前的 queue tail 编码，即 (tail CPU, tail index) 保存在 qspinlock 的 tail CPU 和 tail index 字段，此时三元组更新为 (*, 1, 1)

之后就自旋等待 qspinlock 的 locked byte 与 pending bit 都变为 0

```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	
	/*
	 * If we observe any contention; queue.
	 */
	if (val & ~_Q_LOCKED_MASK)
		goto queue;

	...
queue:
	val = atomic_cond_read_acquire(&lock->val, !(VAL & _Q_LOCKED_PENDING_MASK));

	...
}
```


#### CPU 4 lock (contended queue)

之后当另一个 CPU 即 CPU 4 试图获取锁时，同样需要自己分配一个 mcs node，将其添加到 mcs node 链表中，并将 qpinlock 的 tail CPU 和 tail index 字段更新为当前 CPU 对应的 queue tail 编码，此时三元组更新为 (*, 1, 1)

之后就自旋等待其对应的 mcs_spinlock 的 locked 字段变为 1

```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	
	/*
	 * If we observe any contention; queue.
	 */
	if (val & ~_Q_LOCKED_MASK)
		goto queue;

	...
queue:
	val = atomic_cond_read_acquire(&lock->val, !(VAL & _Q_LOCKED_PENDING_MASK));

	/*
	 * if there was a previous node; link it and wait until reaching the
	 * head of the waitqueue.
	 */
	if (old & _Q_TAIL_MASK) {
		arch_mcs_spin_lock_contended(&node->locked);
	}

	...
}
```


#### CPU 1 unlock

> CPU 1 unlock

当 CPU 1 释放锁时，只需要将 qspinlock 的 locked byte 字段清为 0，此时三元组更新为 (*, 1, 0)


> CPU 2 acquire lock

之前 CPU 2 都在自旋等待 qspinlock 的 locked byte 字段清为 0，此时 CPU 2 就会获得锁，并将 locked byte 字段设置为 1，将 pending bit 清为 0，此时三元组更新为 (*, 0, 1)

```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	/*
	 * take ownership and clear the pending bit.
	 *
	 * 0,1,0 -> 0,0,1
	 */
	clear_pending_set_locked(lock);
	qstat_inc(qstat_lock_pending, true);
	return;	
}
```


#### CPU 2 unlock

> CPU 2 unlock

当 CPU 2 释放锁时，将 qspinlock 的 locked byte 字段清为 0，此时三元组更新为 (*, 0, 0)


> CPU 3 acquire lock

之前的 CPU 3 都在自旋等待 qspinlock 的 locked byte 与 pending bit 都变为 0，此时 CPU 3 就会获得锁，此时将 qspinlock 的 locked byte 字段设置为 1，此时三元组更新为 (*, 0, 1)

同时将 mcs_spinlock 链表中的下一个节点即 CPU 4 对应的 mcs_spinlock 的 locked 字段设置为 1


```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	
	/* Either somebody is queued behind us or _Q_PENDING_VAL is set */
	set_locked(lock);

	/*
	 * contended path; wait for next if not observed yet, release.
	 */
	if (!next)
		next = smp_cond_load_relaxed(&node->next, (VAL));

	arch_mcs_spin_unlock_contended(&next->locked);
	...
}
```


> CPU 4 forward waiting

之前 CPU 4 都在自旋等待其对应的 mcs_spinlock 的 locked 字段变为 1，因而此时 CPU 4 会退出在对应的 mcs_spinlock 上的自旋，转而自旋等待 locked byte 与 pending bit 都变为 0

```c
void queued_spin_lock_slowpath(struct qspinlock *lock, u32 val)
{
	...
	
	val = atomic_cond_read_acquire(&lock->val, !(VAL & _Q_LOCKED_PENDING_MASK));
	
	...
}
```


#### CPU 3 unlock

> CPU 3 unlock

当 CPU 3 释放锁时，将 qspinlock 的 locked byte 字段清为 0，此时三元组更新为 (*, 0, 0)

> CPU 4 acquire lock

之前 CPU 4 都在自旋等待 qspinlocked 的 locked byte 与 pending bit 都变为 0，此时 CPU 4 就会获取锁，同时将 qspinlock 的 locked byte 字段设置为 1，此时三元组更新为 (*, 0, 1)


#### CPU 4 unlock

当 CPU 4 释放锁时，将 qspinlock 的 locked byte 字段清为 0，此时三元组更新为 (*, 0, 0)


#### summary

如果尝试获取锁的 CPU 数量小于等于 2，那么只需要一个 4 字节的 qspinlock 就够了，此时

- 第一个尝试获取锁的 CPU 需要占有 locked byte 字段
- 而第二个尝试获取锁的 CPU 则需要标记 pending bit 字段，同时在 locked byte 上自旋等待

此时 qspinlock 实际上等同于 ticket spinlock，此时仍然存在 cache line 刷新，但是由于此时尝试获取锁的 CPU 数量最大为 2，因而这里的 cache line 刷新操作实际上是有意义的


之后当第三个及之后的 CPU 试图获取锁时，就需要在 qspinlock 之外单独获取一个对应的 MCS node，所有这些 MCS node 会组成一个链表，其中

- 链表头的 MCS node 会自旋等待 locked byte 与 pending bit 都变为 0
- 其余的 MCS node 会自旋等待当前 MCS node 的 locked 字段变为 1（MCS node 的 locked 字段的初始值为 0，当 MCS node 链表中的一个 node 释放锁时，就会将其下一个 node 的 locked 字段设置为 1）

此时对于 N 个 CPU，其内存占用为一个 qspinlock 加上 (N-2) 个 MCS node

此时 qspinlock 就会转而使用 MCS lock，从而避免了 cache bouncing 的影响，因而 qspinlock 具有非常好的可扩展性
