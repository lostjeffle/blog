## Writeback - 4 Dirty Throttle


系统中 dirty page 的水平不能太高，因而内核中有好几个入口会发起 writeback 操作，其中一个入口是进程执行 page cache write routine 中，需要检查当前系统中所有 dirty page 的数量是否超过阈值，如果超过阈值，那么当前进程上下文就会停止当前的写操作，转而发起 writeback 操作，这一过程称为 dirty throttle


### Classic Dirty Throttle

在 v3.1 及其之前版本，采用的算法非常简单，即系统中 dirty page 的水平超过某个阈值时，就会发生 dirty throttle

```
                             |
              free run area  |  throttle area
-----------------------------+---------------------------->
                       thresh^                  dirty pages
```

这个阈值由以下两个参数决定
`thresh = (dirty_background_thresh + dirty_thresh) / 2)`

```            
  free run   |   free run    | soft throttle | hard throttle
-------------+---------------+---------------+------------>
             ^               ^               ^          dirty pages
dirty_background_thresh     thresh          dirty_thresh
```

这一算法的设计原理是

1. free run area

如果当前系统中 dirty page 的水平超过了 dirty_background_thresh，但是还没有超过 thresh，那么考虑到系统会时不时地发起 background writeback 操作，因而此时可以先不发起 writeback 操作，寄希望于后台的 background writeback 操作可以追上生产 dirty page 的速度；这样可以减小 small-write dirty throttle 毛刺

2. soft throttle area

如果当前系统中 dirty page 的水平超过了 thresh，但是还没有超过 dirty_thresh，那么此时会检查当前写操作对应的 blkdev 设备的 dirty page 的水平是否超过了 dirty_thresh 中该设备对应的配额，超过的时候就会发生 dirty throttle

特定 blkdev 设备的 dirty_thresh 阈值的计算方法为

- writeback 框架维护一个全局的 @writeout_completions 计数，描述截止当前系统中所有 gendisk 完成回写的 dirty page 的数量
- 同时每个 gendisk 的 bdi 中维护一个本地的 @completions 计数，描述截止当前该 gendisk 完成回写的 dirty page 的数量
- 因而将 gendisk 的 @completions 计数除以全局的 @writeout_completions 计数，再乘以全局的 dirty_thresh，即得到该 gendisk 对应的 dirty_thresh 阈值，即经常执行回写操作同时回写速度快的 gendisk 设备具有更高的 dirty_thresh 阈值


3. hard throttle area

如果系统中 dirty page 的水平超过了 dirty_thresh 阈值，那么就会发生 dirty throttle



### IO-less Dirty Throttle

上述介绍的 Classic Dirty Throttle 算法，所有执行 page cache write 的进程都有可能进入 dirty throttle 流程，即多个进程上下文都会发起回写操作，这种算法存在以下缺陷

- 多个进程上下文发起回写操作，会加剧相关的锁竞争
- 多个进程上下文发起回写操作，每个进程都可能对一个 disk 上的一个文件执行回写操作，这样一个磁盘就会同时写多个文件，在 HDD 时代磁头就会剧烈抖动，导致磁盘性能下降

因而 吴峰光 (Fengguang Wu) 在 v3.2 版本合入的 IO-less Dirty Throttle 特性中，当发生 dirty throttle 时，当前进程上下文会发起 background writeback，之后进入 TASK_KILLABLE 状态睡眠一段时间，这样当前进程上下文不再直接执行回写操作，而是统一由 worker thread 执行回写，从而缩小了回写的并发度，缓解了以上问题


此外考虑到 dirty throttle 并不是用户期望的，因为 dirty throttle 会带来进程的停顿，因而 dirty throttle 更多是一种托底的方案，我们需要尽可能地减小 dirty throttle 发生的几率

虽然发生 dirty throttle 时候，当前进程上下文会发起 background writeback 操作，然而进程生产 dirty page 的速度仍然可能快于 background writeback 回写的速度，因而 IO-less Dirty Throttle 特性的思想就是，在发生 dirty throttle 的时候，在发起 background writeback 之后，当前进程上下文需要暂停写入（即进入 TASK_KILLABLE 状态睡眠）一段时间，从而抑制 dirty page 的产生，而这也正是 "IO-less" 名称的由来


#### setpoint

IO-less Dirty Throttle 算法中的一个重要概念是“平衡点”即 setpoint，这是考虑到系统中 dirty page 的水平不能太高，也不能太低，而是要维持在一个合理的水位即 setpoint

dirty page 的水平不能太高，如果太高那么文件写入的过程中就可能找不到 free page cache 可用，当然也不能太低，如果太低那么内存的使用率就会很低，无法充分发挥内存的能力，从而导致写入的带宽无法提升


其实 Classic Dirty Throttle 算法中也有类似的概念，例如

`free_run = (dirty_background_thresh + dirty_thresh) / 2)`

```            
-------------+---------------+---------------+------------>
             ^               ^               ^          dirty pages
dirty_background_thresh     free_run         dirty_thresh
```


IO-less Dirty Throttle 算法中的 setpoint 则是

`setpoint = (free_run + dirty_thresh) / 2)`

```
                                  setpoint
-------------+---------------+-------+-------+------------>
             ^               ^               ^          dirty pages
dirty_background_thresh     free_run         dirty_thresh
```


当系统中 dirty page 的水平维持在 setpoint 水位时，内核会控制用户进程生产 dirty page 的速度与 background writeback 回写的速度保持平衡，从而让系统中 dirty page 的水平一致维持在 setpoint 水位


#### dirty_ratelimit 

首先需要计算对于一个进程来说，进程以怎样的速度生产 dirty page，系统中 dirty page 的水平会保持不变，我们将这个速度称为 dirty_ratelimit

以下描述 dirty_ratelimit 计算公式的推导过程

首先以下公式不言自明，dirty_rate 表示生产 dirty page 的速度，write_bw 表示 dirty page 回写的速度，长期来看两者一定是相等的

```
dirty_rate == write_bw                                      (1)
```


task_ratelimit 表示每个进程生产 dirty page 的速度，假设当前系统中有 N 个进程在生产 dirty page，那么为了确保系统中 dirty page 的水平保持不变，task_ratelimit 有以下计算公式

```
task_ratelimit = balanced_dirty_ratelimit == write_bw / N   (2)
```


根据 (2) 可以得到以下变式，其中 dirty_rate 表示系统生产 dirty page 的速度

```
                            dirty_rate     write_bw
balanced_dirty_ratelimit =  ----------- * ----------        (3)
                                 N         dirty_rate
```


同时以下等式也是不言自明的

```
dirty_rate == N * task_ratelimit                            (4)         
```


将 (4) 代入 (3)，就可以得到

```
                                              write_bw
balanced_dirty_ratelimit =  task_ratelimit * ----------     (5)
                                              dirty_rate
```

将 (2) 代入 (5)，就可以得到

```
                              write_bw
balanced_dirty_ratelimit *=  ----------                     (6)
                              dirty_rate
```


也就是说虽然我们不知道进程中生产 dirty page 的进程的数量 N，但是最终我们可以用一种启发式的算法即等式 (6)，计算得到 balanced_dirty_ratelimit，即为了确保系统中 dirty page 的水平保持不变，每个进程生产 dirty page 的速度


上述等式 (6) 中有三个输入

- 上一个采样周期的 balanced_dirty_ratelimit，算法每隔 BANDWIDTH_INTERVAL 即 200ms 更新一次该数据，初始值是 task_ratelimit_0
- write_bw 即 dirty page 回写的速度，dirty_rate 即生产 dirty page 的速度，这两者都可以通过 dirty page 产生、回写过程中维护相应的计数器来进行计算


> write_bw (write bandwidth)

首先介绍 write_bw 的计算方法

之前我们讨论 dirty_rate == write_bw 时，系统中 dirty page 的水平可以保持不变，此时这两个参数包括系统中所有 disk 设备的 dirty page；但是 disk 的速度存在差异，如果只是维护整个系统的 dirty_rate/rite_bw 参数，就有可能因为速度快的 disk 设备占用了太多的带宽，而导致速度慢的 disk 设备反而被 throttle 了

因而为了不同 disk 设备之间的公平性，dirty_rate/rite_bw 参数都是 per-wb 范围的，即每个 disk 设备都会维护一组 dirty_rate/rite_bw 参数，例如 write_bw 就维护在 @wb->avg_write_bandwidth 中

```sh
balance_dirty_pages
    __wb_update_bandwidth
        wb_update_write_bandwidth
           elapsed = (jiffies - wb->bw_time_stamp) / HZ;
           written = percpu_counter_read(&wb->stat[WB_WRITTEN]) - wb->written_stamp;
           wb->avg_write_bandwidth = written / elapsed;
```

首先通过 (wb->stat[WB_WRITTEN] - wb->written_stamp) 获取当前这个采样周期中回写的 dirty page 的数量 (@wb->written_stamp 表示截止上一个采样周期 wb->stat[WB_WRITTEN] 计数的值)

之后通过 (jiffies - wb->bw_time_stamp) 计算当前这个采样周期已经过去的时间

以上两者相除，就得到截止当前这个采样周期 write_bw 的值


> dirty_rate

类似地，dirty_rate 的计算过程为

```sh
balance_dirty_pages
    __wb_update_bandwidth
        wb_update_dirty_ratelimit
            elapsed = (jiffies - wb->bw_time_stamp) / HZ;
            written = percpu_counter_read(&wb->stat[WB_DIRTIED]) - wb->dirtied_stamp;
            dirty_rate = dirtied / elapsed;
```


> balanced_dirty_ratelimit

类似地，balanced_dirty_ratelimit 保存在 wb->dirty_ratelimit 中

根据以下计算公式

```
                              write_bw
balanced_dirty_ratelimit *=  ----------                     (6)
                              dirty_rate
```

可以计算得到 balanced_dirty_ratelimit

```sh
balance_dirty_pages
    __wb_update_bandwidth
        wb_update_dirty_ratelimit
            elapsed = (jiffies - wb->bw_time_stamp) / HZ;
            written = percpu_counter_read(&wb->stat[WB_DIRTIED]) - wb->dirtied_stamp;
            wb->dirty_ratelimit *= write_bw / dirty_rate;
```


#### pos_ratio

以上计算得到的 balanced_dirty_ratelimit 只能确保系统中 dirty page 的水平保持不变

如果当前系统中 dirty page 的水平已经超过了 setpoint，那么当前可用的 dirty_ratelimit 配额需要小于 balanced_dirty_ratelimit，使得 dirty page 回写的速度大于产生的速度，从而让系统中 dirty page 的水平降至 setpoint 水位

类似地，如果当前系统中 dirty page 的水平在 setpoint 以下，那么当前可用的 dirty_ratelimit 配额可以大于 balanced_dirty_ratelimit，使得 dirty page 回写的速度小于产生的速度，从而让系统中 dirty page 的水平回升至 setpoint 水位

此时需要使用一个参数对上述计算的 balance_dirty_pages 进行修正，得到最后可用的 task_ratelimit，这个参数就称为 pos_ratio

```sh
balance_dirty_pages
    wb_position_ratio // calculate pos_ratio
    task_ratelimit = wb->dirty_ratelimit * pos_ratio;
```


正如之前描述的，pos_ratio 应该是一个随着当前系统中 dirty page 的水平而动态变化的函数

- 当前系统中 dirty page 的水平在 setpoint 时，pos_ratio 应该为 1，此时系统中 dirty page 产生和回写的速度相当，从而使得系统中 dirty page 的水平保持在 setpoint 水位
- 当前系统中 dirty page 的水平大于 setpoint 时，pos_ratio 应该小于 1，使得 dirty page 回写的速度大于产生的速度，从而降低系统中 dirty page 的水平；同时 dirty page 水平越大，斜率应该越大，即 pos_ratio 下降地越快，从而达到快速抑制 dirty page 水平的目的
- 类似地，当前系统中 dirty page 的水平小于 setpoint 时，pos_ratio 应该大于 1，使得 dirty page 回写的速度小于产生的速度，从而抬升系统中 dirty page 的水平；同时 dirty page 水平越小，斜率应该越大，即 pos_ratio 上升地越快，从而达到快速抬升 dirty page 水平的目的


因而我们就得到了以下 pos_ratio 曲线

```
    ^ pos_ratio
    |
    |            |<===== global dirty control scope ======>|
2.0 .............*
    |            .*
    |            . *
    |            .   *
    |            .     *
    |            .        *
    |            .            *
1.0 ................................*
    |            .                  .     *
    |            .                  .          *
    |            .                  .              *
    |            .                  .                 *
    |            .                  .                    *
  0 +------------.------------------.----------------------*------------->
          freerun^          setpoint^                 limit^   dirty pages
```

实际上，pos_ratio 曲线是一个三次多项式函数

```
                   setpoint - dirty 3
f(dirty) := 1.0 + (----------------)
                   limit - setpoint
```


根据以下公式

```
task_ratelimit = wb->dirty_ratelimit * pos_ratio;
```

得到了以下 task_ratelimit 曲线

```
  ^ task rate limit
  |
  |            *
  |             *
  |              *
  |[free run]      *      [smooth throttled]
  |                  *
  |                     *
  |                         *
  ..bdi->dirty_ratelimit..........*
  |                               .     *
  |                               .          *
  |                               .              *
  |                               .                 *
  |                               .                    *
  +-------------------------------.-----------------------*------------>
                          setpoint^                  limit^  dirty pages
```


最终经 pos_ratio 修正后得到的 task_ratelimit (即每个进程产生 dirty page 的速度) 有

```
task_ratelimit = (u64)dirty_ratelimit * pos_ratio >> RATELIMIT_CALC_SHIFT;
```


#### pause time

此时当前进程上下文需要暂停的时间即为

```
pause = HZ * pages_dirtied / task_ratelimit;
```

pages_dirtied 为 balance_dirty_pages() 传入的 @pages_dirtied 参数，即当前一次写操作需要写入的 dirty page 数量


之后当前进程上下文就会进入 TASK_KILLABLE 状态睡眠一段时间 (@pause)，睡眠结束后就会继续写入 dirty page

```sh
balance_dirty_pages
    for (;;) {
        pause = HZ * pages_dirtied / task_ratelimit;
        __set_current_state(TASK_KILLABLE);
        io_schedule_timeout(pause);
        
        if (task_ratelimit)
            break;
        ...
    }
```

#### refactored freerun

Classic Dirty Throttle 中介绍过，当系统中 dirty page 水平超过 thresh，但是尚未超过 dirty_thresh 时，会检查当前写操作对应的 disk 设备的 dirty page 的水平是否超过了 dirty_thresh 中该设备对应的配额，超过的时候就会发生 dirty throttle；此时使用 @completions 计数来计算特定的 disk 设备对应的 dirty_thresh 配额

而在 IO-less Dirty Throttle 算法中，只要系统中 dirty page 水平超过了 thresh，那么就会发生 dirty throttle，只是此时当前 wb (当前写入的文件所在的 disk 的 backing_dev_info->wb) 对应的 dirty_thresh 配额会参与上述 @pause 时间的计算，从而使得当前 wb 对应的 dirty_thresh 配额还有富余的时候，dirty throttle 暂停的时间短一些

此时也是用 @completions 计数来计算特定的 wb 对应的 dirty_thresh 配额，只是代码上有一些重构，此时

- @global_wb_domain->completions 计数保存全局的 @completions 计数，每个 dirty page 成功完成回写的时候，都会增加该计数
- 当前回写的文件所在的 wb 也就是每个 disk 设备对应的 wb 即 @backing_dev_info->wb->completions 计数，保存该 wb 自己的 @completions 计数，每个 dirty page 成功完成回写的时候，也会增加该计数

```sh
end_page_writeback
    test_clear_page_writeback
        __wb_writeout_inc
            wb_domain_writeout_inc(&global_wb_domain, &wb->completions, ...)
```


### Cgroup Writeback

在一开始每个 bdi 只有一个 wb，也就是内嵌在 bdi->@wb 字段的 wb，这个唯一的 wb 负责对应的 gendisk 下的所有 dirty inode 的回写

```c
struct backing_dev_info {
	struct bdi_writeback wb;  /* the root writeback info for this bdi */
	...
}
```

后来为了支持 cgroup writeback，wb 就变成了 per-cgroup 的概念，也就是每个 cgroup 都有一个对应的 wb，这样才实现了每个 cgroup 都可以独立执行回写操作

同时在支持 cgroup writeback 之后，还作了以下调整

#### freerun

在此之前 freerun 的区域为，当前系统中 global dirty page 的水平小于 global freerun 阈值

在支持 cgroup writeback 之后 freerun 的区域为

- 当前系统中 global dirty page 的水平小于 global freerun 阈值
- 同时当前进程所在的 cgroup 的 dirty page 的水平也小于该 cgroup 的 freerun 阈值

freerun 阈值的计算公式都是
`freerun = (dirty_background_thresh + dirty_thresh) / 2)`


#### @completion counter 

之前介绍过，IO-less Dirty Throttle 算法中，每个 disk 设备的 dirty page 的水平与该 disk 设备的 dirty_thresh 配额的比例，会影响 dirty throttle 中的 @pause 时间，disk 设备对应的 dirty_thresh 配额是通过相应的 @completions 计数计算的

@global_wb_domain->completions 计数保存全局的 @completions 计数；当前回写的文件所在的 wb 也就是每个 disk 设备对应的 wb 即 @backing_dev_info->wb->completions 计数，保存该 wb 自己的 @completions 计数；两者相除就得到了该 disk 设备在 dirty_thresh 中的配额


在支持 cgroup writeback 之后，wb 变成了 per-cgroup 的概念，此时每个 cgroup 会分配有一个 wb_domain 即 memcg->cgwb_domain，此时 memcg->cgwb_domain->completions 就保存该 cgroup 下全局（包含所有 disk 设备）的 @completions 计数；wb->memcg_completions 保存该 cgroup 下当前写入的文件所在的 disk 对应的 @completions 计数；

此时每个 dirty page 成功完成回写的时候，会增加以上这两个 @completions 计数

```sh
end_page_writeback
    test_clear_page_writeback
        __wb_writeout_inc
            wb_domain_writeout_inc(&global_wb_domain, &wb->completions, ...) # update global completions counter
            wb_domain_writeout_inc(&memcg->cgwb_domain, &memcg_wb->memcg_completions, ...) # update cgroup completions counter
```


#### pos_ratio

在支持 cgroup writeback 之后，不但会计算 global pos_ratio，还会计算 cgroup pos_ratio，取其中较小的那个作为最终使用的 pos_ratio

之前介绍过了 global pos_ratio 的计算公式与曲线，cgroup pos_ratio 的曲线则略有不同，此时 cgroup pos_ratio 是一个一次方程，同时最小值为 1/4

```
    ^ pos_ratio
    |
    |            *
    |              *
    |                *
    |                  *
    |                    * |<=========== span ============>|
1.0 .......................*
    |                      . *
    |                      .   *
    |                      .     *
    |                      .       *
    |                      .         *
    |                      .           *
    |                      .             *
    |                      .               *
    |                      .                 *
    |                      .                   *
    |                      .                     *
1/4 ...............................................* * * * * * * * * * * *
    |                      .                         .
    |                      .                           .
    |                      .                             .
  0 +----------------------.-------------------------------.------------->
                wb_setpoint^                    x_intercept^
```

```
x_intercept = bdi_setpoint + 8 * write_bw
```
