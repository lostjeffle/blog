title:'XArray - Locking'
## XArray - Locking


advancaed API 即 xas_\*() 接口都是没有锁保护的，而 normal API 即 xa\_*() 接口则在调用的 xas_\*() 接口的基础上封装了相应的锁保护

### locking between write operations

xas_store() 这类 write 操作的调用者必须使用 xarray 自身附带的 spinlock 进行锁保护，从而确保 write 类接口之间是完全互斥的

```c
struct xarray {
	spinlock_t	xa_lock;
	...
};
```

以 xa_store() 为例

```sh
xa_store
    xa_lock(xa);
    xas_store
    xa_unlock(xa);
```


### locking between read/write operations

advancaed API 即 xas_\*() 接口内部都是没有锁保护的，这些接口之间是完全并行的，而由于 xas_store() 这类 write 操作中有可能会删除 node (xas_store() 的 @entry 参数为 NULL 时相当于清空对应的 slot，当所在的 node 全空的时候，就会删除该 node 并释放该 node 占用的内存)，而 xas_load() 这类 read 操作则可能仍在引用这些已经删除了的 node

因而必须对 write 类操作中 “释放 node 占用的内存”，以及 read 类操作中 “对 node 的引用” 这两类操作进行保护，从而防止 read 类操作中对已经释放了的内存进行引用

#### strong locking (spinlock)

一种方式是类似地，xas_load() 和 xas_store() 的调用者都使用 spinlock 等锁机制，来确保 read/write 类接口之间是完全互斥的

例如可以使用 xarray 自身附带的 spinlock 进行锁保护

```
reader                              writer
=============                       ===============
    xa_lock(xa);                    xa_lock(xa);
    xas_load                        xas_store
    xa_unlock(xa);                  xa_unlock(xa);
```


#### weak locking (RCU)

上述锁机制可以确保 read/write 类接口之间的强互斥性，但是在高负载场景下会影响 xarray 的 read/write 性能，因而另一种方式是使用 RCU lock 对上述操作进行保护

> RCU locking

实际上 xas_store() 这类 write 操作已经内嵌了 RCU lock 保护，其中对 xarray 的任何修改都是通过 rcu_assign_pointer() 实现的

```sh
xas_store
    # for any write operation
    rcu_assign_pointer(*slot, entry)
```

xas_store() 在删除 node、并释放该 node 占用内存的时候，会使用 RCU lock 进行保护

```sh
xas_store
    update_node
        xas_delete_node
            # when node->count decreased to 0
            xa_node_free(node)
                call_rcu(&node->rcu_head, radix_tree_node_rcu_free)
```


此时 xas_load() 的调用者可以通过 RCU lock 进行保护，从而防止 xas_load() 执行过程中引用到已经释放了的内存

```sh
rcu_read_lock();
xas_load() // reading from xarray
rcu_read_unlock();
```

这样 xas_store() 在删除 node 的时候，并不会立即释放该 node 占用的内存，而是等到一个 RCU period 之后，即所有 reader 退出临界区 (调用 rcu_read_unlock()) 之后，才会真正释放 node 占用的内存


> XA_RETRY_ENTRY

之前介绍的 RCU locking 可以让 xarray 的 read/write 类操作并行执行的同时，防止 read 类操作引用到已经释放了的内存

但是 read/write 类操作并行执行的特性还会带来另一个问题，例如假设一个 xarray 只有一层，即 level 1 node

```
                        +-----------+
                        |   xarray  |
                        +-----------+
                              |
                              | xa_head
                              |
                        +-----------+
                        |   node    |
                        +-----------+
                         |      |
                slots[0] |      | slots[X]
                         |      |
                    entry A    entry B
```

接下来对 index X 处执行 xas_store(index X, NULL) 操作，即移除 entry B；此时 level 1 node 中只有 leftmost 的 slot 存储有有效值 (entry A)，而其他 slot 都为空

```
# after remove entry B
        
                        +-----------+
                        |   xarray  |
                        +-----------+
                              |
                              | xa_head
                              |
                        +-----------+
                        |   node    |
                        +-----------+
                         |      
                slots[0] |
                         |      
                    entry A
```

此时就会触发 shrinking 操作，即移除中间的 @node 节点，而使得 @xa_head 直接指向唯一的 entry A

```
# after shrinking

                        +-----------+
                        |   xarray  |
                        +-----------+
                              |
                              | xa_head
                              |
                            entry A
                              
                        +-----------+
                        |   node    |
                        +-----------+
                         |      
                slots[0] |
                         |
                    entry A     
                    
```

那么考虑以下时序，如果 xas_load() 在找到上述 node 之后，紧接着另一个进程执行的 xas_store() 触发了 shrinking 操作从而使得 node 被移除，而之后 xas_load() 返回的 xas 仍然指向这个被移除的 node

```
xas_load()                          xas_store()
# lookup entry A                    # remove entry B
=============                       ===============
xas_descend
    # find @node
                                    # remove @node
                                    # make xa_head pointing to entry A
return xas
# with xas->xa_node pointing to @node
```

虽然在 RCU lock 的保护下，xas_load() 的调用者在对返回的 xas->xa_node 进行引用的时候，并不会触发错误，同时 xas->xa_node 的 @slots[xas->xa_offset] 位置处存储的值仍然有效 (即 entry A)，但是此时 xarray 的结构毕竟已经发生了变化，返回的 xas 作为指向 xarray 的一个指针，其已然失效，例如对 xas_load() 返回的 xas 执行 xas_advance() 就会导致错误

因而 xas_store() 在触发上述操作的时候，必须通过某种方式通知 xas_load() 及其调用者，在具体实现中，上述 shrinking 操作过程中，xas_store() 在删除 node 节点的时候，会将 node 节点的 @slots[0] 设置为一个特殊的值 XA_RETRY_ENTRY，以通知 xas_load()

```
# after shrinking

                        +-----------+
                        |   xarray  |
                        +-----------+
                              |
                              | xa_head
                              |
                            entry A
                              
                        +-----------+
                        |   node    |
                        +-----------+
                         |      
                slots[0] |
                         |
                    XA_RETRY_ENTRY    
                    
```

```sh
xas_store
    update_node
        xas_delete_node
            xas_shrink
                entry = node->slots[0]
                xa->xa_head = entry
                
                node->slots[0] = XA_RETRY_ENTRY;
                xa_node_free(node)
                    call_rcu(&node->rcu_head, radix_tree_node_rcu_free);
```

这样 xas_load() 的调用者必须对 xas_load() 返回的结果进行检查，(通常是调用 xas_retry()) 如果最终返回的 entry 实际上是 XA_RETRY_ENTRY，就说明之前一轮 xas_load() 执行过程中并发执行的 write 操作，已经导致 xarray 的结构发生了变化；此时程序必须重新发起一轮新的 xas_load() 查找操作，从 xarray 树的顶点开始重新查找

以 xa_load() 为例，通过 RCU lock 对 xas_load() 进行保护时，常用的 coding pattern 为

```sh
xa_load
    rcu_read_lock();
    
    do {
        xas_load() // reading from xarray
    } while (xas_retry(&xas, entry))
    
    rcu_read_unlock();
```


### xa locking

xa_store()/xa_insert()/xa_reserve()/xa_erase()/xa_destroy() 这类 write 操作会使用 xarray 自身附带的 spinlock 进行锁保护

```c
struct xarray {
	spinlock_t	xa_lock;
	...
};
```

所以 write 类接口之间是完全互斥的


而 xa_load() 这类 read 接口则是使用 RCU lock 进行保护

```sh
xa_load
    rcu_read_lock();
    xas_load() // reading from xarray
    rcu_read_unlock();
```

之前介绍的 write 类接口对 xarray 的任何修改也都是通过 rcu_assign_pointer() 实现的

```sh
xa_store
    spin_lock(&xa_lock)
    xas_store
        # for any write operation
        rcu_assign_pointer(*slot, entry)
    spin_unlock(&xa_lock)
```

因而 read 类接口和 write 类接口之间是完全并行的


### locking and memory allocation

> first trying non-blocking memory allocation

如上所述，xa_store() 在执行过程中会上锁，因而执行过程中如果需要分配新节点，从而需要分配内存的时候，使用的 gfp 标志使得内存分配过程是 non-blocking 的 (因为持有 spinlock 锁的时候不能 blocking)

```sh
xa_store
    spin_lock(&xa_lock)
    xas_store
        # if need to allocate memory
        xas_create
            xas_alloc
                gfp = GFP_NOWAIT | __GFP_NOWARN
                node = kmem_cache_alloc(..., gfp)
    spin_unlock(&xa_lock)
```

> retrying non-blocking memory allocation

此时如果上述 non-blocking 的内存分配失败 (xas->xa_node 存储 -ENOMEM 错误码)

首先检查 xa_store() 传入的 @gfp 参数是否是 non-blocking 的，如果是的话，就用 xa_store() 传入的 @gfp 参数再次尝试分配内存。如果再次失败，那么函数最终返回 -ENOMEM；否则将分配的内存缓存在 xas->xa_alloc，接下来会再次调用 xas_store()，这一次在需要分配新节点的时候就会直接使用 xas->xa_alloc 中缓存的内存

```sh
xa_store
    spin_lock(&xa_lock)
    xas_store // non-blocking memory failed with -ENOMEM
    __xas_nomem(&xas, gfp)
        xas->xa_alloc = kmem_cache_alloc(..., gfp)
    
    xas_store
        xas_create
            xas_alloc
                node = xas->xa_alloc
    spin_unlock(&xa_lock)
```

> retrying blocking memory allocation

而如果 xa_store() 传入的 @gfp 参数不是 non-blocking 的，那么先释放掉 spinlock 锁，之后使用 xa_store() 传入的 @gfp 参数再次尝试分配内存，同样缓存在 xas->xa_alloc 中，之后再重新上锁

```sh
xa_store
    spin_lock(&xa_lock)
    xas_store // non-blocking memory failed with -ENOMEM
    __xas_nomem(&xas, gfp)
        xas_unlock
        xas->xa_alloc = kmem_cache_alloc(..., gfp)
        xas_lock
    
    xas_store
        xas_create
            xas_alloc
                node = xas->xa_alloc
    spin_unlock(&xa_lock)
```
