## fscache -refactor


### data structure

#### cache

backend 调用 fscache_acquire_cache() 创建 cache，通常每个 backend 对应一个 cache

```c
struct fscache_cache *fscache_acquire_cache(const char *name)
```

@name 描述需要创建的 cache 的 tag name，会保存在创建的 fscache_cache 的 @name 字段

```c
struct fscache_cache {
	...
	char			*name;
};
```

fscache 框架使用 @fscache_caches 全局链表管理所有的 fscache_cache


```c
void fscache_relinquish_cache(struct fscache_cache *cache)
```

![fscache_cache_state_machine](media/16382563240083/fscache_cache_state_machine.jpg)


> cache lookup

fscache_lookup_cache() 寻找名称为 @name 的 cache

1. 在注册 fscache 的场景下，name maching 的策略为

```
fscache_acquire_cache
    fscache_lookup_cache(@name, ...)
```

首先在 @fscache_caches 全局链表，即所有已经注册的 cache 中寻找名称为 @name 的 cache

- 如果 @name 不为空，那么优先寻找名称为 @name 的 cache；其次寻找 @fscache_caches 全局链表中的第一个名称为空的 cache，并将该 cache 的名称设置为 @name
- 如果 @name 为空，那么优先寻找名称同样为空的 cache，其次寻找 @fscache_caches 全局链表中的第一个名称不为空的 cache

如果上述过程中找不到匹配的 cache，就会创建并注册一个名称为 @name 的新 cache


2. 在注册 volume 的场景下，name maching 的策略为

```
fscache_alloc_volume
    fscache_lookup_cache(@name, ...)
```

首先在 @fscache_caches 全局链表，即所有已经注册的 cache 中寻找名称为 @name 的 cache

- 如果 @name 不为空，那么必须寻找名称为 @name 的 cache
- 如果 @name 为空，那么优先寻找名称同样为空的 cache，其次寻找 @fscache_caches 全局链表中的第一个名称不为空的 cache

如果上述过程中找不到匹配的 cache，就会创建并注册一个名称为 @name 的新 cache


#### volume

fs 调用 fscache_acquire_volume() 注册 volume

volume 是一组 data file cookie 的集合，fs 可以为每个 superblock 注册一个对应的 volume

```c
struct fscache_volume *fscache_acquire_volume(const char *volume_key,
					      const char *cache_name,
					      u64 coherency_data)
```

fscache 框架使用 @fscache_volumes 全局链表管理所有的 fscache_volume

当前创建的 volume 保存在 @cache_name 描述的 cache 之下，@cache_name 描述的实际上就是 fscache_acquire_cache() 的 @name 参数描述的 cache 的 tag name

如果 @cache_name 为 NULL，那么实际上就是从 @fscache_caches 链表的头部取出一个 cache，也就是第一个注册的 cache 作为当前创建的 volume 所在的 cache


@volume_key 字符串用于在系统范围内唯一标识一个 volume，保存在 volume 的 @key 字段

```c
struct fscache_volume {
	unsigned int			key_hash;	/* Hash of key string */
	char				*key;		/* Volume ID, eg. "afs@example.com@1234" */
	...
};
```

此时 @key 指向的内存区间布局如下所示

- 起始的一个 u8 描述传入的 @volume_key 字符串的长度
- 随后存储传入的 @volume_key 字符串

```
strlen()
   of       
@volume_key                              padding
+-------+-------------------------------+-------+
|       |     @volume_key (string)      |       |
+-------+-------------------------------+-------+
   u8                                       
```

fscache 会对 @key 指向的内存作 hash 运算，最终得到的 hash 值保存在 @key_hash 字段，并根据该 hash 值将该 volume 添加到 @fscache_volume_hash 全局 hash table 中



```c
void fscache_relinquish_volume(struct fscache_volume *volume,
			       u64 coherency_data,
			       bool invalidate)
```

![fscache_volume_state_machine](media/16382563240083/fscache_volume_state_machine.jpg)


#### cookie

fs 调用 fscache_acquire_cookie() 注册 cookie

fs 可以为每个 inode 注册一个对应的 cookie (data file cookie)

```c
struct fscache_cookie *fscache_acquire_cookie(struct fscache_volume *volume,
					      u8 advice,
					      const void *index_key,
					      size_t index_key_len,
					      const void *aux_data,
					      size_t aux_data_len,
					      loff_t object_size)
```

@volume 描述当前创建的 cookie 所在的 volume

fscache 框架使用 @fscache_cookies 全局链表管理所有的 fscache_cookie


@index_key 指向的一块内存用于在系统范围内唯一标识一个 cookie，保存在 cookie 的 @key 字段

```c
struct fscache_cookie {
	void			*key;		/* Index key */
	u32				key_hash;	/* Hash of volume, key, len */
	...
}
```

fscache 会对 @key 指向的内存作 hash 运算，最终得到的 hash 值保存在 @key_hash 字段，并根据该 hash 值将该 cookie 添加到 @fscache_cookie_hash 全局 hash table 中


@object_size 描述文件的大小，如果该参数为 0，那么 cookie 会置上 FSCACHE_COOKIE_NO_DATA_TO_READ 标记


```c
void fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
```

![fscache_cookie_state_machine](media/16382563240083/fscache_cookie_state_machine.jpg)


### Routine

#### 0. register cache

cachefiles 内核模块会注册 /dev/cachefiles 设备文件


用户态的 cachefilesd 进程对该设备文件写入 "dir"，以设置 backing 文件的根目录

```
cachefiles_daemon_write
    # process "dir" cmd
    cachefiles_daemon_dir
        cache->rootdirname = dir
```

用户态的 cachefilesd 进程对该设备文件写入 "bind"

```
cachefiles_daemon_write
    # process "bind" cmd
    cachefiles_daemon_bind
        cachefiles_add_cache
            fscache_acquire_cache # allocate cache
            fscache_add_cache # register cache
                cache->ops = cachefiles_cache_ops       
```


#### 1. register volume

volume 是一组 data file cookie 的集合，fs 可以为每个 superblock 注册一个对应的 volume

```sh
# mount
nfs_get_tree_common
    nfs_get_cache_cookie
        nfs_fscache_get_super_cookie
            fscache_acquire_volume // register superblock's volume
```

fscache_acquire_volume() 需要传入 @key 参数来唯一标识当前创建的这个 volume，nfs 中这个 key 的格式为

```
"nfs,<ver>,<family>,<port>,<address>,<fsidH>,<fsidL>*<,param>[,<uniq>]"
```


fscache_acquire_volume() 过程中会通过 worker 调用 cache->ops->acquire_volume() 回调函数，例如 cachefiles 中需要为当前注册的 volume 创建相应的目录

需要注意的是，fscache_acquire_volume() 在调度 worker 之后就会立即返回，而不会等待 worker 执行完成，即 worker 完全是异步执行的；这一过程中 fscache_acquire_volume() 在调度 worker 之前会将 volume 置上 FSCACHE_VOLUME_CREATING 标记，worker 在调用 cache->ops->acquire_volume() 回调函数完成之后，会清除该标记

```sh
# mount
fscache_acquire_volume
    # allocate and init volume
    
    fscache_create_volume
        # schedule volume->work

# worker
fscache_create_volume_work
    cache->ops->acquire_volume(), e.g., cachefiles_acquire_volume()
        # allocate and init 'struct cachefiles_volume'
        # mkdir for volume under '<root>/cache/'
```

cachefiles 中会在 '<root>/cache/' 目录下为当前注册的 volume 创建相应的目录，其格式为 "I<volume_key>"，其中 <volume_key> 为 volume 的名称，即 fscache_acquire_volume() 传入的 @volume_key 参数

同时在 "I<volume_key>" 目录下创建 256 个子目录，其命名格式为 "@%02x", i=0~255



#### 2. register data file cookie

fs 可以为每个 inode 注册一个对应的 cookie (data file cookie)

```sh
# mount
nfs_get_tree_common
    nfs_get_root
        nfs_fhget
            nfs_fscache_init_inode
                fscache_acquire_cookie // register root inode's data cookie
```

```sh
# .lookup
nfs_lookup
    nfs_fhget
        nfs_fscache_init_inode
            fscache_acquire_cookie // register inode's data cookie
```


#### 3. IO path

##### 3.1 open file

open 文件的时候，会调度 worker 调用 cache->ops->lookup_cookie() 回调函数

类似地这里的 worker 也是异步执行的，当 worker 执行完毕的时候，cookie 会转变为 FSCACHE_COOKIE_STATE_ACTIVE 状态

```sh
# open
nfs_open
    nfs_fscache_open_file
        fscache_use_cookie
            # cookie is in FSCACHE_COOKIE_STATE_QUIESCENT state
            fscache_begin_lookup
                cookie->state = FSCACHE_COOKIE_STATE_LOOKING_UP state 
                cookie->flags |= FSCACHE_COOKIE_IS_CACHING
                cookie->flags |= FSCACHE_COOKIE_HAS_BEEN_CACHED
            
            fscache_queue_cookie // schedule cookie->work

# worker
fscache_cookie_worker
    fscache_cookie_state_machine
        # cookie is in FSCACHE_COOKIE_STATE_LOOKING_UP state
        fscache_init_access_gate
            cookie->flags |= FSCACHE_COOKIE_NACC_ELEVATED
        
        fscache_perform_lookup
            cache->ops->lookup_cookie(), e.g. cachefiles_lookup_cookie()
                cachefiles_cook_key
                cachefiles_look_up_object
```

> data blob file 路径

之前介绍过，volume 注册的时候，cachefiles 会在 '<root>/cache/' 目录下创建格式为 "I<volume_key>" 的目录，同时在该目录下创建 256 个子目录

每个 cookie 会有一个对应的 data blob file，这些 data blob file 会均匀分布在这 256 个子目录中；对于某个特定的 cookie，其 @key_hash (u32) 存储对应的 hash 值，其实际上是根据 cookie 的 key 进行 hash 运算得来的，将该 hash 值对于 256 作一个 hash 映射 (hash_value % 256)，就得到了该 cookie 对应的 data blob file 应该保存在哪个子目录下


> data blob file 尚未创建

open 文件的时候，会调用 cache->ops->lookup_cookie() 回调函数，cachefiles 下如果当前执行 lookup 操作的 cookie 对应的 data blob file 尚未创建，那么会创建一个 tmpfile 文件，这个文件的大小会被设置为 @cookie->object_size

```sh
fscache_perform_lookup
    cache->ops->lookup_cookie(), e.g. cachefiles_lookup_cookie()
        cachefiles_cook_key
        cachefiles_look_up_object
            # corresponding data blob file not created yet
            cachefiles_create_file
                # create tmpfile under corresponding fan subdir
```

需要注意的是，tmpfile 文件刚创建的时候，此时文件的路径还不在之前描述的对应的 fan 子目录下，而是在 tmp filesystem 统一的临时目录下


> data blob file 已经存在

上述调用 cache->ops->lookup_cookie() 回调函数的过程中，如果当前执行 lookup 操作的 cookie 对应的 data blob file 已经存在，那么会在对应的子目录下创建一个 tmpfile 文件，这个文件的大小会被设置为 @cookie->object_size

```sh
fscache_perform_lookup
    cache->ops->lookup_cookie(), e.g. cachefiles_lookup_cookie()
        cachefiles_cook_key
        cachefiles_look_up_object
            # corresponding data blob file already exist
            cachefiles_open_file
                # open data blob file
                
                cachefiles_check_auxdata
                    # read "CacheFiles.cache" xattr
```

cachefiles 下的 data blob file 都会打上 "CacheFiles.cache" xattr，其值为

```
+---------------------------+---------------+
|   struct cachefiles_xattr |   aux_data    |
+---------------------------+---------------+
```

其中 cachefiles_xattr.type 为 CACHEFILES_COOKIE_TYPE_DATA；紧随 struct cachefiles_xattr 其后的是该 cookie 的 aux_data


此时在 open 文件，从而调用 cache->ops->lookup_cookie() 回调函数的过程中，如果 cookie 对应的 data blob file 已经存在，那么此时就会检查该 data blob file 的 "CacheFiles.cache" xattr 的值是否有效，主要包括

- 检查 data blob file 的 "CacheFiles.cache" xattr 中存储的 aux_data 与 fscache_acquire_cookie() 传入的 @aux_data 是否一致
- 检查 data blob file 的 "CacheFiles.cache" xattr 中存储的 object_size 与 fscache_acquire_cookie() 传入的 @object_size 是否一致

只有以上都保持一致，该 data blob file 的一致性检查才算通过


##### 3.2 read

```sh
# .readpage()
netfs_readpage(..., xxx_netfs_read_request_ops)
    # allocate and init 'struct netfs_read_request'
        ops->init_rreq() if defined
    
    ops->begin_cache_operation() if defined
        fscache_begin_read_operation
            fscache_begin_operation(..., FSCACHE_WANT_PARAMS)
                cache->ops->begin_operation(), e.g. cachefiles_begin_operation()
                    # @cres (struct netfs_cache_resources) is actually @cache_resources of previously allocated 'struct netfs_read_request'
                    # @want_state = FSCACHE_WANT_PARAMS
                    
                    cres->ops = &cachefiles_netfs_cache_ops
                    cres->cache_priv2 = 'struct file' of corresponding data blob file

    netfs_rreq_submit_slice // submit sub requests
        netfs_rreq_prepare_read
            netfs_cache_prepare_read
                cres->ops->prepare_read(), e.g. cachefiles_prepare_read()
```


###### sub request management

在 fscache 框架下，netfs 的 readpage() 回调函数通常实现为 netfs_readpage()

```c
int netfs_readpage(struct file *file, struct folio *folio, ...)
```

描述当前正需要对 netfs 中的 @file 文件执行 readpage 操作，读取的数据需要保存在 @folio 中，@folio 正是 @file 文件的一个 page cache


每次 netfs_readpage() 调用都会封装一个 struct netfs_read_request，来描述当前的 readpage 请求

```c
struct netfs_read_request {
	struct inode		*inode;		/* The file being accessed */
	struct address_space	*mapping;/* The mapping being accessed */	
	loff_t			start;		/* Start position */
	size_t			len;		/* Length of the request */
	...
};
```

@inode/@mapping 都是当前需要执行 read 操作的 netfs 下的 inode/address_space

@start 是当前需要执行 read 操作的数据在 @inode 文件中的 file offset
@len 就是当前当前需要执行 read 操作的数据的长度，在 netfs_readpage() 中就是 PAGE_SIZE


fscache 的核心原理是查询 data blob file 的 extent tree，对于当前需要执行 read 操作的数据，如果 data blob file 中已经缓存，那么直接从 data blob file 读取数据；而如果 data blob file 中是 hole，那么只能 fallback 回到从远端拉取数据

这里需要注意的是，存储 data blob file 的文件系统是以 block 为粒度执行 block mapping 的，例如 data blob file 存储在 ext4 文件系统上时，block mapping 可以以 1K 为单位进行映射

那么此时 netfs_readpage() 需要读取的一个 page 就有可能映射为多个 block，其中有的 block 的数据可能已经在 data blob file 中 ready，因而直接从 data blob file 读取就好；有的 block 对应在 data blob file 中可能是 hole，此时就必须从远端拉取

因而对应地，一个 struct netfs_read_request 可能会拆分为多个 struct netfs_read_subrequest

```c
struct netfs_read_subrequest {
	loff_t			start;		/* Where to start the I/O */
	size_t			len;		/* Size of the I/O */
	...
}
```

netfs_read_request 的 @subrequests 链表就组织其对应的所有 netfs_read_subrequest

```c
struct netfs_read_request {
	struct list_head	subrequests; /* Requests to fetch I/O from disk or net */
	...
};
```


下图描述了一个 netfs_read_request 拆分为 A/B/C/D/E/F 多个 netfs_read_subrequest 的情形

![fscache_sub_request](media/16382563240083/fscache_sub_request.jpg)

- A/C/E 为 NETFS_READ_FROM_CACHE，对应的数据已经在 data blob file 中 ready，因而直接从 data blob file 读取就好
- B/D 为 NETFS_DOWNLOAD_FROM_SERVER，对应在 data blob file 中是 hole，此时就必须从远端拉取
- F 为 NETFS_FILL_WITH_ZEROES，属于 EOF 访问，此时直接填零处理



之前介绍过一个 netfs_read_request 可能拆分为多个 netfs_read_subrequest，此时 netfs_read_request 中维护的 @nr_rd_ops 计数来实现 netfs_read_subrequest/netfs_read_request 的 completion 操作的同步

```c
struct netfs_read_request {
	atomic_t		nr_rd_ops;	/* Number of read ops in progress */
	...
};
```

@nr_rd_ops 计数的初始值为 1，netfs_readpage() 中每次下发一个 subrequest 的时候，都会增加 @nr_rd_ops 计数

```sh
netfs_readpage
    atomic_set(&rreq->nr_rd_ops, 1); // initial refcount

    # for each sub request
    netfs_rreq_submit_slice
        netfs_rreq_prepare_read
        atomic_inc(&rreq->nr_rd_ops) // inc refcount
        
        # fetch data, i.e. read from cache or remote
```    

subrequest 完成的时候，在 completion 操作中会减去 @nr_rd_ops 计数

```sh    
# on sub request completion
netfs_subreq_terminated
    # completion operation
    
    atomic_dec_return(&rreq->nr_rd_ops) // dec refcount
    
    # if currently @rreq->nr_rd_ops has decreasedto '1'
    # (all sub requests completed, there's initial refcount only)
    wake_up_var(&rreq->nr_rd_ops)
```


下发的 subrequest 都是异步的，此时 netfs_readpage() 中下发完所有 subrequest 时，需要等待所有的 subrequest 完成，正这是通过 @nr_rd_ops 计数实现的

```sh
netfs_readpage
    atomic_set(&rreq->nr_rd_ops, 1); // initial refcount

    # for each sub request
    netfs_rreq_submit_slice
        netfs_rreq_prepare_read
        atomic_inc(&rreq->nr_rd_ops) // inc refcount
        
        # fetch data, i.e. read from cache or remote
        
    # wait for all sub requests completion
    wait_var_event(&rreq->nr_rd_ops, atomic_read(&rreq->nr_rd_ops) == 1) 
```    


###### NETFS_FILL_WITH_ZEROES

如果当前访问的数据范围超过了文件的大小，即 EOF 访问，那么此时直接对需要访问的数据范围作填零处理

```sh
netfs_rreq_submit_slice
    netfs_rreq_prepare_read
        netfs_cache_prepare_read
            cres->ops->prepare_read(), e.g. cachefiles_prepare_read()
                # if read past EOF, return NETFS_FILL_WITH_ZEROES
    
    # since source == NETFS_FILL_WITH_ZEROES
    netfs_read_from_cache
        __set_bit(NETFS_SREQ_CLEAR_TAIL, &subreq->flags)
        netfs_subreq_terminated
            # since NETFS_SREQ_CLEAR_TAIL set
            netfs_clear_unread // fill zero
```


###### NETFS_DOWNLOAD_FROM_SERVER

如果 block 对应在 data blob file 中是 hole，此时就必须从远端拉取

```sh
netfs_rreq_submit_slice
    netfs_rreq_prepare_read
        netfs_cache_prepare_read
            cres->ops->prepare_read(), e.g. cachefiles_prepare_read()
                # if FSCACHE_COOKIE_NO_DATA_TO_READ set in cookie->flags (the data blob file is completely empty),
                # or the range covered by sub request is completely hole (fully miss)
                    __set_bit(NETFS_SREQ_WRITE_TO_CACHE, &subreq->flags)
                    return NETFS_DOWNLOAD_FROM_SERVER

    # since source == NETFS_DOWNLOAD_FROM_SERVER
    netfs_read_from_server
        netfs_ops->issue_op(subreq)
            # fetch data from remote, store into netpage
```

这里会调用 netfs 自己实现的 issue_op() 回调函数以从远端拉取数据，此时拉取的数据会直接存储在 netfs_readpage() 传入的 @folio 中，即将数据读取到 netfs 中的一个 page cache 中

这里下发的 subrequest 是异步完成的，当 subrequest 完成的时候会给整个 request 标记上 NETFS_RREQ_WRITE_TO_CACHE

```sh
# when data has been fetched
netfs_subreq_terminated
    # since NETFS_SREQ_WRITE_TO_CACHE set in &subreq->flags
    set_bit(NETFS_RREQ_WRITE_TO_CACHE, &rreq->flags)
```

之后当这个 request 对应的所有 subrequest 都完成的时候，就需要将从远端拉取的数据，缓存到 data blob file 中

```sh
netfs_readpage
    atomic_set(&rreq->nr_rd_ops, 1); // initial refcount

    # for each sub request
    netfs_rreq_submit_slice
        netfs_rreq_prepare_read
        atomic_inc(&rreq->nr_rd_ops) // inc refcount
        
        # fetch data, i.e. read from cache or remote
        
    # wait for all sub requests completion
    wait_var_event(&rreq->nr_rd_ops, atomic_read(&rreq->nr_rd_ops) == 1)
    
    netfs_rreq_assess
        # since NETFS_RREQ_WRITE_TO_CACHE set in &rreq->flags
        netfs_rreq_write_to_cache
            netfs_rreq_do_write_to_cache
                # iterate all sub requests, and for each sub request marked with NETFS_SREQ_WRITE_TO_CACHE
                cres->ops->prepare_write(subreq), e.g. cachefiles_prepare_write()
                    # reserve block for backing data blob file if block not allocated yet
        
                # DIRECT write data from netpage (from netfile's address_space) to backing data blob file    
                cres->ops->write(), e.g. cachefiles_write()
```

这里对所有带有 NETFS_SREQ_WRITE_TO_CACHE 标记的 subrequest，即 NETFS_DOWNLOAD_FROM_SERVER 类型的 subrequest，调用 cache backend 实现的 write() 回调函数，以将数据回写到 data blob file 中

这里是通过 DIRECT write 直接将 netfs 的 page cache 中的数据写到 data blob file 中


###### NETFS_READ_FROM_CACHE

如果 block 对应的数据已经在 data blob file 中 ready，那么直接从 data blob file 读取就好

```sh
netfs_rreq_submit_slice
    netfs_rreq_prepare_read
        netfs_cache_prepare_read
            cres->ops->prepare_read(), e.g. cachefiles_prepare_read()
                # if the range covered by sub request is completely ready (fully hit)
                return NETFS_READ_FROM_CACHE

    # since source == NETFS_READ_FROM_CACHE
    netfs_read_from_cache
        netfs_cache_ops->read(), e.g. cachefiles_read()
            vfs_iocb_iter_read // DIRECT read from backing data blob file
            return -EIOCBQUEUED
```

这里会通过 DIRECT read，直接将数据从 data blob file 读取到 netfs_readpage() 传入的 @folio 中，即将数据读取到 netfs 中的一个 page cache 中

这里下发的 subrequest 是异步完成的

```sh
# async completion
cachefiles_read_complete
    netfs_cache_read_terminated
        netfs_subreq_terminated
```


netfs_cache_ops->read() 回调函数的 @read_hole 描述对 backing file 的 hole 的处理方式

NETFS_READ_HOLE_IGNORE 会直接向 backing file 发起 DIRECT IO，而无论对应的 file offset 区间内是否存在 hole，此时 backing file 所在的文件系统在处理该 DIRECT IO (例如 iomap_dio_rw()) 的时候，检测到该区间内存在 hole 时，就会将 page 内该 hole 对应的区域清为 0

NETFS_READ_HOLE_CLEAR 和 NETFS_READ_HOLE_FAIL 两种情况下都会对 backing file 执行 SEEK_DATA llseek 操作，以判断对应的 file offset 区间内是否存在 hole。如果存在 hole，对于 NETFS_READ_HOLE_FAIL 来说，当前的 read 操作会直接返回 -ENODATA 错误；而对于 NETFS_READ_HOLE_CLEAR 来说，将 page 内该 hole 对应的区域清为 0


因而 NETFS_READ_HOLE_IGNORE 与 NETFS_READ_HOLE_CLEAR 虽然都会将 page 内 hole 对应的区域清为 0，但是两者的区别是：

NETFS_READ_HOLE_CLEAR 是通过 SEEK_DATA llseek 操作来判断对应的 file offset 区间内是否存在 hole，此时不会向 backing file 所在的文件系统下发 DIRECT IO，但是这里会多一次 llseek 操作，因而适用于事先不清楚该 file offset 区间内是否存在 hole 的情况

而 NETFS_READ_HOLE_IGNORE 则是直接向 backing file 所在的文件系统下发 DIRECT IO，在处理该 DIRECT IO 的过程中检测到 hole 的时候，才会将 page 内 hole 对应的区域清为 0，因而适用于事先确定该 file offset 区间内不存在 hole 的情况


###### incomplete sub request

之前介绍过 subrequest 的 @len 字段描述其需要读取的数据长度

```c
struct netfs_read_subrequest {
	size_t			len;		/* Size of the I/O */
	...
}
```

无论是直接从 data blob file 读取数据，还是从远端拉取数据，实际成功读取到的数据都可能小于 @len

fscache 中可以通过 netfs_subreq_terminated() 执行 subrequest 的 completion 操作，@transferred_or_error 就描述此次该 subrequest 成功读取到的数据长度，即传入的 @transferred_or_error 参数有可能小于 @len

```c
void netfs_subreq_terminated(struct netfs_read_subrequest *subreq,
			     ssize_t transferred_or_error,
			     bool was_async)
```

此时 subrequest 的 @transferred 字段描述截止当前，该 subrequest 已经成功读取的数据大小

```c
struct netfs_read_subrequest {
	size_t			transferred;	/* Amount of data transferred */
	...
}
```

此时 subrequest 的 completion 操作中，如果实际读取的数据小于 @len，那么该 subrequest 就会标记为 NETFS_SREQ_SHORT_READ，整个 reqeust 会标记为 NETFS_RREQ_INCOMPLETE_IO

```sh
# when data has been fetched
netfs_subreq_terminated
    subreq->transferred += transferred_or_error;
    
    if subreq->transferred < subreq->len:
        __set_bit(NETFS_SREQ_SHORT_READ, &subreq->flags);
        set_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags);
```

之后当所有 subrequest 完成的时候，netfs_readpage() 中检查到存在 incomplete request，就会对所有标记为 NETFS_SREQ_SHORT_READ 的 subrequest 重新发起 read 操作

```sh
netfs_readpage
    # for each sub request
    netfs_rreq_submit_slice
        netfs_rreq_prepare_read
        
        # fetch data, i.e. read from cache or remote
        
    # wait for all sub requests completion
    wait_var_event(&rreq->nr_rd_ops, atomic_read(&rreq->nr_rd_ops) == 1) 
    
    netfs_rreq_assess
        if test_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags):
            netfs_rreq_perform_resubmissions
                # for each subrequest marked with NETFS_SREQ_SHORT_READ:
                    netfs_rreq_short_read
                        netfs_read_from_cache()/netfs_read_from_server()
```

因而对于一个 subrequest 来说，当前真正需要读取的数据范围实际上是，[start + transferred, start + len]

```c
struct netfs_read_subrequest {
	loff_t			start;		/* Where to start the I/O */
	size_t			len;		/* Size of the I/O */
	size_t			transferred;	/* Amount of data transferred */
	...
}
```

###### req completion

之前描述过，一个 struct netfs_read_request 可能会拆分为多个 struct netfs_read_subrequest

每个 subrequest 完成的时候都会调用 netfs_subreq_terminated()，其中减小 @rreq->nr_rd_ops 计数；最终当所有 subrequest 都完成的时候，也就是 @rreq->nr_rd_ops 计数变为 1 (initial refcount) 的时候，会唤醒一直等待在那边的 netfs_readpage()

```sh
# when data has been fetched for each subreq
netfs_subreq_terminated
    atomic_dec_return(&rreq->nr_rd_ops) // dec refcount
    
    # if currently @rreq->nr_rd_ops has decreasedto '1'
    # (all sub requests completed, there's initial refcount only)
    wake_up_var(&rreq->nr_rd_ops)
```


netfs_readpage() 在下发完所有 subrequest 的时候，需要等待所有的 subrequest 完成，也就是等待 @nr_rd_ops 计数变为 1 (initial refcount)；之后会调用 netfs_rreq_assess()，其中就会给对应的 page 置上 PG_locked/PG_uptodate 标记

```sh
netfs_readpage
    atomic_set(&rreq->nr_rd_ops, 1); // initial refcount

    # for each sub request
    netfs_rreq_submit_slice
        netfs_rreq_prepare_read
        atomic_inc(&rreq->nr_rd_ops) // inc refcount
        
        # fetch data, i.e. read from cache or remote
        
    # wait for all sub requests completion
    wait_var_event(&rreq->nr_rd_ops, atomic_read(&rreq->nr_rd_ops) == 1)
    
    netfs_rreq_assess
        netfs_rreq_unlock
            folio_mark_uptodate(folio)
            folio_unlock(folio)
```    


##### 3.3 write

```sh
# f_op->write_iter()
    a_ops->write_begin()
        # check if netpage ready, read from remote server or cache if not
        netfs_write_begin

# buffer write
# write to netpage

# .write_end()
    folio_mark_dirty
        mapping->a_ops->set_page_dirty()
            fscache_set_page_dirty
                node->i_state |= I_PINNING_FSCACHE_WB
                fscache_use_cookie(cookie, true)
                    # initial state: cookie is in FSCACHE_COOKIE_STATE_ACTIVE state
                    # cookie->flags: set FSCACHE_COOKIE_LOCAL_WRITE
                    # cookie->flags: set FSCACHE_COOKIE_DO_PREP_TO_WRITE
                    # schedule worker

# worker
fscache_cookie_worker
    # since FSCACHE_COOKIE_DO_PREP_TO_WRITE bit is set
    fscache_prepare_to_write
        cache->ops->prepare_to_write(), e.g. cachefiles_prepare_to_write()
            # basically do nothing
```


```sh
# writeback routine, a_ops->writepage()
    # writeback to remote server
    
    # also writeback to backing data blob file
    fscache_write_to_cache
        # allocate and init 'struct fscache_write_request'
        
        fscache_begin_operation(..., FSCACHE_WANT_PARAMS)
            cache->ops->begin_operation(), e.g. cachefiles_begin_operation()
                # @cres (struct netfs_cache_resources) is actually @cache_resources of previously allocated 'struct fscache_write_request'
                # @want_state = FSCACHE_WANT_PARAMS
                
                cres->ops = &cachefiles_netfs_cache_ops
                cres->cache_priv2 = 'struct file' of corresponding data blob file
        
        cres->ops->prepare_write(), e.g. cachefiles_prepare_write()
            # reserve block for backing data blob file if block not allocated yet
        
        # writeback data from netpage to backing data blob file    
        fscache_write
             cres->ops->write(), e.g. cachefiles_write()
                # DIRECT write to backing data blob file
```


#### 4. cleanup data file cookie

当 fs 对文件执行 close 操作，从而触发 inode eviction 的时候，通常需要在 s_ops->evict_inode() 回调函数中调用 fscache_relinquish_cookie() 以执行 cookie 的清理操作

```c
void fscache_relinquish_cookie(struct fscache_cookie *cookie, bool retire)
```

```sh
# close file (inode cleanup)
s_ops->evict_inode()
    fscache_relinquish_cookie(cookie, @retire)
        # cookie->flags: set FSCACHE_COOKIE_RELINQUISHED
        # cookie->flags: set FSCACHE_COOKIE_DO_RELINQUISH
        fscache_drop_withdraw_cookie
            __fscache_withdraw_cookie
                fscache_end_cookie_access
                    # schedule cookie->work

# worker
fscache_cookie_worker
    fscache_cookie_state_machine
        # since FSCACHE_COOKIE_DO_RELINQUISH is set
        # cookie's state transform to FSCACHE_COOKIE_STATE_RELINQUISHING state
        
        cache->ops->withdraw_cookie(cookie), e.g. cachefiles_withdraw_cookie()
            cachefiles_clean_up_object
                cachefiles_commit_object
                    # if FSCACHE_COOKIE_NEEDS_UPDATE is set, i.e. data blob file previously not exist and thus newly created,
                    # or FSCACHE_COOKIE_LOCAL_WRITE is set, i.e. previously write to netpage
                    cachefiles_set_object_xattr
                        # set "CacheFiles.cache" xattr of data blob file
                    
                    cachefiles_commit_tmpfile
                        # link a temporary file into its rightful place under corresponding fan subdir
                        # cookie->flags: clear CACHEFILES_OBJECT_USING_TMPFILE

        # cookie's state transform to FSCACHE_COOKIE_STATE_DROPPED state
```

这一过程中会给对应的 data blob file 设置上 "CacheFiles.cache"，其中主要包含该 cookie 的 aux_data、object_size 等元数据信息

同时之前描述 open 文件的时候，会对该文件对应的 data blob file 执行 lookup 操作，如果此时该 data blob file 尚未创建，那么会创建一个 tmpfile 文件，该 tmpfile 文件刚创建的时候，其路径是在 tmp filesystem 统一的临时目录下

此时 close 文件的时候，会通过 link() 调用将该 tmpfile 文件 link 到对应的 fan 子目录下


同时值得注意的是，fscache_relinquish_cookie() 的 @retire 参数描述是否丢弃 data blob file

当 @retire 参数为 false 时，fscache_relinquish_cookie() 函数的执行路径如之前描述的，会执行 cachefiles_commit_object()，以将 tmpfile link 到对应的 fan 子目录下，从而使得 data blob file 存储到磁盘上

而当 @retire 参数为 true 时，fscache_relinquish_cookie() 函数的执行路径如下所示，此时不会执行 cachefiles_commit_object()，也就是说 data blob file 不会存储到磁盘上，之后 inode eviction 流程中该 tmpfile 就会从 tmp filesystem 中移除

```sh
# close file (inode cleanup)
s_ops->evict_inode()
    fscache_relinquish_cookie(cookie, @retire)
        # if @retire is true
        # cookie->flags: set FSCACHE_COOKIE_RETIRED
        # cookie->flags: set FSCACHE_COOKIE_DO_RELINQUISH
        fscache_drop_withdraw_cookie
            __fscache_withdraw_cookie
                fscache_end_cookie_access
                    # schedule cookie->work

# worker
fscache_cookie_worker
    fscache_cookie_state_machine
        # since FSCACHE_COOKIE_DO_RELINQUISH is set
        # cookie's state transform to FSCACHE_COOKIE_STATE_RELINQUISHING state
        
        cache->ops->withdraw_cookie(cookie), e.g. cachefiles_withdraw_cookie()
            cachefiles_clean_up_object
                # since FSCACHE_COOKIE_RETIRED bit is set
                # cachefiles_commit_object() is not called

        # cookie's state transform to FSCACHE_COOKIE_STATE_DROPPED state
```


### culling management

cachefilesd 可以通过 write /dev/cachefiles 设置 brun/bcull/bstop frun/fcull/fstop 水位线，当 cachefiles 的缓存文件占用的空间超过这个水位线的时候，fscache 就会受到限制

具体来讲，当缓存文件所在的文件系统的可用空间下降到 *cull 水位线以下的时候，cachefiles 需要通知 cachefilesd，由 cachefilesd 来删除一些缓存文件，来腾出一些空间，直到可用空间恢复到 *run 水位线以上

当缓存文件所在的文件系统的可用空间下降到 *stop 水位线以下的时候，cachefiles 就会停止创建新的缓存文件、或往缓存文件写数据等，直到可用空间恢复到 *stop 水位线以上


之前介绍到，当缓存文件的可用空间下降到 *cull 水位线以下的时候，需要由 cachefilesd 来删除一些缓存文件，其具体过程是，cachefilesd 会向 /dev/cachefiles 写入 "cull <file>" 命令

```
cachefiles_cull
    if this backing file marked with S_KERNEL_FILE, i.e. it's still in use:
        return -EBUSY
    
    cachefiles_bury_object
        for non-directory backed backing file:
            vfs_unlink // delete this file directly
        
        for directory backed backing file:
            vfs_rename // move into the graveyard for userspace to delete
```

但是 "cull <file>" 命令只能删除当前没有被使用 (例如没有正在被 open) 的缓存文件，其中是通过文件的 S_KERNEL_FILE 标记来判断需要被删除的文件当前有没有正在被使用


upper fs 在 open 文件的时候，会将对应的 backing file 置上 S_KERNEL_FILE 标记

```sh
fscache_perform_lookup
    cache->ops->lookup_cookie(), e.g. cachefiles_lookup_cookie()
        cachefiles_cook_key
        cachefiles_look_up_object
            # corresponding data blob file already exist
            cachefiles_open_file
                cachefiles_mark_inode_in_use
                    inode->i_flags |= S_KERNEL_FILE // Mark the backing file as being a cache file
                
                # open data blob file
```


upper fs 在 close 文件的时候，会清除对应的 backing file 的 S_KERNEL_FILE 标记

```sh
# close file (inode cleanup)
s_ops->evict_inode()
    fscache_relinquish_cookie(cookie, @retire)
        fscache_drop_withdraw_cookie
            __fscache_withdraw_cookie
                fscache_end_cookie_access
                    # schedule cookie->work

# worker
fscache_cookie_worker
    fscache_cookie_state_machine
        # since FSCACHE_COOKIE_DO_RELINQUISH is set
        # cookie's state transform to FSCACHE_COOKIE_STATE_RELINQUISHING state
        
        cache->ops->withdraw_cookie(cookie), e.g. cachefiles_withdraw_cookie()
            cachefiles_clean_up_object
                cachefiles_unmark_inode_in_use
                    inode->i_flags &= ~S_KERNEL_FILE
```
