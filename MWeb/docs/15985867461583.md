title:'How to use atomic/barrier'
## How to use atomic/barrier


### compiler barrier

理论上当一个变量在两个或多个线程之间共享，同时其中一个线程会对变量执行修改 (write) 操作，那么另一个线程在读取 (read) 这个变量的时候

- 如果执行 read 操作的线程会对同一个变量多次重复执行 read 操作，那么就需要使用 READ_ONCE() 读取该变量
- 如果执行 write 操作的线程会对同一个变量多次重复执行 write 操作，那么就需要使用 WRITE_ONCE() 修改该变量

当然有一个前提条件，那就是在 lockfree 编程的情形下才需要使用 READ_ONCE()，如果使用锁对读取变量的操作进行保护，由于锁机制中已经使用到 memory barrier，因而在锁临界区中的读取操作实际上不必再套上一层 READ_ONCE()


### atomic_t

需要注意的是，原子操作 (atomic_t) 的语义与 memory model 是两个正交的概念

原子操作的语义只是规定一个处理器对 shared memory 执行修改指令（write 或 read-modify-write）的过程中，在另一个处理器看来，这个 shared memory 要么处于指令执行前的状态，要么处于指令执行后的状态，而不会看到处于指令执行的中间状态

例如考虑以下代码

```c
	static void obj_list_add(struct obj *obj, struct list_head *head)
	{
		obj->active = 1;
		list_add(&obj->list, head);
	}

	static void obj_list_del(struct obj *obj)
	{
		list_del(&obj->list);
		obj->active = 0;
	}

	static void obj_destroy(struct obj *obj)
	{
		BUG_ON(obj->active);
		kfree(obj);
	}

	struct obj *obj_list_peek(struct list_head *head)
	{
		if (!list_empty(head)) {
			struct obj *obj;

			obj = list_entry(head->next, struct obj, list);
			atomic_inc(&obj->refcnt);
			return obj;
		}
		return NULL;
	}

	void obj_poke(void)
	{
		struct obj *obj;

		spin_lock(&global_list_lock);
		obj = obj_list_peek(&global_list);
		spin_unlock(&global_list_lock);

		if (obj) {
			obj->ops->poke(obj);
			if (atomic_dec_and_test(&obj->refcnt))
				obj_destroy(obj);
		}
	}

	void obj_timeout(struct obj *obj)
	{
		spin_lock(&global_list_lock);
		obj_list_del(obj);
		spin_unlock(&global_list_lock);

		if (atomic_dec_and_test(&obj->refcnt))
			obj_destroy(obj);
	}
```

如果 atomic_t 操作中不包含 barrier，那么在执行到 obj_destroy() 的时候，就有可能发现引用计数已经降为 0，但是 @obj->active 仍为 1，从而触发 BUG_ON() assertion

考虑以下执行顺序

```
	cpu 0				cpu 1
	obj_poke()			obj_timeout()
	obj = obj_list_peek();
	... gains ref to obj, refcnt=2
					obj_list_del(obj);
					obj->active = 0 ...
					... visibility delayed ...
					atomic_dec_and_test()
					... refcnt drops to 1 ...
	atomic_dec_and_test()
	... refcount drops to 0 ...
	obj_destroy()
	BUG() triggers since obj->active
	still seen as one
					obj->active update visibility occurs
```

CPU 1 执行以下序列的时候

```
obj_timeout
    obj_list_del
        obj->active = 0
    atomic_dec_and_test
```

如果因为 cache 等原因，使得 CPU 0 看来，CPU 1 的 "obj->active = 0" 与 "atomic_dec_and_test" 这两条指令发生 reorder，那么 CPU 0 在执行 obj_destroy() 的时候，就会发现引用计数已经降为 0，但是 @obj->active 仍为 1，从而触发 BUG_ON() assertion


换句话说，原子操作 (atomic_t) 只是保证了 "atomic_dec_and_test" 这条指令本身的原子性，即一个处理器在执行 atomic_dec_and_test 对 shared memory 进行修改时，在另一个处理器看来，shared memory 要么处于修改前的状态，要么处于修改后的状态

但是尽管 "atomic_dec_and_test" 这条指令本身是原子的，"atomic_dec_and_test" 指令仍然有可能与该指令之前或之后的 load/store 指令发生 reorder，在以上的例子中 "atomic_dec_and_test" 指令就是与 "obj->active = 0" 指令发生了 reorder

当然两条内存 load/store 指令发生 reorder 是再正常不过的事情，只要这两条指令操作的内存在逻辑上并没有联系；只有当这两条指令操作的内存在逻辑上存在联系时，reorder 才会引入问题，此时才需要 barrier 来消除 reorder

上面的例子中，这两条内存操作指令操作的内存分别是 atomic_t 修饰的引用计数与 @obj->active，在逻辑上当引用计数降为 0 时会触发对 @obj->active 的 BUG_ON() assertion 检查，也正是这个 assersion 检查建立了这两者在逻辑上的联系





atomic_t 有一些错误的使用方式，这些错误的使用方式引入的 BUG 通常又都十分微妙，下文就介绍一些常见的错误用法

#### some atomic_t ops doesn't imply barriers

如之前所述，原子操作 (atomic_t) 的语义与 memory model 是两个正交的概念，atomic_t 操作中以下操作是没有隐含 barrier 的

- atomic_read()/atomic_set() 
- atomic_add()atomic_sub()
- atomic_inc()atomic_dec()

因而在 lock-free 场景下，如果上述 atomic_t 操作与其他内存指令发生 reorder 会影响代码逻辑的，就必须使用 barrier 对上述 atomic_t 操作进行保护

参考以下 patch:[io_uring: add a memory barrier before atomic_read](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=c0e48f9dea9129aa11bec3ed13803bcc26e96e49)


#### atomic_t can't guarantee the order

我们说 atomic_t 操作是原子的，因而在 lock-free 场景下使用 atomic_t 变量确实可以替代部分的锁

例如当需要并行修改某个变量时，就必须使用锁来进行保护

```c
int var;

P0                                  P1
spin_lock(lock);                    spin_lock(lock);
var ++;                             var --;
spin_unlock(lock)                   spin_unlock(lock);
```

但是将这个变量修改为 atomic_t，由于 atomic_t 的操作保证是原子的，因而此时就不再需要锁了


```c
atomic_t var;

P0                                  P1
atomic_inc(var)                     atomic_dec(var)
```


但是需要注意的是，只有 atomic_t 操作本身是保证是原子的，如下是 lock-free 场景中常见的一种模式，此时使用 atomic_t 操作作为判断的条件，条件执行临界区操作

```c
atomic_t cond;

if (atomic_inc_not_zero(cond))
    do_something_to_buffer
```

考虑上述例子，其中实际包含了两步操作 1) atomic_t 操作 以及 2) 临界区操作，atomic_t 操保证是原子的，但是上述两步操作作为一个整体就不是原子的了，因而上述例子中，在执行 atomic_t 操作和临界区操作的中间，其他 CPU 也有可能插进来执行临界区相关的操作

参考以下这个 patch：[blk-mq: fix hang caused by freeze/unfreeze sequence](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=7996a8b5511a72465b0b286763c2d8f412b8874a)


```c
void blk_freeze_queue_start(struct request_queue *q)
{
	int freeze_depth;

	freeze_depth = atomic_inc_return(&q->mq_freeze_depth);
	if (freeze_depth == 1) {
		percpu_ref_kill(&q->q_usage_counter);
		...
	}
}
```

```c
void blk_mq_unfreeze_queue(struct request_queue *q)
{
	int freeze_depth;

	freeze_depth = atomic_dec_return(&q->mq_freeze_depth);
	if (!freeze_depth) {
		percpu_ref_resurrect(&q->q_usage_counter);
		...
	}
}
```

上述例子中使用 atomic_t 类型的 mq_freeze_depth 计数来对 percpu_ref 类型的 q_usage_counter 变量进行保护，但是正如之前介绍的，atomic_t 操作本身与后面的临界区操作作为一个整体并不是原子的，考虑以下执行序列

```
 CPU#0                         CPU#1
 ----------------              -----------------
 q1 = blk_mq_init_queue(shared_tags)

                                q2 = blk_mq_init_queue(shared_tags):
                                  blk_mq_add_queue_tag_set(shared_tags):
                                    blk_mq_update_tag_set_depth(shared_tags):
    list_for_each_entry()
                                      blk_mq_freeze_queue(q1)
                                       > percpu_ref_kill()
                                       > blk_mq_freeze_queue_wait()
                                    
                                      blk_mq_unfreeze_queue()
                                        > atomic_dec_return()
 blk_cleanup_queue(q1)
  blk_mq_freeze_queue(q1)
   > atomic_inc_return()
   > percpu_ref_kill()
                 ^^^^^^ freeze_depth can't guarantee the order

                                        > percpu_ref_resurrect()

   > blk_mq_freeze_queue_wait()
                 ^^^^^^ Hang here!!!!
```

CPU 1 执行 blk_mq_unfreeze_queue() 过程中，执行了 atomic_dec_return() 但是尚未执行 percpu_ref_resurrect() 的时候，CPU 0 就率先执行 blk_mq_freeze_queue() 中的 atomic_inc_return() 与 percpu_ref_kill()，之后 CPU 1 才继续执行 blk_mq_unfreeze_queue() 中的 percpu_ref_resurrect()

这就导致percpu_ref @q_usage_counter 连续执行了两次 percpu_ref_kill() 操作，从而引入 BUG

这种场景下，只有锁机制才能保证一个代码块（上述例子中就包括 atomic_t 操作与临界区操作）的原子性
