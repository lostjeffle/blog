title:'Page Cache Consistency'
## Page Cache Consistency

### buffer read & readpage

无论是 buffer read(2)、read_cache_page*() 函数，还是 buffer write(2) 路径中需要先读取 page cache，这些路径中都需要读取 address_space 中的 page，这个时候如果 address_space 中还没有对应的 page，那么就会创建该 page，并调用 a_ops->readpage() 回调函数，来将磁盘上的内容读取到该 page 中

但是 a_ops->readpage() 回调函数返回的时候，只是说明 IO 请求已经提交，但是对应的 IO 请求可能还没有执行完成，而上述读取 page 内容的操作都是同步的，因而读取 page 的操作必须等待 .readpage() 下发的 IO 完成，即等待对应的数据从磁盘读取到 page 中，这里就使用 @page->flags 的 PG_locked bit 进行同步

PG_locked 用于描述描述 .readpage() 下发的 IO 是否已经完成，当新分配的 page 被添加到 page cache 的时候，这个 page 初始就处于 locked 状态，之后当 .readpage() 下发的 IO 完成的时候才会清除 PG_locked bit，使得 page 切换为 unlocked 状态；而读取 page 的操作在 address space 中找到对应的 page 之后、在真正读取 page 中的内容之前，必须等待 page 处于 unlocked 状态，也就是等待 .readpage() IO 的完成

但是 PG_locked bit 只能描述 .readpage() 下发的 IO 是否已经完成，它无法描述这个 IO 的完成状态，即这个 IO 是成功了还是失败了，因而需要另外一个 PG_uptodate bit 来描述这个 IO 的完成状态；读取 page 的操作在等待 page 切换为 unlocked 状态之后，还需要检查 page 的 PG_uptodate 状态，如果 page 没有设置上 PG_uptodate 就说明 .readpage() IO 失败了，page 中的内容是无效的，此时当前操作必须返回 -EIO

```c
enum pageflags {
	PG_locked,		/* Page is locked. Don't touch. */
	PG_uptodate,
	...
}
```

> During initiation of disk I/O, PG_locked is set. This bit is set before I/O and cleared when writeback _starts_ or when read _completes_. 
> PG_locked also pins a page in pagecache, and blocks truncation of the file while it is held.
> PG_uptodate tells whether the page's contents is valid.  When a read completes, the page becomes uptodate, unless a disk I/O error happened.


#### initial newly created: locked

一开始 page cache 新创建出来的时候，其初始状态下就会置上 PG_locked bit

之后调用 a_ops->readpage() 回调函数向磁盘提交 IO 请求之后，需要同步地等待 page 的 PG_locked bit 被清除

```sh
# read_cache_page*()
do_read_cache_page
    page = find_get_page(mapping, index)
    
    if page not exist:
        # allocate new cache page with gfp flags
        page = __page_cache_alloc(gfp)
            
        # insert new allocated cache page into address_space
        add_to_page_cache_lru
            __SetPageLocked(page) // page->flags: set PG_locked
            # add page to inode's address space

        # then read content from disk into new allocated cache page
        mapping->a_ops->readpage(data, page)
            # read from disk, submit IO request

        page = wait_on_page_read(page)
            wait_on_page_locked(page) // wait for PG_locked cleared           
```

```sh
# f_ops->read_iter(), e.g. filemap_read()
    filemap_get_pages
        filemap_get_read_batch  // find page cache
        
        if page not exist:
            filemap_create_page
                page = page_cache_alloc() // create new page cache
                
                # insert new allocated cache page into address_space
                add_to_page_cache_lru
                    __SetPageLocked(page) // page->flags: set PG_locked
                    # add page to inode's address space                
                
                filemap_read_page
                    a_ops->readpage() // read from disk
                    wait_on_page_locked_killable(page) // wait for PG_locked cleared
```


#### IO completion: unlock

此后当 IO 请求完成的时候，在 IO completion 中就会清除 page 的 PG_locked bit，以描述该 page 的 IO 请求已经完成；同时会设置 page 的 PG_uptodate bit，以描述该 page 的 IO request 成功完成，没有发生任何错误

```sh
# a_ops->readpage()
    iomap_readpage
        bio->bi_end_io = iomap_read_end_io

# IO completion
bio->bi_end_io(), i.e. iomap_read_end_io()
    iomap_read_page_end_io
        #if IO failed:
            ClearPageUptodate(page)
            SetPageError(page)
        # else:
            SetPageUptodate(page) // page->flags: set PG_uptodate
    
        unlock_page(page) // page->flags: clear PG_locked
```


#### check IO completion status

回到读取 page 的操作，当 page 的 PG_locked bit 被清除，即 page 的 IO request 完成的时候，就会从同步睡眠等待的状态中唤醒过来

此时会检查该 page 的 PG_uptodate bit，如果 page 设置有 PG_uptodate bit，说明该 page 对应的 IO request 成功完成，没有发生任何错误；否则说明该 page 对应的 IO request 虽然已经完成，但是发生了错误，因而当前操作会返回 -EIO 错误

```sh
# read_cache_page*()
do_read_cache_page
    page = find_get_page(mapping, index)
    
    if page not exist:
        # allocate new cache page with gfp flags
        page = __page_cache_alloc(gfp)
            
        # insert new allocated cache page into address_space
        add_to_page_cache_lru
            __SetPageLocked(page) // page->flags: set PG_locked
            # add page to inode's address space

        # then read content from disk into new allocated cache page
        mapping->a_ops->readpage(data, page)
            # read from disk, submit IO request

        page = wait_on_page_read(page)
            wait_on_page_locked(page) // wait for PG_locked cleared
            
            if !PageUptodate(page):
                return -EIO
            else:
                return page            
```

```sh
# f_ops->read_iter(), e.g. filemap_read()
    filemap_get_pages
        filemap_get_read_batch  // find page cache
        
        if page not exist:
            filemap_create_page
                page = page_cache_alloc() // create new page cache
                
                # insert new allocated cache page into address_space
                add_to_page_cache_lru
                    __SetPageLocked(page) // page->flags: set PG_locked
                    # add page to inode's address space                
                
                filemap_read_page
                    a_ops->readpage() // read from disk
                    wait_on_page_locked_killable(page) // wait for PG_locked cleared
                    
                    if PageUptodate(page):
                        return 0
                    else:
                        return -EIO
```


### buffer write

并发的 buffer write(2) 之间是互斥的

filemap based buffer write(2) 是通过 inode_lock 来实现并发的 buffer write(2) 之间互斥的

```sh
# filemap based buffer write(2)
f_op->write_iter(), e.g. generic_file_write_iter()
    inode_lock(inode)
    # do buffer write
    inode_unlock(inode)
```

iomap based buffer write(2) 依赖 iomap_file_buffered_write() 的 caller 自己通过锁来实现并发的 buffer write(2) 之间互斥的

```sh
# iomap based buffer write(2)
f_op->write_iter()
    # lock
    iomap_file_buffered_write()
    #unlock
```


### buffer/mmap write & writeback

PG_dirty bit 描述 page 是否需要回写，此时当修改 page 中的内容时就需要置上 PG_dirty，在发起 writeback 请求之后就需要清除 PG_dirty

```c
enum pageflags {
	PG_dirty,
	...
}
```

PG_dirty bit 只能描述每个 page 是否需要回写的状态，为了快速找到 address space 中处于 PG_dirty 状态的 page，address space 还使用 PAGECACHE_TAG_DIRTY tag 来快速追踪 address space 中的所有 PG_dirty 状态的 page

因而很重要的一个任务就是如何维护 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag，从而反映所有 (需要回写的) dirty page，有可能修改 page 内容的路径是 buffer write(2) 和 mmap write

#### buffer write

buffer write(2) 在写入 page 之后，就会置上 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag

```sh
# filemap based buffer write(2)
f_op->write_iter(kiocb, iov_iter)
    generic_perform_write
        a_ops->write_begin()
            folio = __filemap_get_folio(..., FGP_WRITEBEGIN)
                # find buffer page in page cache
                # lock page
        
        # copy from user buffer to buffer page
        
        a_ops->write_end()
            # mark buffer page and inode as dirty
            folio_mark_dirty(folio)
                a_ops->dirty_folio(), e.g. filemap_dirty_folio
                    folio_test_set_dirty # set PG_dirty
                    __folio_mark_dirty   # set PAGECACHE_TAG_DIRTY
                    __mark_inode_dirty   # add inode to wb's dirty inode list

            folio_unlock # unlock page
```

```sh
# iomap based buffer write(2)
iomap_file_buffered_write
    iomap_iter
        iomap_write_iter
            # prepare for page cache
            iomap_write_begin
                __iomap_get_folio
                    iomap_get_folio
                        __filemap_get_folio(..., FGP_WRITEBEGIN)
                            # find buffer page in page cache
                            # lock page
            
            copy_page_from_iter_atomic // copy to page cache
            
            iomap_write_end
                __iomap_write_end
                    filemap_dirty_folio
                        folio_test_set_dirty # set PG_dirty
                        __folio_mark_dirty   # set PAGECACHE_TAG_DIRTY
                        __mark_inode_dirty   # add inode to wb's dirty inode list

            __iomap_put_folio
                folio_unlock # unlock page
```

#### writeback

之后 writeback 过程中，实际上就是通过 PAGECACHE_TAG_DIRTY tag 寻找所有 (需要回写的) dirty page，并对这些 dirty page 执行回写操作；这一过程中就会清除 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag

> .writepages()

```sh
# writeback: wbc->sync_mode == WB_SYNC_NONE
__writeback_single_inode
    do_writepages
        a_ops->writepages()
            write_cache_pages
                writeback_iter
                    writeback_get_folio
                        filemap_get_folios_tag(..., PAGECACHE_TAG_DIRTY)
                            # find PAGECACHE_TAG_DIRTY pages
                            folio_lock # lock page
                (for each PAGECACHE_TAG_DIRTY page)
                    folio_clear_dirty_for_io
                        folio_test_clear_dirty(folio) # clear PG_dirty
                    
                    # call fs specific writepage()
                        folio_start_writeback(folio)
                            # set PG_writeback
                            # set PAGECACHE_TAG_WRITEBACK tag
                            # clear PAGECACHE_TAG_DIRTY tag
                        folio_unlock # unlock page
                        
                        # send writeback IO
```

> .writepage()

```
# direct reclaim
do_try_to_free_pages
    shrink_zones
        shrink_node
            shrink_node_memcg
                shrink_list
                    shrink_inactive_list
                        shrink_page_list
                            # for each inactive page cache
                                trylock_page(page) # lock page
                                
                                pageout
                                    clear_page_dirty_for_io(page) # clear PG_dirty
                                    
                                    # set PG_Reclaim flag
                                    SetPageReclaim(page)
                                    
                                    a_ops->writepage(page, &wbc)
                                        set_page_writeback(page) # set PG_Writeback
                                        
                                        # writeback dirty page
                                        
                                        unlock_page # unlock page
```

> .launder_page()

```sh
# invalidate page cache
invalidate_inode_pages2_range
    lock_page(page); # wait until others release the lock
    
    # for dirty page, writeback the dirty page
    do_launder_page(mapping, page)
        a_ops->launder_page(page)
            clear_page_dirty_for_io(page) # clear PG_Dirty
            
            folio_start_writeback
                # set PG_writeback
                # set PAGECACHE_TAG_WRITEBACK tag
                # clear PAGECACHE_TAG_DIRTY tag            
            
            # writeback dirty page

    unlock_page # unlock page
```


#### mmap write

在 shared mmap 模式下，用户进程可以直接对 mmap(2) 返回的内存地址作写操作 (mmap write)，这个时候该如何设置对应 page 的 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag 呢？

[title:'MM - 6 Write Protect Page Fault'](mweblib://16212343733707) 中介绍到 mm 层使用一种特殊的机制对 shared mmap 场景下的 dirty page 进行追踪

此时 writeback 的过程中，将回写的 page 对应的 pte 设置为 read-only

```sh
# writeback: wbc->sync_mode == WB_SYNC_NONE
__writeback_single_inode
    do_writepages
        a_ops->writepages()
            write_cache_pages
                writeback_iter
                    writeback_get_folio
                        filemap_get_folios_tag(..., PAGECACHE_TAG_DIRTY)
                            # find PAGECACHE_TAG_DIRTY pages
                            folio_lock # lock page
                (for each PAGECACHE_TAG_DIRTY page)
                    folio_clear_dirty_for_io
                        folio_mkclean
                            # find all vma maping to this page (may belong to multiple processes)
                                page_mkclean_one(page, vma, ...)
                                    # get corresponding pte
                                    entry = ptep_clear_flush(vma, address, pte);
                                    entry = pte_wrprotect(entry); // clean pte's writable
                                    entry = pte_mkclean(entry); 
                                                           
                        folio_test_clear_dirty(folio) # clear PG_dirty
                    
                    # call fs specific writepage()
                        folio_start_writeback(folio)
                            # set PG_writeback
                            # set PAGECACHE_TAG_WRITEBACK tag
                            # clear PAGECACHE_TAG_DIRTY tag
                        folio_unlock # unlock page
                        
                        # send writeback IO
```


之后进程再一次通过 mmap 对该 page 执行写操作时，就会触发 Write Protect Page Fault，其中请求将对应的 pte 重新设置为 writable，这一过程中会调用 .page_mkwrite() 回调函数以通知文件系统，用户进程尝试重新对这个 page 进行置脏；此时 .page_mkwrite() 中就会置上 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag

```sh
# filemap based write protect fault
handle_mm_fault
    __handle_mm_fault
        handle_pte_fault
            # Write Protect: pte exist, pte.P = 1
            do_wp_page
                wp_page_shared
                    do_page_mkwrite
                        vmf->flags = FAULT_FLAG_WRITE|FAULT_FLAG_MKWRITE
                        
                        # notification that a previously read-only page is about to become writable
                        vma->vm_ops->page_mkwrite()
                            iomap_page_mkwrite 
                                folio_lock # lock page                                   
                                return VM_FAULT_LOCKED
                                
                        finish_mkwrite_fault
                            wp_page_reuse
                                entry = pte_mkyoung(vmf->orig_pte);
                                entry = maybe_mkwrite(pte_mkdirty(entry), vma);
                        
                        fault_dirty_shared_page
                            folio_mark_dirty(page)
                                a_ops->dirty_folio(), e.g. filemap_dirty_folio
                                    folio_test_set_dirty # set PG_dirty
                                    __folio_mark_dirty   # set PAGECACHE_TAG_DIRTY
                                    __mark_inode_dirty   # add inode to wb's dirty inode list 
```

```sh
# iomap based write protect fault
handle_mm_fault
    __handle_mm_fault
        handle_pte_fault
            # Write Protect: pte exist, pte.P = 1
            do_wp_page
                wp_page_shared
                    do_page_mkwrite
                        vmf->flags = FAULT_FLAG_WRITE|FAULT_FLAG_MKWRITE
                        
                        # notification that a previously read-only page is about to become writable
                        vma->vm_ops->page_mkwrite()
                            iomap_page_mkwrite 
                                folio_lock # lock page
                                iomap_folio_mkwrite_iter
                                    folio_mark_dirty
                                        a_ops->dirty_folio(), e.g. filemap_dirty_folio
                                            folio_test_set_dirty # set PG_dirty
                                            __folio_mark_dirty   # set PAGECACHE_TAG_DIRTY
                                            __mark_inode_dirty   # add inode to wb's dirty inode list                                    
                                return VM_FAULT_LOCKED
```


### writeback

PG_writeback bit 描述该 page 当前是否处于 writeback 状态 (从发起回写请求开始、到回写 IO 完成结束)，此时在发起回写请求的时候需要置上 PG_writeback，在回写 IO 完成的时候清除 PG_writeback

```c
enum pageflags {
	PG_writeback,		/* Page is under writeback */
	...
}
```

此外使用 PAGECACHE_TAG_WRITEBACK tag 快速追踪 address space 中的所有 PG_writeback 状态的 page


#### start writeback

按照 [title:'Page Cache Consistency - Read'](mweblib://17314844589836#writeback) 中描述的，writeback 过程中会清除 PG_dirty bit 与 PAGECACHE_TAG_DIRTY tag，同时置上 PG_writeback bit 和 PAGECACHE_TAG_WRITEBACK tag


#### writeback IO completion

之后当 writeback 过程发起的 IO 完成时，就会清除对应的 page 本身的 writeback 标记，同时会在 address space 的 @page_tree radix tree 中，清除对应 page 的 PAGECACHE_TAG_WRITEBACK tag 标记

```sh
# when writeback IO finished
end_page_writeback(page)
    folio_end_writeback
        __folio_end_writeback
            folio_xor_flags_has_waiters(folio, 1 << PG_writeback) # clear PG_writeback
            # clear PAGECACHE_TAG_WRITEBACK tag
        
        # wake up waiters on PG_writeback
        folio_wake_bit(folio, PG_writeback)
```


#### disallow duplicate writeback on same page

同一个 page 不允许同时存在多个 writeback IO，即当一个 page 的回写 IO 还没有完成的时候是允许对该 page 执行 buffer 写入操作，即重新将 page 置脏，此时该文件就有可能再次触发回写流程，此时回写流程中检查到该 page 当前有回写 IO 还没有完成的时候，必须等待这个回写 IO 完成之后，才能继续执行这个 page 的回写操作，从而确保同一个 page 在同一时刻只能有一个 inflight writeback IO

```sh
# writeback: wbc->sync_mode == WB_SYNC_NONE
__writeback_single_inode
    do_writepages
        a_ops->writepages()
            write_cache_pages
                writeback_iter
                    writeback_get_folio
                        filemap_get_folios_tag(..., PAGECACHE_TAG_DIRTY)
                            # find PAGECACHE_TAG_DIRTY pages
                            folio_lock # lock page
                            
                            folio_prepare_writeback
                                if folio_test_writeback(folio):
                                    folio_wait_writeback(folio) # wait for writeback completion
                ...
                            
                (for each PAGECACHE_TAG_DIRTY page)
                    folio_clear_dirty_for_io
                        folio_test_clear_dirty(folio) # clear PG_dirty
                    
                    # call fs specific writepage()
                        folio_start_writeback(folio)
                            # set PG_writeback
                            # set PAGECACHE_TAG_WRITEBACK tag
                            # clear PAGECACHE_TAG_DIRTY tag
                        folio_unlock # unlock page
                        
                        # send writeback IO
```


#### wait for writeback IO before freeing page

在释放 page cache 之前都需要等待该 page 的回写 IO 完成，因而可以确保 writeback IO 完成之前 page 是不会被释放的

> direct reclaim

在 direct recliam 中会等待 writeback IO 完成再释放 page

```
# direct reclaim
do_try_to_free_pages
    shrink_zones
        shrink_node
            shrink_node_memcg
                shrink_list
                    shrink_inactive_list
                        shrink_page_list
                            # for each inactive page cache
                                # lock page
                                trylock_page(page)
                                
                                if folio_test_writeback(folio):
                                    # skip this page, or
                                    folio_wait_writeback(folio) # wait for writeback completion

                    ...
                    # free page
```

> invalidate page cache: invalidate_inode_pages2()

在 invalidate page cache 过程中会等待 writeback IO 完成再释放 page

```sh
# page cache based
invalidate_inode_pages2_range
    # wait until others release the lock
    lock_page(page);
    
    folio_wait_writeback # wait for writeback IO completion
    
    invalidate_complete_page2(mapping, page)
        # delete page from address space,
        # and drop one refcount
    
    pagevec_release
        # drop last refcount, and thus free page cache
```

> truncate: truncate_inode_pages()

在 truncate(2) 使文件缩小时，将 newsize 之后的 page cache 释放掉的时候，会等待 writeback IO 完成再释放 page

```
# truncate(2) syscall
    vfs_truncate
        do_truncate
            newattrs.ia_valid = ATTR_SIZE
            notify_change
                i_op->setattr()
                    # if truncate:
                        truncate_pagecache
                            truncate_inode_pages
                                # Pass 1: skip locked page and page under writeback
                                ...
                        
                                # Pass 2: truncate locked page and page under writeback
                                for (;;) {
                                    # for locked page
                                    lock_page(page) // wait until page unlocked by others
                                    
                                    # for page under writeback
                                    wait_on_page_writeback(page) // wait until writeback completed
                                    
                                    truncate_inode_page // delete from address space
                                    pagevec_release // free page cache
                                }
```

> evict: truncate_inode_pages()

evict() 流程中释放掉文件的所有 page cache 的时候，会等待 writeback IO 完成再释放 page

```sh
# evict
    s_op->evict_inode(), or truncate_inode_pages_final()
        truncate_inode_pages
            # Pass 1: skip locked page and page under writeback
            ...
    
            # Pass 2: truncate locked page and page under writeback
            for (;;) {
                # for locked page
                lock_page(page) // wait until page unlocked by others
                
                # for page under writeback
                wait_on_page_writeback(page) // wait until writeback completed
                
                truncate_inode_page // delete from address space
                pagevec_release // free page cache
            }
```


#### PAGECACHE_TAG_TOWRITE

PAGECACHE_TAG_TOWRITE tag 标记是为了解决 writeback 回写过程中潜在的 livelock 问题而引入的

> background of livelock

考虑以下 write_cache_pages() 实现的 writeback 回写过程，其中实际上就是扫描 address space 的 @page_tree radix tree 中的 DIRTY page，对其中的每个 DIRTY page 执行回写操作，直到回写 @nr_to_write 数量的 DIRTY page

```c
write_cache_pages
{
	while (!done && (index <= end)) {
		pagevec_lookup_range_tag(..., PAGECACHE_TAG_DIRTY);
		
		for (i = 0; i < nr_pages; i++) {
		   
		   # writeback one page
			
			if (--wbc->nr_to_write <= 0) {
				done = 1;
				break;
			}
		}
	}
}
```

如果 @sync_mode 为 WB_SYNC_ALL，那么此时 @nr_to_write 通常是 LONG_MAX，上述 write_cache_pages() 运行过程中如果对应的文件又源源不断地产生新的 dirty page，那么 write_cache_pages() 就会长时间陷于 while 循环中，也就是所谓的 livelock 问题


> page cache writeback

PAGECACHE_TAG_TOWRITE tag 标记的引入正是为了解决上述的 livelock 问题

此时在 page cache writeback 过程中，会扫描 address space 的 @page_tree radix tree 中的 PAGECACHE_TAG_DIRTY page，对其中的每个 DIRTY page 打上 PAGECACHE_TAG_TOWRITE 标记

之后扫描 address space 的 @page_tree radix tree 中的 PAGECACHE_TAG_TOWRITE page，只会对 TOWRITE page 执行回写操作，这样新产生的 DIRTY page 并不会执行回写操作，从而避免了 livelock 问题

之后对于执行过回写的 TOWRITE page，再清除其 PAGECACHE_TAG_TOWRITE 标记

```sh
# wbc->sync_mode == WB_SYNC_ALL
__writeback_single_inode
    do_writepages
        a_ops->writepages(), i.e., ext4_writepages
            generic_writepages
                write_cache_pages
                    tag_pages_for_writeback // all PAGECACHE_TAG_DIRTY pages are tagged with PAGECACHE_TAG_TOWRITE
                    pagevec_lookup_range_tag(..., PAGECACHE_TAG_TOWRITE) // find PAGECACHE_TAG_TOWRITE pages
                    
                    (for each PAGECACHE_TAG_TOWRITE page)
                        lock_page(page) // acquire PG_locked in @page->flags                      
                        clear_page_dirty_for_io(page) // clear PG_dirty in @page->flags
                        __writepage
                            a_ops->writepage(page, ...), e.g., ext4_writepage
                                ext4_bio_write_page
                                    set_page_writeback(page)
                                        __test_set_page_writeback
                                            TestSetPageWriteback(page) // set PG_writeback in @page->flags
                                            # mark PAGECACHE_TAG_WRITEBACK tag
                                            # clear PAGECACHE_TAG_DIRTY tag
                                            # clear PAGECACHE_TAG_TOWRITE tag
                                    (for each bh of this page) io_submit_add_bh(..., page, bh)
                                        bio_add_page(io->io_bio, page, bh->b_size, bh_offset(bh))
                                        
                                    unlock_page(page) // release PG_locked in @page->flags
                                ext4_io_submit
                                    submit_bio(io->io_bio)
```

#### PG_writeback

开始 writeback 的时候会给 page 置上 PG_writeback，writeback 完成的时候清楚 PG_writeback，以上两个操作都需要持 page lock 进行互斥

- set PG_writeback: direct reclaim -> writepage()
此时 a_ops->writepage() 执行过程中全程都是持有 page lock 的
```
do_try_to_free_pages
    shrink_zones
        shrink_node
            shrink_node_memcg
                shrink_list
                    shrink_inactive_list
                        shrink_page_list
                            # for each inactive page cache
                                # lock page
                                trylock_page(page)
                                
                                pageout
                                    # Clear a page's dirty flag
                                    clear_page_dirty_for_io(page)
                                    
                                    # set PG_Reclaim flag
                                    SetPageReclaim(page)
                                    
                                    a_ops->writepage(page, &wbc)
                                        # set PG_Writeback flag
                                        set_page_writeback(page)
                                        
                                        # don't wait for writeback completion
                                        
                                        # unlock page
                                        # return 0
                                
```

- set PG_writeback: migration -> writepage()
migration/compaction 过程中当文件系统未实现 a_ops->migratepage() 时，就会调用 a_ops->writepage()，此时 a_ops->writepage() 执行过程中全程都是持有 page lock 的

```
# zoned page frame allocator
alloc_pages
    __alloc_pages_noprof
        # no free page, and thus go to slow path
        __alloc_pages_slowpath
            # first pass: async compaction
            __alloc_pages_direct_compact(..., COMPACT_PRIO_ASYNC)
                try_to_compact_pages
                    # for each zone:
                        compact_zone_order
                            # mode = MIGRATE_ASYNC, since COMPACT_PRIO_ASYNC
                            compact_zone
                                # scan whole zone to find all used movable pages (to be migrated)
                                # store all found migrate pages in cc->migratepages list
                                isolate_migratepages
                                
                                migrate_pages(&cc->migratepages, ...)
                                    # do async migration
                                    migrate_pages_batch(..., MIGRATE_ASYNC, ...)
                                        # 1. remove mapping for all src pages
                                        # for each folio in cc->migratepages list:
                                            migrate_folio_unmap
                                                # 1.1 alloc dst folio
                                                compaction_alloc
                                                    # alloc dst folio from cc->freepages[order] list,
                                                    # refill cc->freepages[order] list (if empty) by scanning
                                                    # whole zone to find all free pages
                                                
                                                # 1.2 lock src folio
                                                    # if trylock failed (in async migration), return -EBUSY
                                                    
                                                # 1.3 ensure folio is not under writeback
                                                    # if folio is under writeback (in async migration),
                                                    # don't wait for writeback IO completion and return -EBUSY
                                                
                                                # 1.4 replace all page table mappings with swap entries
                                                try_to_migrate
                                                
                                                
                                        # 2. move src folio to dst folio
                                        # for each previously unmapped page:
                                            migrate_folio_move(..., src, dst, ...)
                                                move_to_new_folio
                                                    # if src folio is page cache:
                                                        fallback_migrate_folio
                                                            # if page is dirty:
                                                                writeout
                                                                    a_ops->writepage(src, ...)
                                                                        # set PG_Writeback flag
                                                                        set_page_writeback(page)
                                                                        
                                                                        # don't wait for writeback completion
                                                                        
                                                                        # unlock page
                                                                        # return 0
                                                                    
                                                                    # relock page
                                                                    folio_lock(src)
                                    
                                # move all failed pages (since -EBUSY error in async migration)
                                # back to original place, and they will be skipped and not freed
                                putback_movable_pages    
```


- set PG_writeback: page cache invalidation -> launder_page()
invalidate_inode_pages2() 用于移除 (invalidate) address space 中的所有 page cache，其中就会调用 a_ops->launder_page()，这一过程中全程都是持有 page lock 的

```sh
# page cache based
invalidate_inode_pages2_range
    # wait until others release the lock
    lock_page(page);
    
    # for page under writeback
    wait_on_page_writeback(page) // wait until writeback completed
    
    # for file memory mapped page
    unmap_mapping_pages // unmap
    
    # for dirty page, writeback the dirty page
    do_launder_page(mapping, page)
        a_ops->launder_page(page)
            # clear PG_Dirty flag
            clear_page_dirty_for_io(page)
            
            # set PG_Writeback flag
            set_page_writeback(page)
            
            # writeback dirty page
            # wait for writeback IO completion
            
            # return without unlocking page
    
    # reclaim clean page
    invalidate_complete_page2(mapping, page)
        # there's block buffer list for FIEMAP,
        # or 'struct iomap_page' for IOMAP
        if page_has_private(page):
            try_to_release_page
                a_ops->releasepage()
                    try_to_free_buffers(page)
                        drop_buffers(page)
                        # if all buffer heads are not busy, i.e., refcount of buffer head is 0
                        (for each buffer head) free_buffer_head // free buffer head
            
            # if releasepage() succeed, i.e., all buffer heads are not busy and thus freed
            
            __delete_from_page_cache(page, ...) // delete from address space
            a_ops->freepage(), usually NULL
    
    pagevec_release // free page cache
```


- clear PG_writeback

writeback IO 完成的时候会调用 end_page_writeback() 清除 PG_writeback 标记，这一过程是可以不持有 page lock 的




### DIRECT IO & page cache

DIRECT IO 过程中需要确保内核中缓存的所有 dirty page cache 回写到磁盘上，这样才能防止发生 data corruption

> DIRECT read

DIRECT read(2) 过程中在下发 DIRECT IO 之前，需要 1) 回写 dirty page，并 2) 等待回写 IO 完成

```sh
# filemap based DIRECT read(2)
f_op->read_iter(iocb, iter), e.g. generic_file_read_iter()
    kiocb_write_and_wait
        filemap_write_and_wait_range
            __filemap_fdatawrite_range # writeback dirty page cache
            __filemap_fdatawait_range # wait for writeback completion
                   
    # do DIRECT write
    a_ops->direct_IO()
```


```sh
# iomap based DIRECT read(2)
.read_iter()/.write_iter()
    # for DIRECT IO
    iomap_dio_rw
        __iomap_dio_rw
            # for DIRECT read:
            kiocb_write_and_wait
                __filemap_fdatawrite_range # writeback dirty page cache
                __filemap_fdatawait_range # wait for writeback completion
            
            # do DIRECT read
```


> DIRECT write

DIRECT write(2) 过程中在下发 DIRECT IO 之前，和 DIRECT read 一样需要 1) 回写 dirty page，并 2) 等待回写 IO 完成；此外还需要将当前写入范围内的 page cache invalidate 掉，从而确保后续的 buffer read(2) 操作会从磁盘读取到最新的数据

```sh
# filemap based DIRECT write(2)
f_op->write_iter(kiocb, iov_iter), e.g. generic_file_write_iter()
    generic_file_direct_write
        kiocb_invalidate_pages
            filemap_invalidate_pages
                filemap_write_and_wait_range
                    __filemap_fdatawrite_range # writeback dirty page cache
                    __filemap_fdatawait_range # wait for writeback completion
                
                # After a write we want buffered reads to be sure to go to disk to get
                # the new data.  We invalidate clean cached page from the region we're
                # about to write.
                invalidate_inode_pages2_range
        
        # do DIRECT write
        a_ops->direct_IO()
```

