## Block - DISCARD - Segments


有些 IO controller 支持在单个 DISCARD request 中同时对多个非连续的 sector range 执行 discard 操作，@max_discard_segments 参数就描述了这一限制，即单个 DISCARD request 可以包含的 sector range 数量的上限

DISCARD bio 不带有 payload，其 bio_vec 数组为空，此时一个 bio 就只是描述一段需要执行 DISCARD 操作的 sector range




DISCARD request 实际上复用了 @nr_phys_segments 字段来描述该 request 包含的 sector range 的数量

```c
struct request {
	/*
	 * Number of scatter-gather DMA addr+len pairs after
	 * physical address coalescing is performed.
	 */
	unsigned short nr_phys_segments;
	...
};
```



### request calculation

在 bio 封装为 request 的过程中，DISCARD request 的 @nr_phys_segments 字段被初始化为 1

```
    blk_mq_bio_to_request
        blk_init_request_from_bio
            blk_rq_bio_prep
                rq->nr_phys_segments = 1
```


### merge when @max_discard_segments > 1

前面介绍过，有些 IO controller 支持在单个 DISCARD request 中同时对多个非连续的 sector range 执行 DISCARD 操作，@limits.max_discard_segments 参数就描述了这一限制，即单个 DISCARD request 可以包含的 sector range 数量的上限；如果该参数为 1，则说明单个 DISCARD request 中只能包含一段连续的 sector range

@limits.max_discard_segments 参数的不同，直接导致了 request 合并（包括 bio 与 request 合并、requests 之间的合并）过程中行为的差异


首先介绍 @max_discard_segments 大于 1 时的行为，此时一个 request 可以包含多个非连续的 sector range，同时不会对相邻的两个 bio 的 sector range 进行合并，而无论这两个 bio 描述的 sector range 是否连续，此时 req->nr_phys_segments 的值就等同于该 request 中包含的 bio 的数量

为什么不把 sector range 连续的两个 bio 合并为一个 sector range 呢？

可能是因为 DISCARD IO 与普通的 READ/WRITE IO 存在差异。普通的 READ/WRITE IO 可能存在比较多的小 IO，将其中物理地址连续的小 IO 合并为一个 physical segment 对于性能提升是有益的；而 DISCARD IO 在下发下来的时候，通常就已经是一个 sector 地址连续的单个的大 IO，此时再尝试将多个连续的 sector range 合并为一个 sector range，可能收益不大

此外当 @limits.max_discard_segments 参数大于 1 时，IO controller 本身就支持单个 DISCARD request 中包含多个非连续的 sector range，由于 DISCARD IO 通常都是 sector 地址连续的大 IO，因而即使将一个 bio 就视为一个独立的 sector range，一个 DISCARD request 中包含的 bio 的数量可能都小于 @limits.max_discard_segments 参数的值，无需执行 sector range 的合并操作


> bio & request merge

此时 request 与 bio 合并过程中，req->nr_phys_segments 的值总是直接加 1，而无论新合入的 bio 描述的 sector range 是否与之前的 sector range 相连续

```
blk_mq_bio_list_merge
    bio_attempt_discard_merge
        req->nr_phys_segments += 1
```


> requests merge

当 @limits.max_discard_segments 参数大于 1 时，对于 DISCARD request 来说，是不存在 requests 之间的合并的


### merge when @max_discard_segments == 1

而当 @max_discard_segments 参数等于 1 时，其行为就复杂很多。

#### old routine

当 @max_discard_segments 参数等于 1 时，DISCARD request merge 会复用 normal READ/WRITE request 的 front/back merge 的路径

此时一个 DISCARD request 仍然可以包含多个 bio，但是这些 bio 的 sector range 必须是连续的，即多个 bio 仍然组成**一个**连续的 sector range，也就是说这个时候是会对相邻的两个 bio 的 sector range 进行合并操作的


同时在 single-page bvec 年代，struct bio 还维护有 @bi_phys_segments 字段描述该 bio 包含的 physical segment 的数量，此时 DISCARD bio 会复用该字段来描述其包含的需要执行 DISCARD 操作的 sector range 的数量

由于一个 DISCARD bio 就描述一段执行 DISCARD 操作的 sector range，因而其 @bi_phys_segments 字段的值只能为 1

bio->bi_phys_segments 字段的值在 bio split 路径中初始化，其初始值为 1

```
blk_mq_make_request
    blk_queue_split
        blk_bio_discard_split
            *nsegs = 1
```


> bio & request merge

此时 request 与 bio 合并过程中，@req->nr_phys_segments 字段会加上合并的 @bio->bi_phys_segments 的值，由于 DISCARD bio 的 @bi_phys_segments 字段的值均为 1，因而 @req->nr_phys_segments 字段的值实际上也就是加 1

```
blk_mq_bio_list_merge
    bio_attempt_back_merge
        ll_back_merge_fn
            ll_new_hw_segment
                req->nr_phys_segments += bio->bi_phys_segments
```

因而需要注意的是，无论 @max_discard_segments 参数是否大于 1，request->nr_phys_segments 的值实际上都会随着 request 中包含的 bio 数量的增加而增加，因而严格意义上 @req->nr_phys_segments 并不是描述 request 中包含的非连续 sector range 的数量


> requests merge

值得一提的是，当 @max_discard_segments 参数等于 1 时，bio 与 request 的合并走的是 normal READ/WRITE request 合并的路径，也就是 front/back merge 的路径，这也就直接导致了会走到 requests 合并的路径

在 4.19 版本内核中，两个 DISCARD requests 合并过程中，合并后的 @req->nr_phys_segments 会减 1，这也就直接导致了合并后 @req->nr_phys_segments 的值比 request 中包含的 bio 的数量小 1

```
ll_merge_requests_fn
    total_phys_segments = req->nr_phys_segments + next->nr_phys_segments
    if (blk_phys_contig_segment()) total_phys_segments--
    req->nr_phys_segments = total_phys_segments
```


#### new routine

值得一提的是，block driver 在处理 DISCARD request 时，会期待 @req->nr_phys_segments 的值与 request 中包含的 bio 数量相等

当 @max_discard_segments 参数大于 1 时，自然是满足以上条件的

但是当 @max_discard_segments 参数等于 1 时，以上条件就不满足了，因为此时 DISCARD bio 会走 normal READ/WRITE 的 front/back merge 路径，这就导致了 DISCARD request 的 @nr_phys_segments 字段的值仍为 1，但是其中可能包含多个 DISCARD bio

因而 commit 943b40c832beb71115e38a1c4d99b640b5342738 ("block: respect queue limit of max discard segment") 修复了以上问题，自此当 @max_discard_segments == 1 时，DISCARD bio 不会再走到 normal READ/WRITE 的 front/back merge 路径


> bio & request merge

即此时不存在 bio 与 requests 之间的合并的

```sh
blk_mq_submit_bio
    blk_attempt_plug_merge
        blk_attempt_bio_merge
            bio_attempt_back_merge
                ll_back_merge_fn
                    ll_new_hw_segment
                        if (req->nr_phys_segments + nr_phys_segs > blk_rq_get_max_segments(req))
                            goto no_merge;
```

blk_rq_get_max_segments() 的定义为

```c
blk_rq_get_max_segments(struct request *rq)
	if (req_op(rq) == REQ_OP_DISCARD)
		return queue_max_discard_segments(rq->q);

```

也就是说，当 @max_discard_segments == 1 时，DISCARD bio 与 requests 之间不会合并


> requests merge

此时也不再存在 requests 之间的合并

```sh
blk_mq_submit_bio
    blk_attempt_plug_merge
        blk_attempt_bio_merge
            blk_mq_sched_allow_merge
                ll_merge_requests_fn
                    total_phys_segments = req->nr_phys_segments + next->nr_phys_segments
                    if (total_phys_segments > blk_rq_get_max_segments(req))
                        return 0;
```


### device driver calculation

需要注意的是，以上描述的 @req->nr_phys_segments 的计算规则都是 block layer 的行为

而 nvme/virtio-blk driver 在处理 DISCARD request 时，会期待 @req->nr_phys_segments 的值与 request 中包含的 bio 数量相等

```
virtio_queue_rq
    virtblk_setup_discard_write_zeroes
        segments = blk_rq_nr_discard_segments(req)
        range = kmalloc_array(segments, ...)
        __rq_for_each_bio(bio, req) {
            range[n].sector = ;
            ...
        }
```


