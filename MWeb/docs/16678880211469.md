title:'IO - large folio'
## IO - large folio

文件系统传入的 folio 可能是 large folio，即大于 PAGE_SIZE

该特性当前依赖于 THP (transparent hugepage) (只需要开启 CONFIG_TRANSPARENT_HUGEPAGE)，该特性才能启用

此外只有当下面的文件系统支持 large folio 时，VFS 层才会向下面的文件系统传递 large folio，支持 large folio 的文件系统需要调用 mapping_set_large_folios() 以声明该能力

```
xfs_inode_alloc
    # Indicate the file supports large folios
    mapping_set_large_folios(inode's i_mapping)
        # min_order: 0
        # max_order: MAX_PAGECACHE_ORDER
        mapping_set_folio_order_range(mapping, 0, MAX_PAGECACHE_ORDER)
            mapping->flags |= (min << AS_FOLIO_ORDER_MIN) | (max << AS_FOLIO_ORDER_MAX)
```

此时 mapping->flags 的 bit 16~20 用于存储 min_order，bit 21~25 用于存储 max_order

默认情况下 mapping->flags 的 min_order 和 max_order 都是 0，也就是用于 page cache 分配的 folio 都是 PAGE_SIZE 的；而在支持 large folio 的时候，mapping->flags 的 max_order 变为 MAX_PAGECACHE_ORDER，也就是用于 page cache 分配的是 large folio 


支持 large folio 的主要工作是，在往 address space 新插入 page cache 的时候，确保 page cache 是分配成 large folio 的，此时复用 fgp_flags 的高 6 bits 描述当前 __filemap_get_folio() 想要分配的 large folio 的 order

```c
struct folio *__filemap_get_folio(struct address_space *mapping, pgoff_t index,
		fgf_t fgp_flags, gfp_t gfp)
```

```c
#define FGF_GET_ORDER(fgf)      (((__force unsigned)fgf) >> 26) /* top 6 bits */
```


### buffer read

#### readahead

v5.18 引入的 commit 793917d997df ("mm/readahead: Add large folio readahead") 使得 readahead 路径支持 large folio

readahead 支持 large folio 的入口主要是 page_cache_ra_order(..., order)，其 order 参数就描述了需要当前分配的 page cache 的大小

> sync readahead

```sh
filemap_read
    filemap_get_pages
        filemap_get_read_batch  // find page cache
        (find no page) page_cache_sync_readahead
            page_cache_sync_ra
                # it's sequential READ
                ra->size = ... // calculate readahead window size
                page_cache_ra_order(..., ra, 0)
```

> async readahead

```sh
filemap_read
    filemap_get_pages
        filemap_get_read_batch  // find page cache
        (found，and hit PG_readahead) filemap_readahead
            page_cache_async_ra
                ra->size = ... // calculate readahead window size
                page_cache_ra_order(..., ra, filio_order(folio))
    
```


> page_cache_ra_order

readahead 支持 large folio 的入口主要是 page_cache_ra_order()，如果下面的文件系统不支持 large folio，那么会回退到原来的 do_page_cache_ra()，也就是不开启 large folio

```sh
ra->size = ... // calculate readahead window size
page_cache_ra_order(..., ra, ...)
    if !mapping_large_folio_support(mapping):
        # fallback to do_page_cache_ra()
```

而如果下面的文件系统支持 large folio，那么就会尝试分配 large folio。sync readahead 调用 page_cache_ra_order() 的时候，传入的 order 参数总是 0，因而 page_cache_ra_order() 中会分配 order=2 的 large folio；而 async readahead 调用 page_cache_ra_order() 的时候，传入的 order 参数为触发 async readahead 的那个 folio 的 order，也就是前面一个 folio 的 order，此时 page_cache_ra_order() 中分配的 large folio 的大小就是，上一个 folio 的 order 再加上 2，当然前提是分配的 large folio 的大小不能超过 readahead window 的大小

```sh
ra->size = ... // calculate readahead window size
page_cache_ra_order(..., ra, order)
    if mapping_large_folio_support(mapping):
        if order < mapping_max_folio_order(mapping):
            order += 2  // increasing folio size (large folio)
            
        order = min(order, mapping_max_folio_order(mapping))
        order = min_t(unsigned int, new_order, ilog2(ra->size)); // fit to readahead window size
        order = max(order, mapping_min_folio_order(mapping)) 
        
        ra_alloc_folio(..., order) // then allocate large folio
        read_pages // read data into large folio
```


#### buffer read

v5.17 buffer read (filemap_read) 支持 (large) folio-based data copy
> d996fc7f615f filemap: Convert filemap_read

```sh
f_op->read_iter(kiocb, iov_iter), e.g. generic_file_read_iter
    # for buffer read:
    filemap_read
        filemap_get_pages
            # readahead (large) folio
    
        # copy to user buffer
        copy_folio_to_iter
```


### mmap fault

#### readahead

在发生 fault 的时候，需要调用 vm_ops->fault() 回调函数 (一般是 filemap_fault()) 找到对应的 page cache，也就是在文件的 address space 中寻找当前触发 page fault 的地址对应的 page；如果 address space 中还没有对应的 page，就需要创建对应的 page，并执行 IO 操作，这一过程中通常会触发 readahead，就会在 readahead 路径中创建 large folio

v5.18 mmap fault 的 readahead 路径开始支持 large folio
> 56a4d67c264e mm/readahead: Switch to page_cache_ra_order

##### sync readahead

page fault 路径中会首先到 page cache 中查找当前触发 page fault 的地址对应的 page，如果 page cache 中找不到对应的 page (例如 mmap 之后第一次访问)，那么就会触发 sync readahead

```sh
filemap_fault
    find_get_page   // find page in page cache
    (find no page) do_sync_mmap_readahead
        ra->size = ... // calculate readahead window size
        page_cache_ra_order(..., ra, 0)
```

##### async readahead

上述 sync readahead 路径中，readahead window 往前 @async_size 偏移处对应的**一个** page 会被标记为 PG_readahead，这个标记就与之后的 async readahead 相关

之后当这个标记为 PG_readahead 的 page 触发 page fault 的时候，就会触发 async readahead

```sh
filemap_fault
    find_get_page   // find page in page cache
    (find page) do_async_mmap_readahead
        (if PageReadahead(page)) page_cache_async_readahead
            page_cache_async_ra
                ra->size = ... // calculate readahead window size
                page_cache_ra_order(..., ra, folio_order(folio))
```

#### setup page table

在 vm_ops->fault() 回调函数创建了对应的 large folio、并执行 IO 操作读取对应的数据之后，（找到的对应的 page 就保存在 vmf->page 中）回到 page fault handler 中调用 finish_fault() 去完成 pte 的设置

v6.6 就支持对当前触发 fault 找到的 large folio (vmf->page) 中可能包含的多个 page 同时设置 page table
> 3bd786f76de2 mm: convert do_set_pte() to set_pte_range()

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        __handle_mm_fault
            p4d_alloc(), pud_alloc(), pmd_alloc() // allocate pgd/pud/pmd table
            handle_pte_fault
                do_fault // file memory mapping
                    do_read_fault
                        __do_fault
                            vma->vm_ops->fault(vmf), e.g. filemap_fault()
                                # find page at vmf->pgoff index
                                # lock the found page
                                vmf->page = found page  
                                return VM_FAULT_LOCKED
                        
                        finish_fault(vmf)
                            # since vmf->pmd is valid and points to a PMD table
                            vmf->pte = ... // points to the pte inside the PMD table
                            set_pte_range(vmf, folio, page, nr_pages, ...)
```



### buffer write

此时 buffer write 路径中，当 cache miss 需要分配 page cache 的时候，就会分配 large folio，其大小取决于当前 buffer write 的长度

#### iomap-based buffer write

v6.6 iomap-based buffer write 路径开始支持 large folio
> commit d6bb59a9444d ("iomap: Create large folios in the buffered write path")

```sh
iomap_file_buffered_write
    iomap_iter
        iomap_write_iter
            iomap_write_begin(iter, pos, len, ...)
                 # find page cache in page cache,
                 # create new page cache if not exist
                 folio = __iomap_get_folio(iter, pos, len)
                    iomap_get_folio(iter, pos, len)
                        fgp |= fgf_set_order(len)
                        __filemap_get_folio(..., fgp, ...)
                            order = FGF_GET_ORDER(fgp)
                            order = min(order, mapping_max_folio_order(mapping))
                            folio = filemap_alloc_folio(..., order)
```


#### filemap-based buffer write

v6.6 支持 __filemap_get_folio() 接口分配 large folio
> commit 4f6617011910 ("filemap: Allow __filemap_get_folio to allocate large folios")

v6.11 filemap-based buffer write 路径开始支持 (large) folio-based data copy
> commit 9aac777aaf94 ("filemap: Convert generic_perform_write() to support large folios")

v6.12 a_ops->write_begin|end() 回调函数转换为 folio 接口
> 1da86618bdce fs: Convert aops->write_begin to take a folio
> a225800f322a fs: Convert aops->write_end to take a folio
> a060d835cf76 fuse: Convert fuse_write_begin() to use a folio
> 556d0ac068d7 fuse: Convert fuse_write_end() to use a folio

```sh
f_op->write_iter(kiocb, iov_iter), e.g. generic_file_write_iter()
    __generic_file_write_iter
        # for buffer write:
        generic_perform_write
            a_ops->write_begin(pos, len) // find buffer page in page cache
                fgp |= fgf_set_order(len)
                __filemap_get_folio(index, fgp, ...)
                    order = FGF_GET_ORDER(fgp)
                    order = min(order, mapping_max_folio_order(mapping))
                    folio = filemap_alloc_folio(..., order)
                    
            copy_folio_from_iter_atomic // copy from user buffer to buffer page
            
            a_ops->write_end() // mark buffer page and inode as dirty

    generic_write_sync // flush page cache if it's DSYNC
```


