title:'3 DAX - fsdax - mmap'
## 3 DAX - fsdax - mmap

### mmap syscall

file memory mapping 处理过程中，mmap() 系统调用中会将 vma->vm_ops 设置为 DAX 版本的 vma_ops，例如 ext4_dax_vm_ops

```sh
mmap()
    ksys_mmap_pgoff
        vm_mmap_pgoff
            do_mmap
                get_unmapped_area   // allocate virtual address
                mmap_region
                    // allocate vma
                    file->f_op->mmap(), i.e., ext4_file_mmap()
                        vma->vm_ops = &ext4_dax_vm_ops // when DAX enabled
```


### page fault - entry

file memory mapping 中只是为用户进程地址空间分配虚拟地址区间，尚未设置对应的 page table 建立映射；之后当发生 page fault 时，就会调用 vm_ops->fault() 回调函数

在普通模式下该回调函数用于将当前访问的 page 添加到文件的 page cache 中，之后设置 pmd/pte 使得该虚拟地址区间映射到这个 page cache 中的 physical page frame

而在 DAX 模式下发生 page fault 时，首先通过 iomap 机制计算当前发生 page fault 的文件偏移在 NVDIMM 物理地址空间内的物理地址 (PFN)，之后就是设置相应的 pmd/pte，使得当前发生 page fault 的虚拟地址映射向 NVDIMM 中的物理地址 (PFN)

以上地址映射关系建立之后，CPU 对该虚拟地址区间的内存操作，实际上就是对 NVDIMM 设备内的存储单元的直接操作

根据当前系统的配置，有 pte fault 与 pmd fault 两个入口

#### pte fault

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault // file memory mapping
                do_read_fault
                    vma->vm_ops->fault(), that is, ext4_dax_fault()
                        dax_iomap_fault
                            dax_iomap_pte_fault
```


#### pmd fault

当开启 huge page 的时候，以下情况下会优先走 pmd fault

- /sys/kernel/mm/transparent_hugepage/enabled 配置为 "always"
- 触发 page fault 的文件处于 DAX 模式
- /sys/kernel/mm/transparent_hugepage/enabled 配置为 "madvise"，此时查询触发 page fault 的 vma 的 @vm_flags 标志位是否含有 VM_HUGEPAGE 标志

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        # if /sys/kernel/mm/transparent_hugepage/enabled == "always"
        # or /sys/kernel/mm/transparent_hugepage/enabled == "madvise" and vma->vm_flags & VM_HUGEPAGE
        # or vma_is_dax(vma)
            create_huge_pmd
                vma->vm_ops->huge_fault()
                    dax_iomap_fault // with @pe_size = PE_SIZE_PMD
                        dax_iomap_pmd_fault
```


这里需要注意的是，dax page fault 中会调用 iomap_ops->iomap_begin() 计算当前触发 page fault 的 file offset 对应的在 NVDIMM 中的物理地址，其中如果当前是 write 操作触发的 page fault，那么 iomap_ops->iomap_begin() 中会分配 NVDIMM 中相应的空间以用于映射

这里分配的 NVDIMM 中的空间必须按照 PMD 对齐，否则 page fault 最终会回退到 pte fault

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        __handle_mm_fault
            create_huge_pmd
                vma->vm_ops->huge_fault()
                    dax_iomap_fault // with @pe_size = PE_SIZE_PMD
                        dax_iomap_pmd_fault
                            iomap_ops->iomap_begin(..., &iomap)
                            dax_iomap_pfn
                                dax_direct_access
                                    if (pfn_t_to_pfn(*pfnp) & (PHYS_PFN(size)-1)) // iomap->addr not aligned on PMD boundary:
                                        iomap_ops->iomap_end()
                                        return VM_FAULT_FALLBACK
            # fallback to pte fault
            handle_pte_fault
```


### page fault - routine

以下以 pte fault 为例，介绍 page fault 的主要流程

```sh
dax_iomap_pte_fault
    # 1. calculate relative sector address in NVDIMM
    iomap_ops->iomap_begin() // get sector address in NVDIMM of current file offset
    
    # 2. calculate absolute physical address (PFN) in NVDIMM
    dax_iomap_pfn
        dax_direct_access
            dax_dev->ops->direct_access(dax_dev, pgoff, ..., pfnp), i.e., pmem_dax_direct_access()
                *pfnp = pmem->phys_addr + PFN_PHYS(pgoff) + pmem->data_offset // calculate physical address in NVDIMM

    # 3. insert mapping entry into address space
    dax_insert_entry(mapping, ..., entry, pfn)
        new_entry = dax_radix_locked_entry(pfn, flags); // construct new entry from pfn
        __radix_tree_replace(..., new_entry, ...);
    
    # 4. insert pte into page table
    vmf_insert_mixed
        insert_pfn(vma, addr, pfn, pgprot, mkwrite)
            pte = get_locked_pte(mm, addr, ...)
            pte_mkspecial(pfn_t_pte(pfn, prot))
```

1. calculate sector address

首先调用 iomap_ops->iomap_begin() 回调函数计算当前触发 page fault 的 file range 对应的 sector address

需要注意的是如果当前是 write 操作触发的 page fault，那么 iomap_ops->iomap_begin() 中可能会分配 NVDIMM 中相应的存储空间以用于映射

2. calculate PFN

之后调用 dax_ops->direct_access() 回调函数将 sector address 翻译为系统全局的物理地址 (PFN)

3. insert mapping entry into address space

之后根据 PFN 构建相应的 mapping entry 并添加到文件的 address space 中

4. insert pte into page table

同样根据 PFN 构建相应的 pte entry，添加到当前触发 page fault 的进程的 page table 中


### shared file mmap

#### writeback introduction

shared file mmap 需要考虑的一个问题就是 dirty pagecache 的 writeback。shared file mmap 是直接映射到文件的 page cache 的，用户进程对这一映射区域的更改需要保存到原文件，即 dirty pagecache 需要回写

DAX 模式下虽然 bypass 了 pagecache，用户进程是将数据直接写入 NVDIMM 存储单元，但是实际上也存在 writeback 的概念。虽然 NVDIMM 本身就有可持久化的特性，但是处理器是按照访问内存的方式来访问 NVDIMM 的，而由于多级缓存的特性，处理器写入的数据有可能保留在处理器缓存中，尚未下刷到 NVDIMM，此时内核需要显式地调用 clwb (cache line writeback) 或 clflush (cache line flush) 指令将处理器缓存中的数据下刷到 NVDIMM

而 writeback 又必然要求在 address space 中维护相应的 mapping entry。我们回想一下普通模式下 pagecache 是如何完成回写操作的。普通模式下，文件的 address space 中维护了所有的 pagecache，pagecache 被执行 write 操作的时候，其在 @i_pages radix tree 中的对应位置就会置上 DIRTY tag 标记，之后的 pagecache writeback 流程就是依靠 @i_pages radix tree 中的 DIRTY tag 来找到所有需要回写的 page cache，并对其进行回写操作


因而 DAX 模式下文件的 address space 也需要维护相应的 mapping entry。只是此时 @i_pages radix tree 中保存的不再是 page cache，而是这一段 file range 在 NVDIMM 上对应的一段存储单元的系统全局的物理地址 (PFN, page frame number)，同时仍然通过 radix tree 的 Dirty tag 来标识需要回写的 dirty page

此时 radix tree 中存储的是 exceptional entry，其格式为

```
+-----------------------+-------+-----------+-----+------+--------+
|           PFN         | EMPTY | ZERO_PAGE | PMD | LOCK | 2 bits |
+-----------------------+-------+-----------+-----+------+--------+
```

- 低 2 bits 为 10，以描述该 entry 是一个 exceptional entry
- 中间 4 bits 用于标志位
    - ZERO_PAGE 描述该 entry 描述一个 hole 或 unwritten extent，否则该 entry 描述一个 normal extent
    - EMPTY，通常往 radix tree 添加 entry 的时候，先往 radix tree 中添加一个 empty entry (PFN 字段为 0)，相当于是一个占位符；之后再更新 PFN 字段的值，并移除 EMPTY 标志
    - LOCK 用于将同一个 entry 的并发操作串行化
- 高 bits 存储对应的 PFN


#### read fault + write fault

如果是先 read page fault，后 write page fault，那么 mmap 框架需要解决 shared dirty page 的问题

所谓的 shared dirty page，实际上与文件的 writeback 相关。之前已经介绍过 shared file mmap 场景下需要执行 dirty pagecache 的 writeback 操作。而无论是普通模式还是 DAX 模式，文件的 address space 中都会维护相应的 mapping entry，并通过 @i_pages radix tree 的 DIRTY tag 来标记所有需要回写的 dirty page

以上过程中的重要一步就是，对 page 执行 write 操作的时候，在 @i_pages radix tree 中置上 DIRTY tag。那么 file mmap 流程中是如何置上 DIRTY tag 的呢？

试想一下，用户进程在执行 file mmap 的时候，根据 mmap() 系统调用返回的虚拟地址，就可以以内存访问的形式直接对文件进行 read/write 操作，如果先触发的是 read fault，那么在 read fault 之后已经分配了相应的 page frame 与 pte，如果 pte 设置的是 read/write 权限，那么之后用户进程完全可以根据 mmap() 系统调用返回的虚拟地址，对文件执行 write 操作，这个 write 操作完全是在用户进程的上下文中执行的，内核没有入口去执行设置 DIRTY tag 的操作

因而对于 shared file mmap 的文件，shared dirty page 问题实际上就是如何标记所有需要回写的 dirty page，也即如何给 dirty page 置上 DIRTY tag，这里需要注意的是

1. 只有 shared file mmap 存在上述 shared dirty page 的问题，如果是 private file mmap，read fault 映射的 page frame 只有 read 权限，而 write fault 映射的 page frame 又完全是私有的，并不需要回写，因而不存在 shared dirty page 问题
2. 即使是 shared file mmap，也只有先触发 read fault、后触发 write fault 的场景下才存在上述 shared dirty page 的问题，如果一开始就触发了 write fault，那么在 write fault handler 中就可以置上 DIRTY tag
3. 无论是普通模式还是 DAX 模式，都存在上述 shared dirty page 问题，也就是说这是 shared file mmap 下的一个通用问题

那么回到 shared dirty page 问题，在之前的实现中，由于没法置上 DIRTY tag，因而 writeback 过程中需要遍历 page table，根据 pte.D 找出该文件所有的 dirty page，由于需要遍历整个 page table，这种实现无疑是低效率的


后来实现的 page_mkwrite() 特性解决了这个问题。此时所有支持 shared file mmap 的文件系统都需要实现 vma_ops->page_mkwrite() 回调函数

```c
struct vm_operations_struct {
	...
	/* notification that a previously read-only page is about to become
	 * writable, if an error is returned it will cause a SIGBUS */
	vm_fault_t (*page_mkwrite)(struct vm_fault *vmf);
	...
}
```

其原理是，对于 shared file mmap，当触发 read fault 的时候，在 read fault handler 中，将 pte 设置为 read-only 权限，即使用户进程当初执行 mmap() 系统调用的时候，声明的是 read/write 权限

此时用户进程对该 page 只有 read 权限，之后进程对该 page 执行写操作的时候，就会触发 Write Protect Page Fault，在该 fault handler 中置上 DIRTY tag，也就是说 vma_ops->page_mkwrite() 回调函数就用来对 page 的 clean -> dirty 的状态变化进行监控，也就是用来追踪 shared dirty page


以下介绍该机制的全部流程

1. mmap: prepare read-only access permission

首先在 mmap() 系统调用过程中，vma->vm_page_prot 中显示对应的 pte 是只读的

```sh
old_mmap()/mmap_pgoff
    ksys_mmap_pgoff
        vm_mmap_pgoff
            do_mmap
                get_unmapped_area
                mmap_region
                    # allocate vma
                    vma->vm_page_prot = vm_get_page_prot(vm_flags); // pte.rw = 1, pte.usr = 1
                    vma->vm_flags = VM_READ｜VM_WRITE｜VM_SHARED
                    vma->vm_file = get_file(file);
                    fops->mmap(), i.e., ext4_file_mmap()
                        vma->vm_ops = ext4_dax_vm_ops
                    
                    vma_set_page_prot(vma)
                        # if vma_wants_writenotify(), i.e., vm_ops->page_mkwrite or vm_ops->pfn_mkwrite defined
                            # modify vma->vm_page_prot, pte.rw = 0
```


2. read page fault

对映射的虚拟地址区间作读操作时，会使得 pte 指向 NVDIMM 中的一个 page

- 但是该 pte 是只读的
- 同时往 address space 中插入一个 mapping entry，此时并没有置上 DIRTY tag

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault // file memory mapping
                do_read_fault
                    vma->vm_ops->fault(), i.e., ext4_dax_fault()
                        dax_iomap_fault
                            dax_iomap_pte_fault
                                # 1. calculate sector address via iomap
                                iomap_ops->iomap_begin()
                                
                                # 2. calculate PFN
                                dax_iomap_pfn
                            
                                # 3. insert mapping entry into address space
                                dax_insert_entry(..., dirty=false)
                                
                                # 4. insert pte into page table
                                vmf_insert_mixed // pte.rw=0
                                    # pte.rw = vma->vm_page_prot
```


3. write page fault

之后进程再一次对该 page 执行写操作时，就会触发 Write Protect Page Fault，其中会调用 vm_ops->page_mkwrite()/pfn_mkwrite() 回调函数，其主要工作是更新对应的 pte，使其具备 writable 权限

同时给 address space 的 @i_pages radix tree 的对应位置置上 DIRTY tag，以标记 NVDIMM 上该 PFN 转变为 dirty 状态，之后需要回写

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_wp_page // copy-on-write
                (vma->vm_flags & VM_SHARED) wp_pfn_shared/wp_page_shared
                    vmf->flags = FAULT_FLAG_WRITE|FAULT_FLAG_MKWRITE
                    vm_ops->pfn_mkwrite()/vm_ops->page_mkwrite()
                        dax_iomap_fault
                            dax_iomap_pte_fault
                                # 1. calculate sector address via iomap
                                iomap_ops->iomap_begin()
                                
                                # 2. calculate PFN
                                dax_iomap_pfn
                                
                                # 3. set DIRTY tag in address space
                                dax_insert_mapping_entry(..., dirty=true)
                                
                                # 4. update pte (with PFN unchanged), turn to be writable
                                vmf_insert_mixed_mkwrite // pte.rw=1
```


#### write fault

而如果一开始就直接触发 write page fault，此时也是 pte 指向 NVDIMM 中的一个 page

- 但是该 pte 是可读可写的
- 同时也会往 address space 插入一个 mapping entry，但此时会立即置上 DIRTY tag

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault  // file memory mapping
                # direct write fault: pte not exist
                do_shared_fault
                    __do_fault
                        vma->vm_ops->fault()
                            dax_iomap_fault
                                dax_iomap_pte_fault
                                    # 1. calculate sector address via iomap
                                    iomap_ops->iomap_begin()
                                    
                                    # 2. calculate PFN
                                    dax_iomap_pfn
                                
                                    # 3. insert mapping entry into address space
                                    dax_insert_entry(..., dirty=true)
                                    
                                    # 4. insert pte into page table
                                    vmf_insert_mixed_mkwrite // pte.rw=1
```


#### writeback

之前介绍过 DAX 模式下也需要执行 writeback 操作

我们知道 writeback 过程中会调用 a_ops->writepages() 对 dirty page 执行回写操作，主要入口是 dax_writeback_mapping_range()，其中就是通过 DIRTY tag 找到所有需要回写的 dirty PFN，在 x86 架构下是执行 clwb 指令执行 flush 操作

```sh
# writeback
a_ops->writepages(), i.e., ext4_dax_aops->writepages(), i.e., ext4_dax_writepages()
    dax_writeback_mapping_range
        find_get_entries_tag // find all dirty page (marked with DIRTY tag)
        (for each dirty page) dax_writeback_one
            dax_mapping_entry_mkclean // remove DIRTY bit of pte
            dax_flush // flush cache with 'clwb' instruction
```


### private file mmap

private file mmap 与 shared file mmap 的一个差异是，由于 private file mmap 中不需要考虑 writeback，因而无需往 address space 中插入 mapping entry，因而也就不需要通过 page_mkwrite()/pfn_mkwrite() 来监控 dirty PFN 事件

#### read fault + write fault

如果是先 read page fault，后 write page fault

1. read page fault

一开始触发 read fault 的时候，会使得 pte 指向 NVDIMM 中的一个 page，但是该 pte 是只读的；同时也会往 address space 中插入 mapping entry (虽然这个 mapping entry 之后并没有什么用)

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault // file memory mapping
                do_read_fault
                    vma->vm_ops->fault(), i.e., ext4_dax_fault()
                        dax_iomap_fault
                            dax_iomap_pte_fault
                                # 1. calculate sector address via iomap
                                iomap_ops->iomap_begin()
                                
                                # 2. calculate PFN
                                dax_iomap_pfn
                            
                                # 3. insert mapping entry into address space
                                dax_insert_entry(..., dirty=false)
                                
                                # 4. insert pte into page table
                                vmf_insert_mixed // pte.rw=0
```


2. write page fault

之后对该虚拟地址区间作写操作时，会触发 write protect page fault，此时会在内存中分配一个 page frame，将原本 NVDIMM 中的一个 page 的内容拷贝到新分配的内存中的一个 page frame，最终更新 pte 使其指向新分配的内存中的 page frame，此时该 pte 是可读可写的

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_wp_page // copy-on-write
                !(vma->vm_flags & VM_SHARED)wp_page_copy
                    # allocate new page frame
                    new_page = alloc_page_vma() // allocate one page from memory
                    cow_user_page(new_page, ..., vmf->address, ...)  // copy contents
                    
                    # make pte writable
                    entry = mk_pte(new_page, vma->vm_page_prot);
                    entry = maybe_mkwrite(entry, ...); // enable write permission
                        if vma->vm_flags & VM_WRITE: pte_mkwrite(pte)
                    set_pte_at_notify(..., pte, entry)  // build mapping
```

这里需要注意的是，cow_user_page() 中 @vmf->address 描述的是原本 NVDIMM 中 page 映射的虚拟地址，@new_page 是新分配的内存中的一个 page frame


#### write fault

如果一开始就是直接触发的 write page fault，那么此时也是在内存中分配一个 page frame，将原本 NVDIMM 中的一个 page 的内容拷贝到新分配的内存中的 page frame，同时分配对应的 pte，并使其指向新分配的内存中的 page frame，此时该 pte 是可读可写的

值得一提的是，现有实现中，此时还是会往 address space 中插入一个空的 mapping entry (设置有 EMPTY 标志，同时这个 mapping entry 之后并没有什么用)

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault  // file memory mapping
                # direct write fault: pte not exist
                do_cow_fault // copy-on-write
                    vmf->cow_page = alloc_page_vma() // allocate one page from memory
                    __do_fault
                        vma->vm_ops->map_pages(), i.e., ext4_dax_fault()
                            dax_iomap_fault
                                dax_iomap_pte_fault
                                    # 1. calculate sector address via iomap
                                    iomap_ops->iomap_begin()
                                    
                                    # 2. calculate PFN
                                    dax_iomap_pfn
                                    
                                    # 3. insert an empty mapping entry into address space
                                    grab_mapping_entry
                                
                                    # 4. copy original page (NVDIMM) to new private page (memory)
                                    (if vmf->cow_page) dax_fault_cow_page
                                        copy_cow_page_dax
                                            copy_user_dax // copy original page to new private page
                                    
                                    # 5. allocate pte pointing to new private page
                                    finish_fault
                                        alloc_set_pte(vmf, ..., vmf->cow_page)
                                            entry = mk_pte(page, vma->vm_page_prot)
                                            entry = maybe_mkwrite(pte_mkdirty(entry), vma) // pte.rw=1
```


此外这里需要注意的是，如果一开始就触发的 write page fault 中首先走到了 pmd fault，会直接回退到 pte fault，即 pmd fault 不负责 private file mmap 的 CoW 流程

```sh
page fault handler entry, that is, do_page_fault/exc_page_fault
    handle_mm_fault
        handle_pte_fault
            do_fault  // file memory mapping
                # direct write falut: pte not exist
                do_cow_fault // copy-on-write
                    vmf->cow_page = alloc_page_vma() // allocate one page from memory
                    __do_fault
                        vma->vm_ops->map_pages(), i.e., ext4_dax_fault()
                            dax_iomap_fault
                                dax_iomap_pmd_fault
                                    /* Fall back to PTEs if we're going to COW */
                                    if (write && !(vma->vm_flags & VM_SHARED))
                                        goto fallback;
```


